{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaruKatou/DL_Course/blob/main/tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "2TzaquEV5Q9K"
      },
      "source": [
        "# Tutorial 1: Introduction to CNNs\n",
        "\n",
        "**Week 2, Day 2: Convnets and DL Thinking**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ Dawn Estes McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi, Alona Fyshe\n",
        "\n",
        "__Content reviewers:__ Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva, Bettina Hein, Kelson Shilling-Scrivo\n",
        "\n",
        "__Content editors:__ Gagana B, Nina Kudryashova, Anmol Gupta, Xiaoxiong Lin, Spiros Chavlis\n",
        "\n",
        "__Production editors:__ Alex Tran-Van-Minh, Gagana B, Spiros Chavlis\n",
        "\n",
        "<br>\n",
        "\n",
        "*Based on material from:* Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KqG2dDDG5Q9M"
      },
      "source": [
        "---\n",
        "# Tutorial Objectives\n",
        "At the end of this tutorial, we will be able to:\n",
        "- Define what convolution is\n",
        "- Implement convolution as an operation\n",
        "\n",
        "In the Bonus materials of this tutorial, you will be able to:\n",
        "\n",
        "- Train a CNN by writing your own train loop\n",
        "- Recognize the symptoms of overfitting and how to cure them\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "aplgCzr-5Q9N",
        "outputId": "9a9224cb-f776-468c-a5d7-4e747bfb5445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to download the slides: https://osf.io/download/s8xz5/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e83092f7dd0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/s8xz5/?direct%26mode=render%26action=download%26mode=render\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# @title Tutorial slides\n",
        "from IPython.display import IFrame\n",
        "link_id = \"s8xz5\"\n",
        "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "w6Oz5WEl5Q9P"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "2zOkq81F5Q9P"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "!pip install Pillow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "lYj-WPoO5Q9Q"
      },
      "outputs": [],
      "source": [
        "# @title Install and import feedback gadget\n",
        "\n",
        "!pip3 install vibecheck datatops --quiet\n",
        "\n",
        "from vibecheck import DatatopsContentReviewContainer\n",
        "def content_review(notebook_section: str):\n",
        "    return DatatopsContentReviewContainer(\n",
        "        \"\",  # No text prompt\n",
        "        notebook_section,\n",
        "        {\n",
        "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
        "            \"name\": \"neuromatch_dl\",\n",
        "            \"user_key\": \"f379rz8y\",\n",
        "        },\n",
        "    ).render()\n",
        "\n",
        "\n",
        "feedback_prefix = \"W2D2_T1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "BpbH_iwf5Q9Q"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import time\n",
        "import torch\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {},
        "id": "dCDkQL8U5Q9R"
      },
      "outputs": [],
      "source": [
        "# @title Figure Settings\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').disabled = True\n",
        "\n",
        "import ipywidgets as widgets  # Interactive display\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {},
        "id": "KYz7F0PT5Q9S"
      },
      "outputs": [],
      "source": [
        "# @title Helper functions\n",
        "from scipy.signal import correlate2d\n",
        "import zipfile, gzip, shutil, tarfile\n",
        "\n",
        "\n",
        "def download_data(fname, folder, url, tar):\n",
        "  \"\"\"\n",
        "  Data downloading from OSF.\n",
        "\n",
        "  Args:\n",
        "    fname : str\n",
        "      The name of the archive\n",
        "    folder : str\n",
        "      The name of the destination folder\n",
        "    url : str\n",
        "      The download url\n",
        "    tar : boolean\n",
        "      `tar=True` the archive is `fname`.tar.gz, `tar=False` is `fname`.zip\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "\n",
        "  if not os.path.exists(folder):\n",
        "    print(f'\\nDownloading {folder} dataset...')\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    with open(fname, 'wb') as fh:\n",
        "      fh.write(r.content)\n",
        "    print(f'\\nDownloading {folder} completed.')\n",
        "\n",
        "    print('\\nExtracting the files...\\n')\n",
        "    if not tar:\n",
        "      with zipfile.ZipFile(fname, 'r') as fz:\n",
        "        fz.extractall()\n",
        "    else:\n",
        "      with tarfile.open(fname) as ft:\n",
        "        ft.extractall()\n",
        "    # Remove the archive\n",
        "    os.remove(fname)\n",
        "\n",
        "    # Extract all .gz files\n",
        "    foldername = folder + '/raw/'\n",
        "    for filename in os.listdir(foldername):\n",
        "      # Remove the extension\n",
        "      fname = filename.replace('.gz', '')\n",
        "      # Gunzip all files\n",
        "      with gzip.open(foldername + filename, 'rb') as f_in:\n",
        "        with open(foldername + fname, 'wb') as f_out:\n",
        "          shutil.copyfileobj(f_in, f_out)\n",
        "          os.remove(foldername+filename)\n",
        "  else:\n",
        "    print(f'{folder} dataset has already been downloaded.\\n')\n",
        "\n",
        "\n",
        "def check_shape_function(func, image_shape, kernel_shape):\n",
        "  \"\"\"\n",
        "  Helper function to check shape implementation\n",
        "\n",
        "  Args:\n",
        "    func: f.__name__\n",
        "      Function name\n",
        "    image_shape: tuple\n",
        "      Image shape\n",
        "    kernel_shape: tuple\n",
        "      Kernel shape\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  correct_shape = correlate2d(np.random.rand(*image_shape), np.random.rand(*kernel_shape), \"valid\").shape\n",
        "  user_shape = func(image_shape, kernel_shape)\n",
        "  if correct_shape != user_shape:\n",
        "    print(f\"❌ Your calculated output shape is not correct.\")\n",
        "  else:\n",
        "    print(f\"✅ Output for image_shape: {image_shape} and kernel_shape: {kernel_shape}, output_shape: {user_shape}, is correct.\")\n",
        "\n",
        "\n",
        "def check_conv_function(func, image, kernel):\n",
        "  \"\"\"\n",
        "  Helper function to check conv_function\n",
        "\n",
        "  Args:\n",
        "    func: f.__name__\n",
        "      Function name\n",
        "    image: np.ndarray\n",
        "      Image matrix\n",
        "    kernel_shape: np.ndarray\n",
        "      Kernel matrix\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  solution_user = func(image, kernel)\n",
        "  solution_scipy = correlate2d(image, kernel, \"valid\")\n",
        "  result_right = (solution_user == solution_scipy).all()\n",
        "  if result_right:\n",
        "    print(\"✅ The function calculated the convolution correctly.\")\n",
        "  else:\n",
        "    print(\"❌ The function did not produce the right output.\")\n",
        "    print(\"For the input matrix:\")\n",
        "    print(image)\n",
        "    print(\"and the kernel:\")\n",
        "    print(kernel)\n",
        "    print(\"the function returned:\")\n",
        "    print(solution_user)\n",
        "    print(\"the correct output would be:\")\n",
        "    print(solution_scipy)\n",
        "\n",
        "\n",
        "def check_pooling_net(net, device='cpu'):\n",
        "  \"\"\"\n",
        "  Helper function to check pooling output\n",
        "\n",
        "  Args:\n",
        "    net: nn.module\n",
        "      Net instance\n",
        "    device: string\n",
        "      GPU/CUDA if available, CPU otherwise.\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  x_img = emnist_train[x_img_idx][0].unsqueeze(dim=0).to(device)\n",
        "  output_x = net(x_img)\n",
        "  output_x = output_x.squeeze(dim=0).detach().cpu().numpy()\n",
        "\n",
        "  right_output = [\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "      0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "      0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [9.309552, 1.6216984, 0.000000, 0.000000, 0.000000, 0.000000, 2.2708383,\n",
        "      2.6654134, 1.2271233, 0.000000, 0.000000, 0.000000],\n",
        "      [12.873457, 13.318945, 9.46229, 4.663746, 0.000000, 0.000000, 1.8889914,\n",
        "      0.31068993, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 8.354934, 10.378724, 16.882853, 18.499334, 4.8546696, 0.000000,\n",
        "      0.000000, 0.000000, 6.29296, 5.096506, 0.000000],\n",
        "      [0.000000, 0.000000, 0.31068993, 5.7074604, 9.984148, 4.12916, 8.10037,\n",
        "      7.667609, 0.000000, 0.000000, 1.2780352, 0.000000],\n",
        "      [0.000000, 2.436305, 3.9764223, 0.000000, 0.000000, 0.000000, 12.98801,\n",
        "      17.1756, 17.531992, 11.664275, 1.5453291, 0.000000],\n",
        "      [4.2691708, 2.3217516, 0.000000, 0.000000, 1.3798618, 0.05612564, 0.000000,\n",
        "      0.000000, 11.218788, 16.360992, 13.980816, 8.354935],\n",
        "      [1.8126211, 0.000000, 0.000000, 2.9199777, 3.9382377, 0.000000, 0.000000,\n",
        "      0.000000, 0.000000, 0.000000, 6.076582, 10.035061],\n",
        "      [0.000000, 0.92164516, 4.434638, 0.7816348, 0.000000, 0.000000, 0.000000,\n",
        "      0.000000, 0.000000, 0.000000, 0.000000, 0.83254766],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "      0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "      0.000000, 0.000000, 0.000000, 0.000000, 0.000000]\n",
        "  ]\n",
        "\n",
        "  right_shape = (3, 12, 12)\n",
        "\n",
        "  if output_x.shape != right_shape:\n",
        "    print(f\"❌ Your output does not have the right dimensions. Your output is {output_x.shape} the expected output is {right_shape}\")\n",
        "  elif (output_x[0] != right_output).all():\n",
        "    print(\"❌ Your output is not right.\")\n",
        "  else:\n",
        "    print(\"✅ Your network produced the correct output.\")\n",
        "\n",
        "\n",
        "# Just returns accuracy on test data\n",
        "def test(model, device, data_loader):\n",
        "  \"\"\"\n",
        "  Test function\n",
        "\n",
        "  Args:\n",
        "    net: nn.module\n",
        "      Net instance\n",
        "    device: string\n",
        "      GPU/CUDA if available, CPU otherwise.\n",
        "    data_loader: torch.loader\n",
        "      Test loader\n",
        "\n",
        "  Returns:\n",
        "    acc: float\n",
        "      Test accuracy\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for data in data_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device).float()\n",
        "    labels = labels.to(device).long()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = 100 * correct / total\n",
        "  return f\"{acc}%\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {},
        "id": "QNvfxuya5Q9U"
      },
      "outputs": [],
      "source": [
        "# @title Plotting Functions\n",
        "\n",
        "def display_image_from_greyscale_array(matrix, title):\n",
        "  \"\"\"\n",
        "  Display image from greyscale array\n",
        "\n",
        "  Args:\n",
        "    matrix: np.ndarray\n",
        "      Image\n",
        "    title: string\n",
        "      Title of plot\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  _matrix = matrix.astype(np.uint8)\n",
        "  _img = Image.fromarray(_matrix, 'L')\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  plt.imshow(_img, cmap='gray', vmin=0, vmax=255) # Using 220 instead of 255 so the examples show up better\n",
        "  plt.title(title)\n",
        "  plt.axis('off')\n",
        "\n",
        "\n",
        "def make_plots(original, actual_convolution, solution):\n",
        "  \"\"\"\n",
        "  Function to build original image/obtained solution and actual convolution\n",
        "\n",
        "  Args:\n",
        "    original: np.ndarray\n",
        "      Image\n",
        "    actual_convolution: np.ndarray\n",
        "      Expected convolution output\n",
        "    solution: np.ndarray\n",
        "      Obtained convolution output\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  display_image_from_greyscale_array(original, \"Original Image\")\n",
        "  display_image_from_greyscale_array(actual_convolution, \"Convolution result\")\n",
        "  display_image_from_greyscale_array(solution, \"Your solution\")\n",
        "\n",
        "\n",
        "def plot_loss_accuracy(train_loss, train_acc,\n",
        "                       validation_loss, validation_acc):\n",
        "  \"\"\"\n",
        "  Code to plot loss and accuracy\n",
        "\n",
        "  Args:\n",
        "    train_loss: list\n",
        "      Log of training loss\n",
        "    validation_loss: list\n",
        "      Log of validation loss\n",
        "    train_acc: list\n",
        "      Log of training accuracy\n",
        "    validation_acc: list\n",
        "      Log of validation accuracy\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  epochs = len(train_loss)\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  ax1.plot(list(range(epochs)), train_loss, label='Training Loss')\n",
        "  ax1.plot(list(range(epochs)), validation_loss, label='Validation Loss')\n",
        "  ax1.set_xlabel('Epochs')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.set_title('Epoch vs Loss')\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2.plot(list(range(epochs)), train_acc, label='Training Accuracy')\n",
        "  ax2.plot(list(range(epochs)), validation_acc, label='Validation Accuracy')\n",
        "  ax2.set_xlabel('Epochs')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_title('Epoch vs Accuracy')\n",
        "  ax2.legend()\n",
        "  fig.set_size_inches(15.5, 5.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {},
        "id": "lP--a5LB5Q9U"
      },
      "outputs": [],
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# For DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness.\n",
        "  NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {},
        "id": "kjnkor4F5Q9V"
      },
      "outputs": [],
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# Inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qj0eVh75Q9V",
        "outputId": "8c9f05d9-b1bd-4df2-eb9e-0e5ebb03b185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
          ]
        }
      ],
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "7bXP_Y2y5Q9W"
      },
      "source": [
        "---\n",
        "# Section 0: Recap the Experience from Last Week\n",
        "\n",
        "*Time estimate: ~15mins*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3tvOKRHF5Q9W"
      },
      "source": [
        "Last week you learned a lot!  Recall that overparametrized ANNs are efficient universal approximators, but also that ANNs can memorize our data.  However, regularization can help ANNs to better generalize. You were introduced to several regularization techniques such as *L1*, *L2*, *Data Augmentation*, and *Dropout*.\n",
        "\n",
        "Today we'll be talking about other ways to simplify ANNs, by making smart changes to their architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581,
          "referenced_widgets": [
            "b87eb034ba5442d0bf3e034a568de188",
            "f25571432bba452ba1f3ce03f18e03e8",
            "998a3290d6f14cf0aafdfd0d249e0a30",
            "f5a46f5d4127447fbb4af27c8ae4f230",
            "786c5cb41f6241f7bded86594855baeb",
            "03b9701815d949bd883444253016294b"
          ]
        },
        "id": "tt5EpoQC5Q9X",
        "outputId": "591d92c4-4163-4080-b5b1-b2765aa519ad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b87eb034ba5442d0bf3e034a568de188"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Video 1: Introduction to CNNs and RNNs\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', '5598K-hS89A'), ('Bilibili', 'BV1cL411p7rz')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "g6_VDazj5Q9X"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Introduction_to_CNNs_and_RNNs_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "01gYI6zk5Q9X"
      },
      "source": [
        "## Think! 0: Regularization & effective number of params\n",
        "Let's think back to last week, when you learned about regularization.  Recall that regularization comes in several forms. For example, L1 regularization adds a term to the loss function that penalizes based on the sum of the _absolute_ magnitude of the weights. Below are the results from training a simple multilayer perceptron with one hidden layer (b) on a simple toy dataset (a).\n",
        "\n",
        "Below that are two graphics that show the effect of regularization on both the number of non-zero weights (d), and on the network's accuracy (c).\n",
        "\n",
        "What do you notice?\n",
        "\n",
        "**Note**: Dense layers are the same as fully-connected layers.  And pytorch calls them linear layers.  Confusing, but now you know!\n",
        "\n",
        "<figure>\n",
        "  <img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/think0.png\">\n",
        "  <figcaption><b>a.</b> The 2-dimensional inputs of class A (red) and B (green). <b>b.</b>The network architecture. Each Dense layer contains the (batch size, dimension), and below, the number of its trainable parameters. <b>c.</b>The train (blue) and validation (orange) accuracy as function of the regularization strength. <b>d.</b>The number of non-zero parameters as a function of the regularization strength.</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "2j7CeIi_5Q9Y"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_18b18cac.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "DReVQuzk5Q9Y"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Regularization_and_effective_number_of_params_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "hdZlXwzL5Q9Y"
      },
      "source": [
        "**Coming Up**\n",
        "\n",
        "The rest of these lectures focus on another way to reduce parameters: weight-sharing. Weight-sharing is based on the idea that some sets of weights can be used at multiple points in a network. We will focus primarily on CNNs today, where the weight-sharing is across the 2D space of an image.  This weight-sharing technique (across space) can reduce the number of parameters and increase a network's ability to generalize. For completeness, a similar approach is the Recurrent Neural Networks (RNNs), which share parameters across time, but we will not dive into this in this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Myi-CqRp5Q9Z"
      },
      "source": [
        "---\n",
        "# Section 1: Neuroscience motivation, General CNN structure\n",
        "\n",
        "*Time estimate: ~25mins*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581,
          "referenced_widgets": [
            "710b8404c9214c5e89d8f9e2b6724776",
            "37004122064e4b0ab6da16504e53690f",
            "322aa03c08044c59aed23f845b5a4e56",
            "7d56cdb94b2f4a379c93b3244069aecf",
            "70b674d385904a38964ac9d5cce6fc55",
            "3304fae8eb5345d9aee08c1abe019634"
          ]
        },
        "id": "QLNBy4kr5Q9Z",
        "outputId": "9d201a0d-e442-49c0-b57b-4986568bf149"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "710b8404c9214c5e89d8f9e2b6724776"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Video 2: Representations & Visual processing in the brain\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', 'AXO-iflKa58'), ('Bilibili', 'BV1c64y1x7mJ')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "bhlEirNy5Q9Z"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Representations_and_Visual_processing_in_the_brain_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "FKmWaBA_5Q9Z"
      },
      "source": [
        "## Think! 1: What makes a representation good?\n",
        "Representations have a long and storied history, having been studied by the likes of Aristotle back in 300 BC! Representations are not a new idea, and they certainly don't exist just in neural networks.\n",
        "\n",
        "Take a moment with your pod to discuss what would make a good representation, and how that might differ depending on the task you train your CNN to do.\n",
        "\n",
        "If there's time, you can also consider how the brain's representations might differ from a *learned* representation inside a NN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "J3dyreMF5Q9Z"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_82e644f4.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "1TGA5m3V5Q9Z",
        "outputId": "4c1fb2e3-b08b-4726-aac6-898d55a739b2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'content_review' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0ed8ac6e62e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Submit your feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontent_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{feedback_prefix}_What_makes_a_representation_good_Discussion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content_review' is not defined"
          ]
        }
      ],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_What_makes_a_representation_good_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "k1-22Ztt5Q9a"
      },
      "source": [
        "---\n",
        "# Section 2: Convolutions and Edge Detection\n",
        "\n",
        "*Time estimate: ~25mins*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tHjx2ClT5Q9a"
      },
      "source": [
        "Fundamental to CNNs are convolutions. After all, that is what the **C** in CNN stands for! In this section, we will define what a convolution is, practice performing a convolution, and implement it in code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581,
          "referenced_widgets": [
            "e8611a6b7ccd4c55b932d8eefd241c69",
            "24e5a887acec411d8ff57a9b759e5fab",
            "8e032ad7e3d74986aa420fece8b33afa",
            "88286767786440e3b6e15852af349671",
            "c3a4dfcb530c44448ce054311f32fcab",
            "1816700c745846cdbc1e0a3ac94da452"
          ]
        },
        "id": "juEc2Ito5Q9a",
        "outputId": "3c23b8e2-1385-450d-de56-c0427f02ce2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8611a6b7ccd4c55b932d8eefd241c69"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Video 3: Details about Convolution\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', 'pmc40WCnF-w'), ('Bilibili', 'BV1Q64y1z77p')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "wnIS3WiL5Q9a"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Details_about_convolution_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gyTy_q0-5Q9a"
      },
      "source": [
        "Before jumping into coding exercises, take a moment to look at this animation that steps through the process of convolution.\n",
        "\n",
        "Recall from the video that convolution involves sliding the kernel across the image, taking the element-wise product, and adding those products together.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/correlation.svg\">\n",
        "\n",
        "Adopted from A. Zhang, Z. C. Lipton, M. Li and A. J. Smola, _[Dive into Deep Learning](http://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html)_.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** You need to run the cell to activate the sliders, and again to run once changing the sliders.\n",
        "\n",
        "**Tip:** In this animation, and all the ones that follow, you can hover over the parts of the code underlined in red to change them.\n",
        "\n",
        "**Tip:** Below, the function is called `Conv2d` because the convolutional filter is a matrix with two dimensions (2D).  There are also 1D and 3D convolutions, but we won't talk about them today."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "pt0kaQjx5Q9a"
      },
      "source": [
        "### Interactive Demo 2: Visualization of Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Yl2Q9r9u5Q9a"
      },
      "source": [
        "**Important:** Change the bool variable `run_demo` to `True` by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "TkD6Pr0C5Q9b",
        "outputId": "76365761-54cf-46ea-e91a-eabfcaff9319"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "    <style>\n",
              "        svg {\n",
              "            #border: 1px solid black;\n",
              "        }\n",
              "    .matrix {\n",
              "        font-family: sans-serif;\n",
              "        transition: all 700ms ease-in-out;\n",
              "    }\n",
              "    .cell rect {\n",
              "        fill:white;stroke-width:1;stroke:rgb(0,0,0)\n",
              "    }\n",
              "    .padding rect {\n",
              "        stroke: rgba(0, 0, 0, 0.25);\n",
              "    }\n",
              "    .padding text {\n",
              "        fill: lightgray;\n",
              "    }\n",
              "    .highlight1 {\n",
              "        fill:none;stroke-width:4;stroke: rgb(236, 58, 58);stroke-dasharray:10,5;\n",
              "    }\n",
              "    .highlight2 {\n",
              "        fill:rgba(229, 132, 66, 0.25);stroke-width:5;stroke: rgb(229, 132, 66);\n",
              "    }\n",
              "    .highlight3 {\n",
              "        fill:rgba(236, 58, 58, 0.25);stroke-width:2;stroke: rgb(236, 58, 58);;\n",
              "    }\n",
              "    .title {\n",
              "        text-anchor: middle;\n",
              "    }\n",
              "    .button_play {\n",
              "        display: inline-block;\n",
              "        background: none;\n",
              "        border: none;\n",
              "        position: relative;\n",
              "        top: -3px;\n",
              "    }\n",
              "    .button_play path {\n",
              "        fill: darkgray;\n",
              "    }\n",
              "    .button_play:hover path {\n",
              "        fill: rgb(236, 58, 58);\n",
              "    }\n",
              "    .display_vis_input input:not(:hover)::-webkit-outer-spin-button,\n",
              "    .display_vis_input input:not(:hover)::-webkit-inner-spin-button {\n",
              "        /* display: none; <- Crashes Chrome on hover */\n",
              "        -webkit-appearance: none;\n",
              "        margin: 0; /* <-- Apparently some margin are still there even though it's hidden */\n",
              "    }\n",
              "\n",
              "    .display_vis_input input:not(:hover)[type=number] {\n",
              "        -moz-appearance:textfield; /* Firefox */\n",
              "        width: 1ch;\n",
              "        margin-right: 0px;\n",
              "        z-index: 0;\n",
              "    }\n",
              "    .display_vis_input input[type=number] {\n",
              "        width: 4ch;\n",
              "        border: 0px;\n",
              "        margin-right: -3ch;\n",
              "        z-index: 6;\n",
              "        display: inline-block;\n",
              "        position: relative;\n",
              "        padding: 0;\n",
              "        border-bottom: 2px solid red;\n",
              "        background: white;\n",
              "        color: black\n",
              "    }\n",
              "    .display_vis_input .pair {\n",
              "        display: inline-block;\n",
              "        white-space:nowrap;\n",
              "            position: relative;\n",
              "    }\n",
              "    .display_vis_input .pair .pair_hide {\n",
              "        max-width: 4em;\n",
              "        transition: max-width 1s ease-in;\n",
              "        display: inline-block;\n",
              "        overflow: hidden;\n",
              "        position: relative;\n",
              "        top: 5px;\n",
              "    }\n",
              "    .pair:not(:hover) .pair_hide {\n",
              "        max-width: 0;\n",
              "    }\n",
              "    .pairX .pair_hide {\n",
              "        max-width: 4em;\n",
              "        transition: max-width 1s ease-in;\n",
              "    }\n",
              "\n",
              "    /* Dropdown Button */\n",
              "    .dropbtn {\n",
              "      border-bottom: 2px solid red;\n",
              "    }\n",
              "\n",
              "    /* The container <div> - needed to position the dropdown content */\n",
              "    .dropdown {\n",
              "      position: relative;\n",
              "      display: inline-block;\n",
              "    }\n",
              "\n",
              "    /* Dropdown Content (Hidden by Default) */\n",
              "    .dropdown-content {\n",
              "      display: none;\n",
              "      position: absolute;\n",
              "      background-color: #f1f1f1;\n",
              "      min-width: 160px;\n",
              "      box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);\n",
              "      z-index: 1;\n",
              "    }\n",
              "\n",
              "    /* Links inside the dropdown */\n",
              "    .dropdown-content a {\n",
              "      color: black;\n",
              "      padding: 5px 2px;\n",
              "      text-decoration: none;\n",
              "      display: block;\n",
              "    }\n",
              "\n",
              "    /* Change color of dropdown links on hover */\n",
              "    .dropdown-content a:hover {background-color: #ddd;}\n",
              "\n",
              "    /* Show the dropdown menu on hover */\n",
              "    .dropdown:hover .dropdown-content {display: block;}\n",
              "\n",
              "    </style>\n",
              "    <script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\" > </script>\n",
              "\n",
              "    <div id=\"animation_conv_filters\" style=\"background: white\">\n",
              "        <div class=\"display_vis_input language-python\" style=\"font-family: monospace; color: black; padding: 10px;\">\n",
              "            <!-- default -->\n",
              "            import torch<br><br>\n",
              "            input = torch.rand(1, 1<input class=\"input_matrixz\" type=\"hidden\" min=\"1\" max=\"3\" value=\"1\">, <input class=\"input_matrixy\" type=\"number\" min=\"3\" max=\"5\" value=\"3\">, <input class=\"input_matrixx\" type=\"number\" min=\"3\" max=\"5\" value=\"4\">)<br>\n",
              "            conv = torch.nn.Conv2d(in_channels=1<input class=\"input_matrixzB\" type=\"hidden\" min=\"1\" max=\"3\" value=\"1\">, out_channels=1<input class=\"input_filterz\" type=\"hidden\" min=\"1\" max=\"3\" value=\"1\">,\n",
              "            kernel_size=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_filtery\" type=\"number\" min=\"2\" max=\"4\" value=\"2\"><span class=\"pair_hide\">,\n",
              "                                                                           <input class=\"input_filterx\" type=\"number\" min=\"2\" max=\"4\" value=\"3\">)</span></span>\n",
              "            <span class=\"pair\" style=\"display: none\"><span class=\"pair_hide\">(</span><input class=\"input_stridex\" type=\"hidden\" min=\"1\" max=\"2\" value=\"1\"><span class=\"pair_hide\">,\n",
              "                                                                      <input class=\"input_stridey\" type=\"hidden\" min=\"1\" max=\"2\" value=\"1\">)</span></span>\n",
              "            <span class=\"pair\" style=\"display: none\"><span class=\"pair_hide\">(</span><input class=\"input_paddingx\" type=\"hidden\" min=\"0\" max=\"4\" value=\"0\"><span class=\"pair_hide\">,\n",
              "                                                                       <input class=\"input_paddingy\" type=\"hidden\" min=\"0\" max=\"4\" value=\"0\">)</span></span>)<br>\n",
              "            result = conv(input)\n",
              "        </div>\n",
              "\n",
              "        <button class=\"button_play play\"><svg width=\"15\" height=\"15\" viewbox=\"0 0 10 10\"><path d=\"M 1.5,0 9.5,5 1.5,10 z\"/></svg></button>\n",
              "        <button class=\"button_play pause\" style=\"display: none\"><svg width=\"15\" height=\"15\" viewbox=\"0 0 10 10\"><path d=\"M 0,0 4,0 4,10, 0,10 z\"/><path d=\"M 6,0 10,0 10,10, 6,10 z\"/></svg></button>\n",
              "        <input type=\"range\" min=\"1\" max=\"100\" value=\"50\" class=\"slider\" style=\"width: 300px; display: inline-block\">\n",
              "        <button class=\"button_play left\"><svg width=\"7\" height=\"15\" viewbox=\"0 0 4 10\"><path d=\"M 0,5 4,0 4,10 z\"/></svg></button>\n",
              "        <button class=\"button_play right\"><svg width=\"7\" height=\"15\" viewbox=\"0 0 4 10\"><path d=\"M 0,0 4,5 0,10 z\"/></svg></button>\n",
              "        <input type=\"checkbox\" class=\"play_fast\">fast play mode\n",
              "        <br/>\n",
              "        <svg height=\"0\" width=\"0\">\n",
              "            <defs>\n",
              "            <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\"\n",
              "                refX=\"0\" refY=\"1.5\" orient=\"auto\" fill=\"rgb(236, 58, 58)\">\n",
              "                <polygon points=\"0 0, 4 1.5, 0 3\" />\n",
              "            </marker>\n",
              "            </defs>\n",
              "        </svg>\n",
              "        <svg class=\"image\" height=\"460\" width=\"600\"></svg>\n",
              "    </div>\n",
              "\n",
              "    <script>\n",
              "        (function() {\n",
              "        var dom_target = document.getElementById(\"animation_conv_filters\")\n",
              "        const divmod = (x, y) => [Math.floor(x / y), x % y];\n",
              "        var svg = d3.select(dom_target).select(\".image\")\n",
              "\n",
              "        var box_s = 50;\n",
              "        var box_z = 10;\n",
              "        var show_single_elements = true;\n",
              "        var group_func = undefined;\n",
              "        function mulberry32(a) {\n",
              "            return function() {\n",
              "              var t = a += 0x6D2B79F5;\n",
              "              t = Math.imul(t ^ t >>> 15, t | 1);\n",
              "              t ^= t + Math.imul(t ^ t >>> 7, t | 61);\n",
              "              return ((t ^ t >>> 14) >>> 0) / 4294967296;\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function numberGenerator(seed, max, digits) {\n",
              "            var random = mulberry32(seed)\n",
              "            return () => parseFloat((random() * max).toFixed(digits));\n",
              "        }\n",
              "        window.numberGenerator = numberGenerator\n",
              "        window.mulberry32 = mulberry32\n",
              "        function generateMatrix2(number, dims) {\n",
              "            var res = [];\n",
              "            for (var i = 0; i < dims[0]; i++) {\n",
              "                if(dims.length == 1)\n",
              "                    res.push(number())\n",
              "                else\n",
              "                    res.push(generateMatrix2(number, dims.slice(1)));\n",
              "            }\n",
              "            return res\n",
              "        }\n",
              "        window.generateMatrix2 = generateMatrix2\n",
              "\n",
              "        function addPadding(matrix, paddingx, paddingy) {\n",
              "            matrix = JSON.parse(JSON.stringify(matrix));\n",
              "            var ly = matrix.length; var lx = matrix[0].length;\n",
              "            for (var i = 0; i < ly; i++) {\n",
              "                for(var p = 0; p < paddingx; p++) {\n",
              "                    matrix[i].splice(0, 0, 0);\n",
              "                    matrix[i].splice(matrix[i].length, 0, 0);\n",
              "                }\n",
              "            }\n",
              "            for(var p = 0; p < paddingy; p++) {\n",
              "                matrix.splice(0, 0, []);\n",
              "                matrix.splice(matrix.length, 0, []);\n",
              "                for (var i = 0; i < lx + paddingx * 2; i++) {\n",
              "                    matrix[0].push(0);\n",
              "                    matrix[matrix.length - 1].push(0);\n",
              "                }\n",
              "            }\n",
              "            matrix.paddingx = paddingx;\n",
              "            matrix.paddingy = paddingy;\n",
              "            return matrix;\n",
              "        }\n",
              "\n",
              "        var stride_x = 1;\n",
              "        var stride_y = 1;\n",
              "        function convolve(matrix, filter) {\n",
              "            var ress = [];\n",
              "            for(var zz = 0; zz < filter.length; zz++) {\n",
              "                var res = [];\n",
              "                for (var i = 0; i < parseInt((matrix[0].length - filter[0][0].length + stride_y) / stride_y); i++) {\n",
              "                    res.push([]);\n",
              "                    for (var j = 0; j < parseInt((matrix[0][0].length - filter[0][0][0].length + stride_x) / stride_x); j++) {\n",
              "                        var answer = 0;\n",
              "                        var text = \"\";\n",
              "                        for (var ii = 0; ii < filter[0][0].length; ii++) {\n",
              "                            for (var jj = 0; jj < filter[0][0][0].length; jj++) {\n",
              "                                for (var z = 0; z < matrix.length; z++) {\n",
              "                                    answer += matrix[z][i * stride_y + ii][j * stride_x + jj] * filter[zz][z][ii][jj];\n",
              "                                    text +=matrix[z][i * stride_y + ii][j * stride_x + jj] + \"*\" + filter[zz][z][ii][jj]+\"+\";\n",
              "                                }\n",
              "                            }\n",
              "                        }\n",
              "                        console.log(i, j, text, \"=\", answer)\n",
              "                        res[res.length - 1].push(answer.toFixed(1))\n",
              "                    }\n",
              "                }\n",
              "                ress.push(res)\n",
              "            }\n",
              "            return ress;\n",
              "        }\n",
              "        function pool(matrix, filter, func) {\n",
              "            var res = [];\n",
              "            for (var i = 0; i < parseInt((matrix.length - filter.length + stride_y) / stride_y); i++) {\n",
              "                res.push([]);\n",
              "                for (var j = 0; j < parseInt((matrix[0].length - filter[0].length + stride_x) / stride_x); j++) {\n",
              "                    var answer = [];\n",
              "                    for(var ii = 0; ii < filter.length; ii++) {\n",
              "                        for(var jj = 0; jj < filter[0].length; jj++) {\n",
              "                            answer.push(matrix[i* stride_y + ii][j* stride_x + jj]);\n",
              "                        }\n",
              "                    }\n",
              "                    if(func == \"max\")\n",
              "                        res[res.length-1].push(Math.max(...answer))\n",
              "                    else {\n",
              "                        var sum = 0;\n",
              "                        for( var ii = 0; ii < answer.length; ii++)\n",
              "                            sum += answer[ii]; //don't forget to add the base\n",
              "                        var avg = sum/answer.length;\n",
              "                        res[res.length-1].push(parseFloat(avg.toFixed(1)));\n",
              "                    }\n",
              "\n",
              "                }\n",
              "            }\n",
              "            return res;\n",
              "        }\n",
              "\n",
              "        class Matrix {\n",
              "            constructor(x, y, matrix, title) {\n",
              "                this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`);\n",
              "                for(var z = 0; z < matrix.length; z++) {\n",
              "                    var gg = this.g.append(\"g\").attr(\"class\", \"matrix_layer\").attr(\"transform\", `translate(${- z*box_z}, ${+ z*box_z})`);\n",
              "                    for (var j = 0; j < matrix[0].length; j++) {\n",
              "                        for (var i = 0; i < matrix[0][0].length; i++) {\n",
              "                            var element = gg.append(\"g\").attr(\"class\", \"cell\").attr(\"transform\", `translate(${i * box_s}, ${j * box_s})`);\n",
              "                            var rect = element.append(\"rect\")\n",
              "                                .attr(\"class\", \"number\")\n",
              "                                .attr(\"x\", -box_s / 2 + \"px\")\n",
              "                                .attr(\"y\", -box_s / 2 + \"px\")\n",
              "                                .attr(\"width\", box_s + \"px\")\n",
              "                                .attr(\"height\", box_s + \"px\")\n",
              "                            if (i < matrix.paddingx || j < matrix.paddingy || i > matrix[0][0].length - matrix.paddingx - 1 || j > matrix[0].length - matrix.paddingy - 1)\n",
              "                                element.attr(\"class\", \"cell padding\")\n",
              "                            element.append(\"text\").text(matrix[z][j][i]).attr(\"text-anchor\", \"middle\").attr(\"alignment-baseline\", \"center\").attr(\"dy\", \"0.3em\")\n",
              "                        }\n",
              "                    }\n",
              "                    gg.append(\"rect\").attr(\"class\", \"highlight3\")\n",
              "                    gg.append(\"rect\").attr(\"class\", \"highlight1\")\n",
              "                    gg.append(\"rect\").attr(\"class\", \"highlight2\")\n",
              "                }\n",
              "                this.arrow = gg.append(\"line\").attr(\"transform\", `translate(${(-0.5)*box_s}, ${(-0.5+filter.length/2)*box_s})`).attr(\"marker-end\", \"url(#arrowhead)\").attr(\"x1\", 0).attr(\"y1\", 0).attr(\"x2\", 50).attr(\"y2\", 0)\n",
              "                    .attr(\"stroke\", \"#000\").attr(\"stroke-width\", 8).attr(\"stroke\", \"rgb(236, 58, 58)\").style(\"opacity\", 0)\n",
              "\n",
              "\n",
              "                gg.append(\"text\").attr(\"class\", \"title\").text(title)\n",
              "                    .attr(\"x\", (matrix[0][0].length/2-0.5)*box_s+\"px\")\n",
              "                    .attr(\"y\", (matrix[0].length)*box_s+\"px\")\n",
              "                    .attr(\"dy\", \"0em\")\n",
              "                this.highlight2_hidden = true\n",
              "            }\n",
              "\n",
              "            setHighlight1(i, j, w, h) {\n",
              "                if(this.old_i == i && this.old_j == j && this.old_w == w)\n",
              "                    return\n",
              "                if(i == this.old_i+stride_x || j == this.old_j+stride_y) {\n",
              "                    if (this.old_j == j)\n",
              "                        this.arrow.attr(\"x1\", this.old_i * box_s).attr(\"y1\", j * box_s)\n",
              "                            .attr(\"x2\", i * box_s - 30).attr(\"y2\", j * box_s).attr(\"transform\", `translate(${(-0.5) * box_s}, ${(-0.5 + h / 2) * box_s})`)\n",
              "                    else\n",
              "                        this.arrow.attr(\"x1\", i * box_s).attr(\"y1\", this.old_j * box_s)\n",
              "                            .attr(\"x2\", i * box_s).attr(\"y2\", j * box_s - 30).attr(\"transform\", `translate(${(-0.5 + w / 2) * box_s}, ${(-0.5) * box_s})`)\n",
              "                    this.arrow.transition().style(\"opacity\", 1)\n",
              "                        .transition()\n",
              "                        .duration(1000)\n",
              "                        .style(\"opacity\", 0)\n",
              "                }\n",
              "                this.old_i = i; this.old_j = j; this.old_w = w;\n",
              "                this.g.selectAll(\".highlight1\")\n",
              "                    .style(\"fill\", \"rgba(236, 58, 58, 0)\")\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                    .attr(\"width\", box_s*w+\"px\")\n",
              "                    .attr(\"height\", box_s*h+\"px\")\n",
              "                    .style(\"fill\", \"rgba(236, 58, 58, 0.25)\")\n",
              "                this.g.selectAll(\".highlight3\")\n",
              "                    .style(\"opacity\", 1)\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .style(\"opacity\", 0)\n",
              "                this.g.selectAll(\".highlight3\")\n",
              "                    .transition()\n",
              "                    .delay(900)\n",
              "                    .duration(0)\n",
              "                    .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                    .attr(\"width\", box_s*w+\"px\")\n",
              "                    .attr(\"height\", box_s*h+\"px\")\n",
              "            }\n",
              "\n",
              "            setHighlight2(i, j, w, h) {\n",
              "                if(this.highlight2_hidden == true) {\n",
              "                    this.g.selectAll(\".highlight2\")\n",
              "                    .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                    .attr(\"width\", box_s*w+\"px\")\n",
              "                    .attr(\"height\", box_s*h+\"px\")\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .style(\"opacity\", 1)\n",
              "                    this.highlight2_hidden = false\n",
              "                    return\n",
              "                }\n",
              "                this.g.selectAll(\".highlight2\")\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                    .attr(\"width\", box_s*w+\"px\")\n",
              "                    .attr(\"height\", box_s*h+\"px\");\n",
              "            }\n",
              "            hideHighlight2() {\n",
              "                this.highlight2_hidden = true\n",
              "                this.g.selectAll(\".highlight2\")\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .style(\"opacity\", 0)\n",
              "            }\n",
              "        }\n",
              "\n",
              "        class Calculation {\n",
              "            constructor(x, y, matrix, title) {\n",
              "                this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`)\n",
              "                this.g.append(\"text\").text(title).attr(\"dy\", \"-1.5em\").attr(\"dx\", \"2em\")\n",
              "                this.g = this.g.append(\"text\")\n",
              "                for (var j in matrix) {\n",
              "                    for (var i in matrix[j]) {\n",
              "                        var element = this.g;\n",
              "                        var a = element.append(\"tspan\")\n",
              "                            .text(i+\"·\"+j)\n",
              "                        if(i == 0 && j > 0)\n",
              "                            a.attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                        if(i == matrix[0].length - 1 && j == matrix.length - 1) {\n",
              "                            a = element.append(\"tspan\")\n",
              "                            .attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                            .text(\" = 12 \")\n",
              "                        }\n",
              "                        else {\n",
              "                            a = element.append(\"tspan\")\n",
              "                                .text(\" + \")\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "            setText(i, text) {\n",
              "                d3.select(this.g.selectAll(\"tspan\")[0][i*2]).text(text)\n",
              "            }\n",
              "            hideAll() {\n",
              "                this.g.selectAll(\"tspan\")\n",
              "                    .attr(\"fill\", \"white\")\n",
              "            }\n",
              "            setHighlight1(i) {\n",
              "                this.g.selectAll(\"tspan\")\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .attr(\"fill\",\n",
              "                    (d, ii) => ii==i*2 ? \"rgb(229, 132, 66)\" : ii> i*2 ? \"white\" : \"black\")\n",
              "\n",
              "            }\n",
              "        }\n",
              "\n",
              "        class CalculationPool {\n",
              "            constructor(x, y, matrix, title) {\n",
              "                this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`)\n",
              "                this.g.append(\"text\").text(title).attr(\"dy\", \"-3em\").attr(\"dx\", \"-2em\")\n",
              "                this.g.append(\"text\").text(group_func+\"([\").attr(\"dy\", \"-1.5em\").attr(\"dx\", \"-0.5em\")\n",
              "                this.g = this.g.append(\"text\")\n",
              "                for (var j in matrix) {\n",
              "                    for (var i in matrix[j]) {\n",
              "                        var element = this.g;\n",
              "                        var a = element.append(\"tspan\")\n",
              "                            .text(\"\")\n",
              "                        if(i == 0 && j > 0)\n",
              "                            a.attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                        if(i == matrix[0].length - 1 && j == matrix.length - 1) {\n",
              "                            a = element.append(\"tspan\")\n",
              "                            .attr(\"dy\", \"1.5em\").attr(\"x\", 0).attr(\"dx\", \"-0.5em\")\n",
              "                            .text(\"\")\n",
              "                        }\n",
              "                        else {\n",
              "                            a = element.append(\"tspan\")\n",
              "                                .text(\"\")\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "            setText(i, text) {\n",
              "                d3.select(this.g.selectAll(\"tspan\")[0][i*2]).text(text)\n",
              "            }\n",
              "            hideAll() {\n",
              "                this.g.selectAll(\"tspan\")\n",
              "                    .attr(\"fill\", \"white\")\n",
              "            }\n",
              "            setHighlight1(i) {\n",
              "                this.g.selectAll(\"tspan\")\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .attr(\"fill\",\n",
              "                    (d, ii) => ii==i*2 ? \"rgb(229, 132, 66)\" : ii> i*2 ? \"white\" : \"black\")\n",
              "\n",
              "            }\n",
              "        }\n",
              "\n",
              "        var matrix, res, m, f, r, c, last_pos, index_max;\n",
              "        function init() {\n",
              "            show_single_elements = dom_target.querySelector(\".play_fast\").checked == false\n",
              "\n",
              "            svg.selectAll(\"*\").remove();\n",
              "\n",
              "            dom_target.querySelector(\".input_matrixzB\").value = dom_target.querySelector(\".input_matrixz\").value\n",
              "\n",
              "            console.log(\"dom_target\", dom_target)\n",
              "            console.log(\"dom_target.querySelector(\\\".input_filterx\\\").value)\", dom_target.querySelector(\".input_filterx\").value)\n",
              "            filter = generateMatrix2(numberGenerator(17, 0.9, 1), [parseInt(dom_target.querySelector(\".input_filterz\").value), parseInt(dom_target.querySelector(\".input_matrixz\").value), parseInt(dom_target.querySelector(\".input_filtery\").value), parseInt(dom_target.querySelector(\".input_filterx\").value)]);\n",
              "            if(dom_target.querySelector(\".input_filterx\").value == dom_target.querySelector(\".input_filtery\").value)\n",
              "                dom_target.querySelector(\".input_filtery\").parentElement.className = \"pair\"\n",
              "            else\n",
              "                dom_target.querySelector(\".input_filtery\").parentElement.className = \"pairX\"\n",
              "            matrix_raw = generateMatrix2(numberGenerator(4, 9, 0), [parseInt(dom_target.querySelector(\".input_matrixz\").value), parseInt(dom_target.querySelector(\".input_matrixy\").value), parseInt(dom_target.querySelector(\".input_matrixx\").value)]);\n",
              "\n",
              "            matrix = JSON.parse(JSON.stringify(matrix_raw));\n",
              "            for(var z = 0; z < matrix.length; z++)\n",
              "                matrix[z] = addPadding(matrix_raw[z], parseInt(dom_target.querySelector(\".input_paddingx\").value), parseInt(dom_target.querySelector(\".input_paddingy\").value));\n",
              "            matrix.paddingx = matrix[0].paddingx\n",
              "            matrix.paddingy = matrix[0].paddingy\n",
              "            stride_x = parseInt(dom_target.querySelector(\".input_stridex\").value)\n",
              "            stride_y = parseInt(dom_target.querySelector(\".input_stridey\").value)\n",
              "\n",
              "            if(dom_target.querySelector(\".input_stridex\").value == dom_target.querySelector(\".input_stridey\").value)\n",
              "                dom_target.querySelector(\".input_stridey\").parentElement.className = \"pair\"\n",
              "            else\n",
              "                dom_target.querySelector(\".input_stridey\").parentElement.className = \"pairX\"\n",
              "                if(dom_target.querySelector(\".input_paddingx\").value == dom_target.querySelector(\".input_paddingy\").value)\n",
              "                dom_target.querySelector(\".input_paddingy\").parentElement.className = \"pair\"\n",
              "            else\n",
              "                dom_target.querySelector(\".input_paddingy\").parentElement.className = \"pairX\"\n",
              "\n",
              "            res = convolve(matrix, filter);\n",
              "                window.matrix = matrix\n",
              "                window.filter = filter\n",
              "                window.res = res\n",
              "            if(group_func != undefined)\n",
              "                res = [pool(matrix[0], filter[0][0], group_func)]\n",
              "\n",
              "            m = new Matrix(1*box_s, (1+filter[0][0].length+1.5)*box_s, matrix, \"Matrix\");\n",
              "\n",
              "            f = []\n",
              "            for(var zz = 0; zz < filter.length; zz++)\n",
              "                f.push(new Matrix((1+(matrix[0][0].length-filter[zz][0][0].length)/2 + zz*(1+filter[zz][0][0].length))*box_s, 1*box_s, filter[zz], group_func == undefined ? (filter.length != 1? `Filter ${zz}` : `Filter`) : \"Pooling\"));\n",
              "            if(group_func != undefined)\n",
              "                f[0].g.selectAll(\".cell text\").attr(\"fill\", \"white\")\n",
              "\n",
              "            console.log(\"res\", res)\n",
              "            r = new Matrix((2+(matrix[0][0].length)+1)*box_s, (1+filter[0][0].length+1.5)*box_s, res, \"Result\");\n",
              "\n",
              "            var c_x = Math.max((1+(matrix[0][0].length))*box_s, (3+filter.length*(1+(filter[0][0].length)))*box_s)\n",
              "            console.log(\"m,ax\", (1+(matrix[0][0].length)), filter.length*(1+(filter[0][0].length)))\n",
              "            if(group_func != undefined)\n",
              "                c = new CalculationPool(c_x, (1+0.5)*box_s, filter[0][0], \"Calculation\");\n",
              "            else\n",
              "                c = new Calculation(c_x, (1+0.5)*box_s, filter[0][0], \"Calculation\");\n",
              "\n",
              "            last_pos = undefined;\n",
              "            if(show_single_elements)\n",
              "                index_max = filter.length*res[0].length*res[0][0].length*(filter[0][0].length * filter[0][0][0].length * filter[0].length + 2)\n",
              "            else\n",
              "                index_max = filter.length*res[0].length*res[0][0].length\n",
              "            window.index_max = index_max\n",
              "            window.filter = filter\n",
              "            setHighlights(0, 0)\n",
              "            svg.attr(\"width\", box_s*(matrix[0][0].length+res[0][0].length+4)+(c.g.node().getBoundingClientRect().width)+\"px\");\n",
              "            svg.attr(\"height\", box_s*(matrix[0].length+filter[0][0].length+3.0)+\"px\");\n",
              "        }\n",
              "        init()\n",
              "\n",
              "        function setHighlights(pos_zz, subpos) {\n",
              "            var [zz, pos] = divmod(pos_zz, res[0].length*res[0][0].length)\n",
              "            var [i, j] = divmod(pos, res[0][0].length)\n",
              "            i *= stride_y;\n",
              "            j *= stride_x;\n",
              "            var [j2, i2] = divmod(subpos, filter[0][0][0].length * filter[0].length)\n",
              "            var [i2, z2] = divmod(i2, filter[0].length)\n",
              "            subpos = Math.floor(subpos/filter[0].length)\n",
              "            console.log(zz, i, j, j2, i2, z2)\n",
              "            if(last_pos != pos || 1) {\n",
              "                var answer = 0;\n",
              "                for(var ii = 0; ii < filter[0][0].length; ii++) {\n",
              "                    for(var jj = 0; jj < filter[0][0][0].length; jj++) {\n",
              "                        var text = []\n",
              "                        if(filter[0].length == 1) {\n",
              "                            for(var z = 0; z < filter[0].length; z++) {\n",
              "                                if (group_func != undefined)\n",
              "                                    text.push(matrix[0][i + ii][j + jj] + \", \");\n",
              "                                else\n",
              "                                    text.push(matrix[z][i + ii][j + jj] + \" · \" + filter[zz][z][ii][jj]);\n",
              "                            }\n",
              "                            if (group_func != undefined)\n",
              "                                c.setText(ii * filter[0][0][0].length + jj, text.join(\", \"));\n",
              "                            else\n",
              "                                c.setText(ii * filter[0][0][0].length + jj, text.join(\"+\"));\n",
              "                        }\n",
              "                        else {\n",
              "                            let max_z = (ii == j2 && jj == i2) ? z2+1 : filter[0].length\n",
              "                            for (var z = 0; z < max_z; z++) {\n",
              "                                if (group_func != undefined)\n",
              "                                    text.push(matrix[0][i + ii][j + jj] + \", \");\n",
              "                                else\n",
              "                                    text.push(matrix[z][i + ii][j + jj] + \"·\" + filter[zz][z][ii][jj]);\n",
              "                                console.log(z, z2, text)\n",
              "                            }\n",
              "                            console.log(\"----------\")\n",
              "                            if (group_func != undefined)\n",
              "                                c.setText(ii * filter[0][0][0].length + jj, text.join(\", \"));\n",
              "                            else\n",
              "                                c.setText(ii * filter[0][0][0].length + jj, \"(\" + text.join(\"+\") + ((filter[0].length==max_z)?\")\":\"\"));\n",
              "                        }\n",
              "                    }\n",
              "                }\n",
              "                if(group_func != undefined)\n",
              "                    c.setText(filter[0][0].length * filter[0][0][0].length - 0.5, \"   ]) = \"+res[zz][i/stride_y][j/stride_x])\n",
              "                else\n",
              "                    c.setText(filter[0][0].length * filter[0][0][0].length - 0.5, \"   = \"+res[zz][i/stride_y][j/stride_x])\n",
              "                if(last_pos != pos)\n",
              "                    c.hideAll();\n",
              "                last_pos = pos;\n",
              "            }\n",
              "            m.setHighlight1(j, i, filter[0][0][0].length, filter[0][0].length)\n",
              "            for(var zzz = 0; zzz < filter.length; zzz++) {\n",
              "                console.log(zzz, zz, zzz == zz)\n",
              "                if (zzz == zz)\n",
              "                    f[zzz].setHighlight1(0, 0, filter[0][0][0].length, filter[0][0].length)\n",
              "                else\n",
              "                    f[zzz].setHighlight1(0, 0, 0, 0)\n",
              "            }\n",
              "            window.f = f\n",
              "\n",
              "            r.setHighlight1(j/stride_x, i/stride_y, 1, 1)\n",
              "            r.g.selectAll(\".matrix_layer\").attr(\"opacity\", (d,i) => i > zz ? 0.2 : 1 )\n",
              "            r.g.selectAll(\".matrix_layer .highlight1\").attr(\"visibility\", (d,i)=>i==zz ? \"visible\" : \"hidden\")\n",
              "            r.g.selectAll(\".matrix_layer .highlight3\").attr(\"visibility\", (d,i)=>i==zz ? \"visible\" : \"hidden\")\n",
              "            window.r = r\n",
              "\n",
              "            let matrixpos = (i + j2) * matrix[0][0].length + (j + i2)\n",
              "            m.g.selectAll(\".matrix_layer\").each(function(p, j){\n",
              "                console.log(d3.select(this).select(\"highlight2\"))\n",
              "                d3.select(this).selectAll(\".cell\").attr(\"opacity\", (d,i) => (i == matrixpos && j > z2 && subpos < filter[0][0].length * filter[0][0][0].length) ? 0 : 1 );\n",
              "                d3.select(this).select(\".highlight2\").style(\"stroke\", (d,i) => (j != z2) ? \"transparent\" : \"rgb(229, 132, 66)\");\n",
              "            })\n",
              "            f[zz].g.selectAll(\".matrix_layer\").each(function(p, j){\n",
              "                console.log(d3.select(this).select(\"highlight2\"), subpos, i2, j2, z2)\n",
              "                d3.select(this).selectAll(\".cell\").attr(\"opacity\", (d,i) => (i == subpos && j > z2 && subpos < filter[0][0].length * filter[0][0][0].length) ? 0 : 1 );\n",
              "                d3.select(this).select(\".highlight2\").style(\"stroke\", (d,i) => (j != z2) ? \"transparent\" : \"rgb(229, 132, 66)\");\n",
              "            })\n",
              "\n",
              "            if(subpos < filter[0][0].length * filter[0][0][0].length) {\n",
              "                m.setHighlight2(j + i2, i + j2, 1, 1)\n",
              "                if(group_func == undefined)\n",
              "                    for(var zzz = 0; zzz < filter.length; zzz++) {\n",
              "                        if (zzz == zz)\n",
              "                            f[zzz].setHighlight2(i2, j2, 1, 1)\n",
              "                        else\n",
              "                            f[zzz].hideHighlight2()\n",
              "                    }\n",
              "                r.g.selectAll(\".cell text\").attr(\"fill\", (d, i) => i >= pos_zz ? \"white\" : \"black\")\n",
              "                c.setHighlight1(subpos);\n",
              "            }\n",
              "            else {\n",
              "                m.hideHighlight2()\n",
              "                for(var zzz = 0; zzz < filter.length; zzz++)\n",
              "                    f[zzz].hideHighlight2()\n",
              "                r.g.selectAll(\".cell text\").attr(\"fill\", (d, i) => i > pos_zz ? \"white\" : \"black\")\n",
              "                if(subpos > filter[0][0].length * filter[0][0][0].length) {\n",
              "                    c.hideAll()\n",
              "                }\n",
              "                else\n",
              "                    c.setHighlight1(subpos);\n",
              "            }\n",
              "\n",
              "            function p(x) { console.log(x); return x}\n",
              "        }\n",
              "        function animate(frame) {\n",
              "            dom_target.querySelector(\"input[type=range]\").value = index;\n",
              "            dom_target.querySelector(\"input[type=range]\").max = index_max - 1;\n",
              "            dom_target.querySelector(\"input[type=range]\").min = 0;\n",
              "            if(show_single_elements) {\n",
              "                var [pos, subpos] = divmod(frame, filter[0][0].length * filter[0][0][0].length * filter[0].length + 2)\n",
              "                setHighlights(pos, subpos);\n",
              "            }\n",
              "            else\n",
              "                setHighlights(frame, filter[0][0].length * filter[0][0][0].length * filter[0].length);\n",
              "        }\n",
              "        var index = -1\n",
              "        animate(0)\n",
              "        var interval = undefined;\n",
              "\n",
              "        function PlayStep() {\n",
              "            index += 1;\n",
              "            if(index >= index_max)\n",
              "                index = 0;\n",
              "            animate(index);\n",
              "        }\n",
              "\n",
              "        function playPause() {\n",
              "            if(interval === undefined) {\n",
              "                dom_target.querySelector(\".play\").style.display = \"none\"\n",
              "                dom_target.querySelector(\".pause\").style.display = \"inline-block\"\n",
              "                interval = window.setInterval(PlayStep, 1000);\n",
              "                PlayStep();\n",
              "            }\n",
              "            else {\n",
              "                dom_target.querySelector(\".play\").style.display = \"inline-block\"\n",
              "                dom_target.querySelector(\".pause\").style.display = \"none\"\n",
              "                window.clearInterval(interval);\n",
              "                interval = undefined;\n",
              "            }\n",
              "        }\n",
              "        dom_target.querySelector(\"input[type=range]\").value = 0;\n",
              "        dom_target.querySelector(\"input[type=range]\").max = index_max;\n",
              "        dom_target.querySelector(\"input[type=range]\").onchange = (i)=>{var v = parseInt(i.target.value); index = v; animate(v);};\n",
              "        dom_target.querySelector(\".play\").onclick = playPause;\n",
              "        dom_target.querySelector(\".pause\").onclick = playPause;\n",
              "        dom_target.querySelector(\".left\").onclick = ()=>{index > 0 ? index -= 1 : index = index_max-1; animate(index);};\n",
              "        dom_target.querySelector(\".right\").onclick = ()=>{index < index_max-1 ? index += 1 : index = 0; animate(index);};\n",
              "\n",
              "        dom_target.querySelector(\".input_filterx\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_filtery\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_filterz\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_matrixx\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_matrixy\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_matrixz\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_matrixzB\").onchange = (i)=>{dom_target.querySelector(\".input_matrixz\").value = parseInt(i.target.value); init();};\n",
              "        dom_target.querySelector(\".input_paddingx\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_paddingy\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_stridex\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".input_stridey\").onchange = ()=>{init()}\n",
              "        dom_target.querySelector(\".play_fast\").onchange = ()=>{init()}\n",
              "        })();\n",
              "    </script>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown *Run this cell to enable the widget!*\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "id_html = 2\n",
        "url = f'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo{id_html}.html'\n",
        "run_demo = True  # @param {type:\"boolean\"}\n",
        "if run_demo:\n",
        "  display(HTML(url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "9bngPkqg5Q9b"
      },
      "source": [
        "#### Definitional Note\n",
        "\n",
        "\n",
        "If you have a background in signal processing or math, you may have already heard of convolution. However, the definitions in other domains and the one we use here are slightly different. The more common definition involves flipping the kernel horizontally and vertically before sliding.\n",
        "\n",
        "**For our purposes, no flipping is needed. If you are familiar with conventions involving flipping, just assume the kernel is pre-flipped.**\n",
        "\n",
        "In more general usage, the no-flip operation that we call convolution is known as _cross-correlation_ (hence the usage of `scipy.signal.correlate2d` in the next exercise). Early papers used the more common definition of convolution, but not using a flip is easier to visualize, and in fact the lack of flip does not impact a CNN's ability to learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "kkcf3I5N5Q9b"
      },
      "source": [
        "## Coding Exercise 2.1: Convolution of a Simple Kernel\n",
        "At its core, convolution is just repeatedly multiplying a matrix, known as a _kernel_ or _filter_, with some other, larger matrix (in our case the pixels of an image). Consider the below image and kernel:\n",
        "\n",
        "\\begin{align}\n",
        "\\textbf{Image} &=\n",
        "\\begin{bmatrix}0 & 200 & 200 \\\\0 & 0 & 200 \\\\ 0 & 0 & 0\n",
        "\\end{bmatrix} \\\\ \\\\\n",
        "\\textbf{Kernel} &=\n",
        "\\begin{bmatrix} \\frac{1}{4} &\\frac{1}{4} \\\\\\frac{1}{4} & \\frac{1}{4}\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Perform (by hand) the operations needed to convolve the kernel and image above. Afterwards enter your results in the \"solution\" section in the code below. Think about what this specific kernel is doing to the original image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "y0pgEluY5Q9b"
      },
      "outputs": [],
      "source": [
        "def conv_check():\n",
        "  \"\"\"\n",
        "  Demonstration of convolution operation\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    original: np.ndarray\n",
        "      Image\n",
        "    actual_convolution: np.ndarray\n",
        "      Expected convolution output\n",
        "    solution: np.ndarray\n",
        "      Obtained convolution output\n",
        "    kernel: np.ndarray\n",
        "      Kernel\n",
        "  \"\"\"\n",
        "  ####################################################################\n",
        "  # Fill in missing code below (the elements of the matrix),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Fill in the solution matrix, then delete this\")\n",
        "  ####################################################################\n",
        "  # Write the solution array and call the function to verify it!\n",
        "  solution = ...\n",
        "\n",
        "  original = np.array([\n",
        "                       [0, 200, 200],\n",
        "                       [0, 0, 200],\n",
        "                       [0, 0, 0]\n",
        "                       ])\n",
        "\n",
        "  kernel = np.array([\n",
        "                     [0.25, 0.25],\n",
        "                     [0.25, 0.25]\n",
        "                     ])\n",
        "\n",
        "  actual_convolution = scipy.signal.correlate2d(original, kernel, mode=\"valid\")\n",
        "\n",
        "  if (solution == actual_convolution).all():\n",
        "    print(\"✅ Your solution is correct!\\n\")\n",
        "  else:\n",
        "    print(\"❌ Your solution is incorrect.\\n\")\n",
        "\n",
        "  return original, kernel, actual_convolution, solution\n",
        "\n",
        "\n",
        "\n",
        "## Uncomment to test your solution!\n",
        "# original, kernel, actual_convolution, solution = conv_check()\n",
        "# make_plots(original, actual_convolution, solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NzZAG3x95Q9b"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_78a81e50.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=252.0 height=275.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_78a81e50_2.png>\n",
        "\n",
        "<img alt='Solution hint' align='left' width=273.0 height=275.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_78a81e50_3.png>\n",
        "\n",
        "<img alt='Solution hint' align='left' width=252.0 height=275.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_78a81e50_4.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "N0n4iq605Q9h",
        "outputId": "b7b1a8d0-2a98-4c84-a3e7-87870863b77c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'content_review' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3bc338381b71>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Submit your feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontent_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{feedback_prefix}_Convolution_of_a_simple_kernel_Exercise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content_review' is not defined"
          ]
        }
      ],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Convolution_of_a_simple_kernel_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4W2U1ceQ5Q9h"
      },
      "source": [
        "## Coding Exercise 2.2: Convolution Output Size\n",
        "\n",
        "Now, you have manually calculated a convolution. How did this change the shape of the output? When you know the shapes of the input matrix and kernel, what is the shape of the output?\n",
        "\n",
        "**Hint:** If you have problems figuring out what the output shape should look like, go back to the visualisation and see how the output shape changes as you modify the image and kernel size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "Bq-r77TD5Q9h"
      },
      "outputs": [],
      "source": [
        "def calculate_output_shape(image_shape, kernel_shape):\n",
        "  \"\"\"\n",
        "  Helper function to calculate output shape\n",
        "\n",
        "  Args:\n",
        "    image_shape: tuple\n",
        "      Image shape\n",
        "    kernel_shape: tuple\n",
        "      Kernel shape\n",
        "\n",
        "  Returns:\n",
        "    output_height: int\n",
        "      Output Height\n",
        "    output_width: int\n",
        "      Output Width\n",
        "  \"\"\"\n",
        "  image_height, image_width = image_shape\n",
        "  kernel_height, kernel_width = kernel_shape\n",
        "  ####################################################################\n",
        "  # Fill in missing code below, then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Fill in the lines below, then delete this\")\n",
        "  ####################################################################\n",
        "  output_height = ...\n",
        "  output_width = ...\n",
        "  return output_height, output_width\n",
        "\n",
        "\n",
        "\n",
        "# Here we check if your function works correcly by applying it to different image\n",
        "# and kernel shapes\n",
        "# check_shape_function(calculate_output_shape, image_shape=(3, 3), kernel_shape=(2, 2))\n",
        "# check_shape_function(calculate_output_shape, image_shape=(3, 4), kernel_shape=(2, 3))\n",
        "# check_shape_function(calculate_output_shape, image_shape=(5, 5), kernel_shape=(5, 5))\n",
        "# check_shape_function(calculate_output_shape, image_shape=(10, 20), kernel_shape=(3, 2))\n",
        "# check_shape_function(calculate_output_shape, image_shape=(100, 200), kernel_shape=(40, 30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Ax8tUFre5Q9h"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_7c652c63.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "1--825y35Q9h"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Convolution_output_size_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "WquLOpIX5Q9h"
      },
      "source": [
        "## Coding Exercise 2.3: Coding a Convolution\n",
        "\n",
        "Here, we have the skeleton of a function that performs convolution using the provided image and kernel matrices.\n",
        "\n",
        "*Exercise:* Fill in the missing lines of code. You can test your function by uncommenting the sections beneath it.\n",
        "\n",
        "Note: in more general situations, once you understand convolutions, you can use functions already available in `pytorch`/`numpy` to perform convolution (such as `scipy.signal.correlate2d` or `scipy.signal.convolve2d`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "iah_dwbW5Q9i"
      },
      "outputs": [],
      "source": [
        "def convolution2d(image, kernel):\n",
        "  \"\"\"\n",
        "  Convolves a 2D image matrix with a kernel matrix.\n",
        "\n",
        "  Args:\n",
        "    image: np.ndarray\n",
        "      Image\n",
        "    kernel: np.ndarray\n",
        "      Kernel\n",
        "\n",
        "  Returns:\n",
        "    output: np.ndarray\n",
        "      Output of convolution\n",
        "  \"\"\"\n",
        "\n",
        "  # Get the height/width of the image, kernel, and output\n",
        "  im_h, im_w = image.shape\n",
        "  ker_h, ker_w = kernel.shape\n",
        "  out_h = im_h - ker_h + 1\n",
        "  out_w = im_w - ker_w + 1\n",
        "\n",
        "  # Create an empty matrix in which to store the output\n",
        "  output = np.zeros((out_h, out_w))\n",
        "\n",
        "  # Iterate over the different positions at which to apply the kernel,\n",
        "  # storing the results in the output matrix\n",
        "  for out_row in range(out_h):\n",
        "    for out_col in range(out_w):\n",
        "      # Overlay the kernel on part of the image\n",
        "      # (multiply each element of the kernel with some element of the image, then sum)\n",
        "      # to determine the output of the matrix at a point\n",
        "      current_product = 0\n",
        "      for i in range(ker_h):\n",
        "        for j in range(ker_w):\n",
        "          ####################################################################\n",
        "          # Fill in missing code below (...),\n",
        "          # then remove or comment the line below to test your function\n",
        "          raise NotImplementedError(\"Implement the convolution function\")\n",
        "          ####################################################################\n",
        "          current_product += ...\n",
        "\n",
        "      output[out_row, out_col] = current_product\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "## Tests\n",
        "# First, we test the parameters we used before in the manual-calculation example\n",
        "image = np.array([[0, 200, 200], [0, 0, 200], [0, 0, 0]])\n",
        "kernel = np.array([[0.25, 0.25], [0.25, 0.25]])\n",
        "# check_conv_function(convolution2d, image, kernel)\n",
        "\n",
        "# Next, we test with a different input and kernel (the numbers 1-9 and 1-4)\n",
        "image = np.arange(9).reshape(3, 3)\n",
        "kernel = np.arange(4).reshape(2, 2)\n",
        "# check_conv_function(convolution2d, image, kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cb10-u3k5Q9i"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_4f643447.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "heMAolyI5Q9i"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Coding_a_Convolution_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "q61_AioT5Q9i"
      },
      "source": [
        "### Convolution on the Chicago Skyline\n",
        "\n",
        "After you have finished programming the above convolution function, run the coding cell below, which applies two different kernels to a greyscale picture of Chicago and takes the geometric average of the results.\n",
        "\n",
        "**Make sure you remove all print statements from your convolution2d implementation, or this will run for a _very_ long time.** It should take somewhere between 10 seconds and 1 minute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "osqAs6Nc5Q9i"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Load images (run me)\n",
        "\n",
        "import requests, os\n",
        "\n",
        "if not os.path.exists('images/'):\n",
        "  os.mkdir('images/')\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/chicago_skyline_shrunk_v2.bmp\"\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(\"images/chicago_skyline_shrunk_v2.bmp\", 'wb') as fd:\n",
        "  fd.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dvB-Ss9T5Q9i",
        "outputId": "6cc13ea0-962e-4972-9572-b3922f07a783"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'images/chicago_skyline_shrunk_v2.bmp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8ee536db8820>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mIPydisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/chicago_skyline_shrunk_v2.bmp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskyline_image_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mimg_skyline_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskyline_image_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mimg_skyline_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_skyline_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/chicago_skyline_shrunk_v2.bmp'"
          ]
        }
      ],
      "source": [
        "# Visualize the output of your function\n",
        "from IPython.display import display as IPydisplay\n",
        "\n",
        "with open(\"images/chicago_skyline_shrunk_v2.bmp\", 'rb') as skyline_image_file:\n",
        "  img_skyline_orig = Image.open(skyline_image_file)\n",
        "  img_skyline_mat = np.asarray(img_skyline_orig)\n",
        "  kernel_ver = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "  kernel_hor = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).T\n",
        "  img_processed_mat_ver = convolution2d(img_skyline_mat, kernel_ver)\n",
        "  img_processed_mat_hor = convolution2d(img_skyline_mat, kernel_hor)\n",
        "  img_processed_mat = np.sqrt(np.multiply(img_processed_mat_ver,\n",
        "                                          img_processed_mat_ver) + \\\n",
        "                              np.multiply(img_processed_mat_hor,\n",
        "                                          img_processed_mat_hor))\n",
        "\n",
        "  img_processed_mat *= 255.0/img_processed_mat.max()\n",
        "  img_processed_mat = img_processed_mat.astype(np.uint8)\n",
        "  img_processed = Image.fromarray(img_processed_mat, 'L')\n",
        "  width, height = img_skyline_orig.size\n",
        "  scale = 0.6\n",
        "  IPydisplay(img_skyline_orig.resize((int(width*scale), int(height*scale))),\n",
        "             Image.NEAREST)\n",
        "  IPydisplay(img_processed.resize((int(width*scale), int(height*scale))),\n",
        "             Image.NEAREST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "o3J1CbvT5Q9i"
      },
      "source": [
        "Pretty cool, right? We will go into more detail on what's happening in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TF9E1E3R5Q9j"
      },
      "source": [
        "## Section 2.1: Demonstration of a CNN in PyTorch\n",
        "At this point, you should have a fair idea of how to perform a convolution on an image given a kernel. In the following cell, we provide a code snippet that demonstrates setting up a convolutional network using PyTorch.\n",
        "\n",
        "We look at the `nn` module in PyTorch. The `nn` module contains a plethora of functions that will make implementing a neural network easier. In particular we will look at the `nn.Conv2d()` function, which creates a convolutional layer that is applied to whatever image that you feed the resulting network.\n",
        "\n",
        "Look at the code below. In it, we define a `Net` class that you can instantiate with a kernel to create a Neural Network object. When you apply the network object to an image (or anything in the form of a matrix), it convolves the kernel over that image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {},
        "id": "hHuRAig65Q9j"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"\n",
        "  A convolutional neural network class.\n",
        "  When an instance of it is constructed with a kernel, you can apply that instance\n",
        "    to a matrix and it will convolve the kernel over that image.\n",
        "  i.e. Net(kernel)(image)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, kernel=None, padding=0):\n",
        "    super(Net, self).__init__()\n",
        "    \"\"\"\n",
        "    Summary of the nn.conv2d parameters (you can also get this by hovering\n",
        "    over the method):\n",
        "    - in_channels (int): Number of channels in the input image\n",
        "    - out_channels (int): Number of channels produced by the convolution\n",
        "    - kernel_size (int or tuple): Size of the convolving kernel\n",
        "\n",
        "    Args:\n",
        "      padding: int or tuple, optional\n",
        "        Zero-padding added to both sides of the input. Default: 0\n",
        "      kernel: np.ndarray\n",
        "        Convolving kernel. Default: None\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2,\n",
        "                           padding=padding)\n",
        "\n",
        "    # Set up a default kernel if a default one isn't provided\n",
        "    if kernel is not None:\n",
        "      dim1, dim2 = kernel.shape[0], kernel.shape[1]\n",
        "      kernel = kernel.reshape(1, 1, dim1, dim2)\n",
        "\n",
        "      self.conv1.weight = torch.nn.Parameter(kernel)\n",
        "      self.conv1.bias = torch.nn.Parameter(torch.zeros_like(self.conv1.bias))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward Pass of nn.conv2d\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Convolution output\n",
        "    \"\"\"\n",
        "    x = self.conv1(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8SZlpri5Q9j",
        "outputId": "1b5d7246-b931-479a-9b88-861b41e42fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image:\n",
            "tensor([[[[0., 1., 2.],\n",
            "          [3., 4., 5.],\n",
            "          [6., 7., 8.]]]])\n",
            "Kernel:\n",
            "tensor([[0., 1.],\n",
            "        [2., 3.]])\n",
            "Output:\n",
            "tensor([[[[19., 25.],\n",
            "          [37., 43.]]]], grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Format a default 2x2 kernel of numbers from 0 through 3\n",
        "kernel = torch.Tensor(np.arange(4).reshape(2, 2))\n",
        "\n",
        "# Prepare the network with that default kernel\n",
        "net = Net(kernel=kernel, padding=0).to(DEVICE)\n",
        "\n",
        "# Set up a 3x3 image matrix of numbers from 0 through 8\n",
        "image = torch.Tensor(np.arange(9).reshape(3, 3))\n",
        "image = image.reshape(1, 1, 3, 3).to(DEVICE)  # BatchSize X Channels X Height X Width\n",
        "\n",
        "print(\"Image:\\n\" + str(image))\n",
        "print(\"Kernel:\\n\" + str(kernel))\n",
        "output = net(image)  # Apply the convolution\n",
        "print(\"Output:\\n\" + str(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "aZ3jppgv5Q9j"
      },
      "source": [
        "As a quick aside, notice the difference in the input and output size. The input had a size of 3×3, and the output is of size 2×2. This is because of the fact that the kernel can't produce values for the edges of the image - when it slides to an end of the image and is centered on a border pixel, it overlaps space outside of the image that is undefined. If we don't want to lose that information, we will have to pad the image with some defaults (such as 0s) on the border. This process is, somewhat predictably, called *padding*. We will talk more about padding in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "3hqWsTRC5Q9j"
      },
      "outputs": [],
      "source": [
        "print(\"Image (before padding):\\n\" + str(image))\n",
        "print(\"Kernel:\\n\" + str(kernel))\n",
        "\n",
        "# Prepare the network with the aforementioned default kernel, but this\n",
        "# time with padding\n",
        "net = Net(kernel=kernel, padding=1).to(DEVICE)\n",
        "output = net(image)  # Apply the convolution onto the padded image\n",
        "print(\"Output:\\n\" + str(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Vtb3lFeI5Q9j"
      },
      "source": [
        "## Section 2.2: Padding and Edge Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-ENixnBp5Q9k"
      },
      "source": [
        "Before we start in on the exercises, here's a visualization to help you think about padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "wOgV2atf5Q9k"
      },
      "source": [
        "### Interactive Demo 2.2: Visualization of Convolution with Padding and Stride\n",
        "\n",
        "\n",
        "Recall that\n",
        "* Padding adds rows and columns of zeros to the outside edge of an image\n",
        "* Stride length adjusts the distance by which a filter is shifted after each convolution.\n",
        "\n",
        "Change the padding and stride and see how this affects the shape of the output. How does the padding need to be configured to maintain the shape of the input?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "E3IHaOJy5Q9k"
      },
      "source": [
        "**Important:** Change the bool variable `run_demo` to `True` by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "GQ8M-NyS5Q9k",
        "outputId": "8f1f686c-e082-467e-f129-5f4545f0a623"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "  <style>\n",
              "    svg {\n",
              "        #border: 1px solid black;\n",
              "    }\n",
              "    .matrix {\n",
              "        font-family: sans-serif;\n",
              "        transition: all 700ms ease-in-out;\n",
              "    }\n",
              "    .cell rect {\n",
              "        fill:white;stroke-width:1;stroke:rgb(0,0,0)\n",
              "    }\n",
              "    .padding rect {\n",
              "        stroke: rgba(0, 0, 0, 0.25);\n",
              "    }\n",
              "    .padding text {\n",
              "        fill: lightgray;\n",
              "    }\n",
              "    .highlight1 {\n",
              "        fill:none;stroke-width:4;stroke: rgb(236, 58, 58);stroke-dasharray:10,5;\n",
              "    }\n",
              "    .highlight2 {\n",
              "        fill:rgba(229, 132, 66, 0.25);stroke-width:5;stroke: rgb(229, 132, 66);\n",
              "    }\n",
              "    .highlight3 {\n",
              "        fill:rgba(236, 58, 58, 0.25);stroke-width:2;stroke: rgb(236, 58, 58);;\n",
              "    }\n",
              "    .title {\n",
              "        text-anchor: middle;\n",
              "    }\n",
              "    .button_play {\n",
              "        display: inline-block;\n",
              "        background: none;\n",
              "        border: none;\n",
              "        position: relative;\n",
              "        top: -3px;\n",
              "    }\n",
              "    .button_play path {\n",
              "        fill: darkgray;\n",
              "    }\n",
              "    .button_play:hover path {\n",
              "        fill: rgb(236, 58, 58);\n",
              "    }\n",
              "    .display_vis_input input:not(:hover)::-webkit-outer-spin-button,\n",
              "    .display_vis_input input:not(:hover)::-webkit-inner-spin-button {\n",
              "        -webkit-appearance: none;\n",
              "        margin: 0;\n",
              "    }\n",
              "\n",
              "    .display_vis_input input:not(:hover)[type=number] {\n",
              "        -moz-appearance:textfield;\n",
              "        width: 1ch;\n",
              "        margin-right: 0px;\n",
              "        z-index: 0;\n",
              "    }\n",
              "    .display_vis_input input[type=number] {\n",
              "        width: 4ch;\n",
              "        border: 0px;\n",
              "        margin-right: -3ch;\n",
              "        z-index: 6;\n",
              "        display: inline-block;\n",
              "        position: relative;\n",
              "        padding: 0;\n",
              "        border-bottom: 2px solid red;\n",
              "        background: white;\n",
              "        color: black\n",
              "    }\n",
              "    .display_vis_input .pair {\n",
              "        display: inline-block;\n",
              "        white-space:nowrap;\n",
              "            position: relative;\n",
              "    }\n",
              "    .display_vis_input .pair .pair_hide {\n",
              "        max-width: 4em;\n",
              "        transition: max-width 1s ease-in;\n",
              "        display: inline-block;\n",
              "        overflow: hidden;\n",
              "        position: relative;\n",
              "        top: 5px;\n",
              "    }\n",
              "    .pair:not(:hover) .pair_hide {\n",
              "        max-width: 0;\n",
              "    }\n",
              "    .pairX .pair_hide {\n",
              "        max-width: 4em;\n",
              "        transition: max-width 1s ease-in;\n",
              "    }\n",
              "\n",
              "    /* Dropdown Button */\n",
              "    .dropbtn {\n",
              "      border-bottom: 2px solid red;\n",
              "    }\n",
              "\n",
              "    /* The container <div> - needed to position the dropdown content */\n",
              "    .dropdown {\n",
              "      position: relative;\n",
              "      display: inline-block;\n",
              "    }\n",
              "\n",
              "    /* Dropdown Content (Hidden by Default) */\n",
              "    .dropdown-content {\n",
              "      display: none;\n",
              "      position: absolute;\n",
              "      background-color: #f1f1f1;\n",
              "      min-width: 160px;\n",
              "      box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);\n",
              "      z-index: 1;\n",
              "    }\n",
              "\n",
              "    /* Links inside the dropdown */\n",
              "    .dropdown-content a {\n",
              "      color: black;\n",
              "      padding: 5px 2px;\n",
              "      text-decoration: none;\n",
              "      display: block;\n",
              "    }\n",
              "\n",
              "    /* Change color of dropdown links on hover */\n",
              "    .dropdown-content a:hover {background-color: #ddd;}\n",
              "\n",
              "    /* Show the dropdown menu on hover */\n",
              "    .dropdown:hover .dropdown-content {display: block;}\n",
              "  </style>\n",
              "\n",
              "  <script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\" > </script>\n",
              "\n",
              "\n",
              "  <div id=\"animation_conv_padding\" style=\"background: white\">\n",
              "    <div class=\"display_vis_input language-python\" style=\"font-family: monospace; color: black; padding: 10px;\">\n",
              "        <!-- padding -->\n",
              "        import torch<br><br>\n",
              "        input = torch.rand(1, 1<input class=\"input_matrixz\" type=\"hidden\" min=\"1\" max=\"3\" value=\"1\">, <input class=\"input_matrixx\" type=\"number\" min=\"3\" max=\"5\" value=\"4\">, <input class=\"input_matrixy\" type=\"number\" min=\"3\" max=\"5\" value=\"4\">)<br>\n",
              "        conv = torch.nn.Conv2d(in_channels=1<input class=\"input_matrixzB\" type=\"hidden\" min=\"1\" max=\"3\" value=\"1\">, out_channels=1<input class=\"input_filterz\" type=\"hidden\" min=\"1\" max=\"3\" value=\"1\">,\n",
              "        kernel_size=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_filterx\" type=\"number\" min=\"2\" max=\"4\" value=\"3\"><span class=\"pair_hide\">,\n",
              "                                                                        <input class=\"input_filtery\" type=\"number\" min=\"2\" max=\"4\" value=\"3\">)</span></span>,\n",
              "        stride=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_stridex\" type=\"number\" min=\"1\" max=\"2\" value=\"1\"><span class=\"pair_hide\">,\n",
              "                                                                  <input class=\"input_stridey\" type=\"number\" min=\"1\" max=\"2\" value=\"1\">)</span></span>,\n",
              "        padding=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_paddingx\" type=\"number\" min=\"0\" max=\"4\" value=\"1\"><span class=\"pair_hide\">,\n",
              "                                                                    <input class=\"input_paddingy\" type=\"number\" min=\"0\" max=\"4\" value=\"1\">)</span></span>)<br>\n",
              "        result = conv(input)\n",
              "    </div>\n",
              "    <button class=\"button_play play\"><svg width=\"15\" height=\"15\" viewbox=\"0 0 10 10\"><path d=\"M 1.5,0 9.5,5 1.5,10 z\"/></svg></button>\n",
              "    <button class=\"button_play pause\" style=\"display: none\"><svg width=\"15\" height=\"15\" viewbox=\"0 0 10 10\"><path d=\"M 0,0 4,0 4,10, 0,10 z\"/><path d=\"M 6,0 10,0 10,10, 6,10 z\"/></svg></button>\n",
              "    <input type=\"range\" min=\"1\" max=\"100\" value=\"50\" class=\"slider\" style=\"width: 300px; display: inline-block\">\n",
              "    <button class=\"button_play left\"><svg width=\"7\" height=\"15\" viewbox=\"0 0 4 10\"><path d=\"M 0,5 4,0 4,10 z\"/></svg></button>\n",
              "    <button class=\"button_play right\"><svg width=\"7\" height=\"15\" viewbox=\"0 0 4 10\"><path d=\"M 0,0 4,5 0,10 z\"/></svg></button>\n",
              "    <input type=\"checkbox\" class=\"play_fast\">fast play mode\n",
              "    <br/>\n",
              "    <svg height=\"0\" width=\"0\">\n",
              "      <defs>\n",
              "      <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\"\n",
              "      refX=\"0\" refY=\"1.5\" orient=\"auto\" fill=\"rgb(236, 58, 58)\">\n",
              "      <polygon points=\"0 0, 4 1.5, 0 3\" />\n",
              "      </marker>\n",
              "      </defs>\n",
              "    </svg>\n",
              "    <svg class=\"image\" height=\"460\" width=\"600\"></svg>\n",
              "  </div>\n",
              "\n",
              "  <script>\n",
              "    (function() {\n",
              "    var dom_target = document.getElementById(\"animation_conv_padding\")\n",
              "    const divmod = (x, y) => [Math.floor(x / y), x % y];\n",
              "    var svg = d3.select(dom_target).select(\".image\")\n",
              "\n",
              "    var box_s = 50;\n",
              "    var box_z = 10;\n",
              "    var show_single_elements = true;\n",
              "    var group_func = undefined;\n",
              "    function mulberry32(a) {\n",
              "        return function() {\n",
              "          var t = a += 0x6D2B79F5;\n",
              "          t = Math.imul(t ^ t >>> 15, t | 1);\n",
              "          t ^= t + Math.imul(t ^ t >>> 7, t | 61);\n",
              "          return ((t ^ t >>> 14) >>> 0) / 4294967296;\n",
              "        }\n",
              "    }\n",
              "\n",
              "    function numberGenerator(seed, max, digits) {\n",
              "        var random = mulberry32(seed)\n",
              "        return () => parseFloat((random() * max).toFixed(digits));\n",
              "    }\n",
              "    window.numberGenerator = numberGenerator\n",
              "    window.mulberry32 = mulberry32\n",
              "    function generateMatrix2(number, dims) {\n",
              "        var res = [];\n",
              "        for (var i = 0; i < dims[0]; i++) {\n",
              "            if(dims.length == 1)\n",
              "                res.push(number())\n",
              "            else\n",
              "                res.push(generateMatrix2(number, dims.slice(1)));\n",
              "        }\n",
              "        return res\n",
              "    }\n",
              "    window.generateMatrix2 = generateMatrix2\n",
              "\n",
              "    function addPadding(matrix, paddingx, paddingy) {\n",
              "        matrix = JSON.parse(JSON.stringify(matrix));\n",
              "        var ly = matrix.length; var lx = matrix[0].length;\n",
              "        for (var i = 0; i < ly; i++) {\n",
              "            for(var p = 0; p < paddingx; p++) {\n",
              "                matrix[i].splice(0, 0, 0);\n",
              "                matrix[i].splice(matrix[i].length, 0, 0);\n",
              "            }\n",
              "        }\n",
              "        for(var p = 0; p < paddingy; p++) {\n",
              "            matrix.splice(0, 0, []);\n",
              "            matrix.splice(matrix.length, 0, []);\n",
              "            for (var i = 0; i < lx + paddingx * 2; i++) {\n",
              "                matrix[0].push(0);\n",
              "                matrix[matrix.length - 1].push(0);\n",
              "            }\n",
              "        }\n",
              "        matrix.paddingx = paddingx;\n",
              "        matrix.paddingy = paddingy;\n",
              "        return matrix;\n",
              "    }\n",
              "\n",
              "    var stride_x = 1;\n",
              "    var stride_y = 1;\n",
              "    function convolve(matrix, filter) {\n",
              "        var ress = [];\n",
              "        for(var zz = 0; zz < filter.length; zz++) {\n",
              "            var res = [];\n",
              "            for (var i = 0; i < parseInt((matrix[0].length - filter[0][0].length + stride_y) / stride_y); i++) {\n",
              "                res.push([]);\n",
              "                for (var j = 0; j < parseInt((matrix[0][0].length - filter[0][0][0].length + stride_x) / stride_x); j++) {\n",
              "                    var answer = 0;\n",
              "                    var text = \"\";\n",
              "                    for (var ii = 0; ii < filter[0][0].length; ii++) {\n",
              "                        for (var jj = 0; jj < filter[0][0][0].length; jj++) {\n",
              "                            for (var z = 0; z < matrix.length; z++) {\n",
              "                                answer += matrix[z][i * stride_y + ii][j * stride_x + jj] * filter[zz][z][ii][jj];\n",
              "                                text +=matrix[z][i * stride_y + ii][j * stride_x + jj] + \"*\" + filter[zz][z][ii][jj]+\"+\";\n",
              "                            }\n",
              "                        }\n",
              "                    }\n",
              "                    console.log(i, j, text, \"=\", answer)\n",
              "                    res[res.length - 1].push(answer.toFixed(1))\n",
              "                }\n",
              "            }\n",
              "            ress.push(res)\n",
              "        }\n",
              "        return ress;\n",
              "    }\n",
              "    function pool(matrix, filter, func) {\n",
              "        var res = [];\n",
              "        for (var i = 0; i < parseInt((matrix.length - filter.length + stride_y) / stride_y); i++) {\n",
              "            res.push([]);\n",
              "            for (var j = 0; j < parseInt((matrix[0].length - filter[0].length + stride_x) / stride_x); j++) {\n",
              "                var answer = [];\n",
              "                for(var ii = 0; ii < filter.length; ii++) {\n",
              "                    for(var jj = 0; jj < filter[0].length; jj++) {\n",
              "                        answer.push(matrix[i* stride_y + ii][j* stride_x + jj]);\n",
              "                    }\n",
              "                }\n",
              "                if(func == \"max\")\n",
              "                    res[res.length-1].push(Math.max(...answer))\n",
              "                else {\n",
              "                    var sum = 0;\n",
              "                    for( var ii = 0; ii < answer.length; ii++)\n",
              "                        sum += answer[ii]; //don't forget to add the base\n",
              "                    var avg = sum/answer.length;\n",
              "                    res[res.length-1].push(parseFloat(avg.toFixed(1)));\n",
              "                }\n",
              "\n",
              "            }\n",
              "        }\n",
              "        return res;\n",
              "    }\n",
              "\n",
              "    class Matrix {\n",
              "        constructor(x, y, matrix, title) {\n",
              "            this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`);\n",
              "            for(var z = 0; z < matrix.length; z++) {\n",
              "                var gg = this.g.append(\"g\").attr(\"class\", \"matrix_layer\").attr(\"transform\", `translate(${- z*box_z}, ${+ z*box_z})`);\n",
              "                for (var j = 0; j < matrix[0].length; j++) {\n",
              "                    for (var i = 0; i < matrix[0][0].length; i++) {\n",
              "                        var element = gg.append(\"g\").attr(\"class\", \"cell\").attr(\"transform\", `translate(${i * box_s}, ${j * box_s})`);\n",
              "                        var rect = element.append(\"rect\")\n",
              "                            .attr(\"class\", \"number\")\n",
              "                            .attr(\"x\", -box_s / 2 + \"px\")\n",
              "                            .attr(\"y\", -box_s / 2 + \"px\")\n",
              "                            .attr(\"width\", box_s + \"px\")\n",
              "                            .attr(\"height\", box_s + \"px\")\n",
              "                        if (i < matrix.paddingx || j < matrix.paddingy || i > matrix[0][0].length - matrix.paddingx - 1 || j > matrix[0].length - matrix.paddingy - 1)\n",
              "                            element.attr(\"class\", \"cell padding\")\n",
              "                        element.append(\"text\").text(matrix[z][j][i]).attr(\"text-anchor\", \"middle\").attr(\"alignment-baseline\", \"center\").attr(\"dy\", \"0.3em\")\n",
              "                    }\n",
              "                }\n",
              "                gg.append(\"rect\").attr(\"class\", \"highlight3\")\n",
              "                gg.append(\"rect\").attr(\"class\", \"highlight1\")\n",
              "                gg.append(\"rect\").attr(\"class\", \"highlight2\")\n",
              "            }\n",
              "            this.arrow = gg.append(\"line\").attr(\"transform\", `translate(${(-0.5)*box_s}, ${(-0.5+filter.length/2)*box_s})`).attr(\"marker-end\", \"url(#arrowhead)\").attr(\"x1\", 0).attr(\"y1\", 0).attr(\"x2\", 50).attr(\"y2\", 0)\n",
              "                .attr(\"stroke\", \"#000\").attr(\"stroke-width\", 8).attr(\"stroke\", \"rgb(236, 58, 58)\").style(\"opacity\", 0)\n",
              "\n",
              "\n",
              "            gg.append(\"text\").attr(\"class\", \"title\").text(title)\n",
              "                .attr(\"x\", (matrix[0][0].length/2-0.5)*box_s+\"px\")\n",
              "                .attr(\"y\", (matrix[0].length)*box_s+\"px\")\n",
              "                .attr(\"dy\", \"0em\")\n",
              "            this.highlight2_hidden = true\n",
              "        }\n",
              "\n",
              "        setHighlight1(i, j, w, h) {\n",
              "            if(this.old_i == i && this.old_j == j && this.old_w == w)\n",
              "                return\n",
              "            if(i == this.old_i+stride_x || j == this.old_j+stride_y) {\n",
              "                if (this.old_j == j)\n",
              "                    this.arrow.attr(\"x1\", this.old_i * box_s).attr(\"y1\", j * box_s)\n",
              "                        .attr(\"x2\", i * box_s - 30).attr(\"y2\", j * box_s).attr(\"transform\", `translate(${(-0.5) * box_s}, ${(-0.5 + h / 2) * box_s})`)\n",
              "                else\n",
              "                    this.arrow.attr(\"x1\", i * box_s).attr(\"y1\", this.old_j * box_s)\n",
              "                        .attr(\"x2\", i * box_s).attr(\"y2\", j * box_s - 30).attr(\"transform\", `translate(${(-0.5 + w / 2) * box_s}, ${(-0.5) * box_s})`)\n",
              "                this.arrow.transition().style(\"opacity\", 1)\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .style(\"opacity\", 0)\n",
              "            }\n",
              "            this.old_i = i; this.old_j = j; this.old_w = w;\n",
              "            this.g.selectAll(\".highlight1\")\n",
              "                .style(\"fill\", \"rgba(236, 58, 58, 0)\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\")\n",
              "                .style(\"fill\", \"rgba(236, 58, 58, 0.25)\")\n",
              "            this.g.selectAll(\".highlight3\")\n",
              "                .style(\"opacity\", 1)\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .style(\"opacity\", 0)\n",
              "            this.g.selectAll(\".highlight3\")\n",
              "                .transition()\n",
              "                .delay(900)\n",
              "                .duration(0)\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\")\n",
              "        }\n",
              "\n",
              "        setHighlight2(i, j, w, h) {\n",
              "            if(this.highlight2_hidden == true) {\n",
              "                this.g.selectAll(\".highlight2\")\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .style(\"opacity\", 1)\n",
              "                this.highlight2_hidden = false\n",
              "                return\n",
              "            }\n",
              "            this.g.selectAll(\".highlight2\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\");\n",
              "        }\n",
              "        hideHighlight2() {\n",
              "            this.highlight2_hidden = true\n",
              "            this.g.selectAll(\".highlight2\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .style(\"opacity\", 0)\n",
              "        }\n",
              "    }\n",
              "\n",
              "    class Calculation {\n",
              "        constructor(x, y, matrix, title) {\n",
              "            this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`)\n",
              "            this.g.append(\"text\").text(title).attr(\"dy\", \"-1.5em\").attr(\"dx\", \"2em\")\n",
              "            this.g = this.g.append(\"text\")\n",
              "            for (var j in matrix) {\n",
              "                for (var i in matrix[j]) {\n",
              "                    var element = this.g;\n",
              "                    var a = element.append(\"tspan\")\n",
              "                        .text(i+\"·\"+j)\n",
              "                    if(i == 0 && j > 0)\n",
              "                        a.attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                    if(i == matrix[0].length - 1 && j == matrix.length - 1) {\n",
              "                        a = element.append(\"tspan\")\n",
              "                        .attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                        .text(\" = 12 \")\n",
              "                    }\n",
              "                    else {\n",
              "                        a = element.append(\"tspan\")\n",
              "                            .text(\" + \")\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "        setText(i, text) {\n",
              "            d3.select(this.g.selectAll(\"tspan\")[0][i*2]).text(text)\n",
              "        }\n",
              "        hideAll() {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .attr(\"fill\", \"white\")\n",
              "        }\n",
              "        setHighlight1(i) {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"fill\",\n",
              "                (d, ii) => ii==i*2 ? \"rgb(229, 132, 66)\" : ii> i*2 ? \"white\" : \"black\")\n",
              "\n",
              "        }\n",
              "    }\n",
              "\n",
              "    class CalculationPool {\n",
              "        constructor(x, y, matrix, title) {\n",
              "            this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`)\n",
              "            this.g.append(\"text\").text(title).attr(\"dy\", \"-3em\").attr(\"dx\", \"-2em\")\n",
              "            this.g.append(\"text\").text(group_func+\"([\").attr(\"dy\", \"-1.5em\").attr(\"dx\", \"-0.5em\")\n",
              "            this.g = this.g.append(\"text\")\n",
              "            for (var j in matrix) {\n",
              "                for (var i in matrix[j]) {\n",
              "                    var element = this.g;\n",
              "                    var a = element.append(\"tspan\")\n",
              "                        .text(\"\")\n",
              "                    if(i == 0 && j > 0)\n",
              "                        a.attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                    if(i == matrix[0].length - 1 && j == matrix.length - 1) {\n",
              "                        a = element.append(\"tspan\")\n",
              "                        .attr(\"dy\", \"1.5em\").attr(\"x\", 0).attr(\"dx\", \"-0.5em\")\n",
              "                        .text(\"\")\n",
              "                    }\n",
              "                    else {\n",
              "                        a = element.append(\"tspan\")\n",
              "                            .text(\"\")\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "        setText(i, text) {\n",
              "            d3.select(this.g.selectAll(\"tspan\")[0][i*2]).text(text)\n",
              "        }\n",
              "        hideAll() {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .attr(\"fill\", \"white\")\n",
              "        }\n",
              "        setHighlight1(i) {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"fill\",\n",
              "                (d, ii) => ii==i*2 ? \"rgb(229, 132, 66)\" : ii> i*2 ? \"white\" : \"black\")\n",
              "\n",
              "        }\n",
              "    }\n",
              "\n",
              "    var matrix, res, m, f, r, c, last_pos, index_max;\n",
              "    function init() {\n",
              "        show_single_elements = dom_target.querySelector(\".play_fast\").checked == false\n",
              "\n",
              "        svg.selectAll(\"*\").remove();\n",
              "\n",
              "        dom_target.querySelector(\".input_matrixzB\").value = dom_target.querySelector(\".input_matrixz\").value\n",
              "\n",
              "        console.log(\"dom_target\", dom_target)\n",
              "        console.log(\"dom_target.querySelector(\\\".input_filterx\\\").value)\", dom_target.querySelector(\".input_filterx\").value)\n",
              "        filter = generateMatrix2(numberGenerator(17, 0.9, 1), [parseInt(dom_target.querySelector(\".input_filterz\").value), parseInt(dom_target.querySelector(\".input_matrixz\").value), parseInt(dom_target.querySelector(\".input_filtery\").value), parseInt(dom_target.querySelector(\".input_filterx\").value)]);\n",
              "        if(dom_target.querySelector(\".input_filterx\").value == dom_target.querySelector(\".input_filtery\").value)\n",
              "            dom_target.querySelector(\".input_filterx\").parentElement.className = \"pair\"\n",
              "        else\n",
              "            dom_target.querySelector(\".input_filterx\").parentElement.className = \"pairX\"\n",
              "        matrix_raw = generateMatrix2(numberGenerator(4, 9, 0), [parseInt(dom_target.querySelector(\".input_matrixz\").value), parseInt(dom_target.querySelector(\".input_matrixy\").value), parseInt(dom_target.querySelector(\".input_matrixx\").value)]);\n",
              "\n",
              "        matrix = JSON.parse(JSON.stringify(matrix_raw));\n",
              "        for(var z = 0; z < matrix.length; z++)\n",
              "            matrix[z] = addPadding(matrix_raw[z], parseInt(dom_target.querySelector(\".input_paddingx\").value), parseInt(dom_target.querySelector(\".input_paddingy\").value));\n",
              "        matrix.paddingx = matrix[0].paddingx\n",
              "        matrix.paddingy = matrix[0].paddingy\n",
              "        stride_x = parseInt(dom_target.querySelector(\".input_stridex\").value)\n",
              "        stride_y = parseInt(dom_target.querySelector(\".input_stridey\").value)\n",
              "\n",
              "        if(dom_target.querySelector(\".input_stridex\").value == dom_target.querySelector(\".input_stridey\").value)\n",
              "            dom_target.querySelector(\".input_stridex\").parentElement.className = \"pair\"\n",
              "        else\n",
              "            dom_target.querySelector(\".input_stridex\").parentElement.className = \"pairX\"\n",
              "            if(dom_target.querySelector(\".input_paddingx\").value == dom_target.querySelector(\".input_paddingy\").value)\n",
              "            dom_target.querySelector(\".input_paddingx\").parentElement.className = \"pair\"\n",
              "        else\n",
              "            dom_target.querySelector(\".input_paddingx\").parentElement.className = \"pairX\"\n",
              "\n",
              "        res = convolve(matrix, filter);\n",
              "            window.matrix = matrix\n",
              "            window.filter = filter\n",
              "            window.res = res\n",
              "        if(group_func != undefined)\n",
              "            res = [pool(matrix[0], filter[0][0], group_func)]\n",
              "\n",
              "        m = new Matrix(1*box_s, (1+filter[0][0].length+1.5)*box_s, matrix, \"Matrix\");\n",
              "\n",
              "        f = []\n",
              "        for(var zz = 0; zz < filter.length; zz++)\n",
              "            f.push(new Matrix((1+(matrix[0][0].length-filter[zz][0][0].length)/2 + zz*(1+filter[zz][0][0].length))*box_s, 1*box_s, filter[zz], group_func == undefined ? (filter.length != 1? `Filter ${zz}` : `Filter`) : \"Pooling\"));\n",
              "        if(group_func != undefined)\n",
              "            f[0].g.selectAll(\".cell text\").attr(\"fill\", \"white\")\n",
              "\n",
              "        console.log(\"res\", res)\n",
              "        r = new Matrix((2+(matrix[0][0].length)+1)*box_s, (1+filter[0][0].length+1.5)*box_s, res, \"Result\");\n",
              "\n",
              "        var c_x = Math.max((1+(matrix[0][0].length))*box_s, (3+filter.length*(1+(filter[0][0].length)))*box_s)\n",
              "        console.log(\"m,ax\", (1+(matrix[0][0].length)), filter.length*(1+(filter[0][0].length)))\n",
              "        if(group_func != undefined)\n",
              "            c = new CalculationPool(c_x, (1+0.5)*box_s, filter[0][0], \"Calculation\");\n",
              "        else\n",
              "            c = new Calculation(c_x, (1+0.5)*box_s, filter[0][0], \"Calculation\");\n",
              "\n",
              "        last_pos = undefined;\n",
              "        if(show_single_elements)\n",
              "            index_max = filter.length*res[0].length*res[0][0].length*(filter[0][0].length * filter[0][0][0].length + 2)\n",
              "        else\n",
              "            index_max = filter.length*res[0].length*res[0][0].length\n",
              "        window.index_max = index_max\n",
              "        window.filter = filter\n",
              "        setHighlights(0, 0)\n",
              "        svg.attr(\"width\", box_s*(matrix[0][0].length+res[0][0].length+4)+(c.g.node().getBoundingClientRect().width)+\"px\");\n",
              "        svg.attr(\"height\", box_s*(matrix[0].length+filter[0][0].length+3.0)+\"px\");\n",
              "    }\n",
              "    init()\n",
              "\n",
              "    function setHighlights(pos_zz, subpos) {\n",
              "        var [zz, pos] = divmod(pos_zz, res[0].length*res[0][0].length)\n",
              "        var [i, j] = divmod(pos, res[0][0].length)\n",
              "        i *= stride_y;\n",
              "        j *= stride_x;\n",
              "        var [j2, i2] = divmod(subpos, filter[0][0][0].length)\n",
              "        if(last_pos != pos) {\n",
              "            var answer = 0;\n",
              "            for(var ii = 0; ii < filter[0][0].length; ii++) {\n",
              "                for(var jj = 0; jj < filter[0][0][0].length; jj++) {\n",
              "                    var text = []\n",
              "                    if(filter[0].length == 1) {\n",
              "                        for(var z = 0; z < filter[0].length; z++) {\n",
              "                            if (group_func != undefined)\n",
              "                                text.push(matrix[0][i + ii][j + jj] + \", \");\n",
              "                            else\n",
              "                                text.push(matrix[z][i + ii][j + jj] + \" · \" + filter[zz][z][ii][jj]);\n",
              "                        }\n",
              "                        if (group_func != undefined)\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, text.join(\", \"));\n",
              "                        else\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, text.join(\"+\"));\n",
              "                    }\n",
              "                    else {\n",
              "                        for (var z = 0; z < filter[0].length; z++) {\n",
              "                            if (group_func != undefined)\n",
              "                                text.push(matrix[0][i + ii][j + jj] + \", \");\n",
              "                            else\n",
              "                                text.push(matrix[z][i + ii][j + jj] + \"·\" + filter[zz][z][ii][jj]);\n",
              "                        }\n",
              "                        if (group_func != undefined)\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, text.join(\", \"));\n",
              "                        else\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, \"(\" + text.join(\"+\") + \")\");\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "            if(group_func != undefined)\n",
              "                c.setText(filter[0][0].length * filter[0][0][0].length - 0.5, \"   ]) = \"+res[zz][i/stride_y][j/stride_x])\n",
              "            else\n",
              "                c.setText(filter[0][0].length * filter[0][0][0].length - 0.5, \"   = \"+res[zz][i/stride_y][j/stride_x])\n",
              "            c.hideAll();\n",
              "            last_pos = pos;\n",
              "        }\n",
              "        m.setHighlight1(j, i, filter[0][0][0].length, filter[0][0].length)\n",
              "        for(var zzz = 0; zzz < filter.length; zzz++) {\n",
              "            console.log(zzz, zz, zzz == zz)\n",
              "            if (zzz == zz)\n",
              "                f[zzz].setHighlight1(0, 0, filter[0][0][0].length, filter[0][0].length)\n",
              "            else\n",
              "                f[zzz].setHighlight1(0, 0, 0, 0)\n",
              "        }\n",
              "        window.f = f\n",
              "\n",
              "        r.setHighlight1(j/stride_x, i/stride_y, 1, 1)\n",
              "        r.g.selectAll(\".matrix_layer\").attr(\"opacity\", (d,i) => i > zz ? 0.2 : 1 )\n",
              "        r.g.selectAll(\".matrix_layer .highlight1\").attr(\"visibility\", (d,i)=>i==zz ? \"visible\" : \"hidden\")\n",
              "        r.g.selectAll(\".matrix_layer .highlight3\").attr(\"visibility\", (d,i)=>i==zz ? \"visible\" : \"hidden\")\n",
              "        window.r = r\n",
              "\n",
              "        if(subpos < filter[0][0].length * filter[0][0][0].length) {\n",
              "            m.setHighlight2(j + i2, i + j2, 1, 1)\n",
              "            if(group_func == undefined)\n",
              "                for(var zzz = 0; zzz < filter.length; zzz++) {\n",
              "                    if (zzz == zz)\n",
              "                        f[zzz].setHighlight2(i2, j2, 1, 1)\n",
              "                    else\n",
              "                        f[zzz].hideHighlight2()\n",
              "                }\n",
              "            r.g.selectAll(\".cell text\").attr(\"fill\", (d, i) => i >= pos_zz ? \"white\" : \"black\")\n",
              "            c.setHighlight1(subpos);\n",
              "        }\n",
              "        else {\n",
              "            m.hideHighlight2()\n",
              "            for(var zzz = 0; zzz < filter.length; zzz++)\n",
              "                f[zzz].hideHighlight2()\n",
              "            r.g.selectAll(\".cell text\").attr(\"fill\", (d, i) => i > pos_zz ? \"white\" : \"black\")\n",
              "            if(subpos > filter[0][0].length * filter[0][0][0].length) {\n",
              "                c.hideAll()\n",
              "            }\n",
              "            else\n",
              "                c.setHighlight1(subpos);\n",
              "        }\n",
              "\n",
              "        function p(x) { console.log(x); return x}\n",
              "    }\n",
              "    function animate(frame) {\n",
              "        dom_target.querySelector(\"input[type=range]\").value = index;\n",
              "        dom_target.querySelector(\"input[type=range]\").max = index_max - 1;\n",
              "        dom_target.querySelector(\"input[type=range]\").min = 0;\n",
              "        if(show_single_elements) {\n",
              "            var [pos, subpos] = divmod(frame, filter[0][0].length * filter[0][0][0].length + 2)\n",
              "            setHighlights(pos, subpos);\n",
              "        }\n",
              "        else\n",
              "            setHighlights(frame, filter[0][0].length * filter[0][0][0].length);\n",
              "    }\n",
              "    var index = -1\n",
              "    animate(0)\n",
              "    var interval = undefined;\n",
              "\n",
              "    function PlayStep() {\n",
              "        index += 1;\n",
              "        if(index >= index_max)\n",
              "            index = 0;\n",
              "        animate(index);\n",
              "    }\n",
              "\n",
              "    function playPause() {\n",
              "        if(interval === undefined) {\n",
              "            dom_target.querySelector(\".play\").style.display = \"none\"\n",
              "            dom_target.querySelector(\".pause\").style.display = \"inline-block\"\n",
              "            interval = window.setInterval(PlayStep, 1000);\n",
              "            PlayStep();\n",
              "        }\n",
              "        else {\n",
              "            dom_target.querySelector(\".play\").style.display = \"inline-block\"\n",
              "            dom_target.querySelector(\".pause\").style.display = \"none\"\n",
              "            window.clearInterval(interval);\n",
              "            interval = undefined;\n",
              "        }\n",
              "    }\n",
              "    dom_target.querySelector(\"input[type=range]\").value = 0;\n",
              "    dom_target.querySelector(\"input[type=range]\").max = index_max;\n",
              "    dom_target.querySelector(\"input[type=range]\").onchange = (i)=>{var v = parseInt(i.target.value); index = v; animate(v);};\n",
              "    dom_target.querySelector(\".play\").onclick = playPause;\n",
              "    dom_target.querySelector(\".pause\").onclick = playPause;\n",
              "    dom_target.querySelector(\".left\").onclick = ()=>{index > 0 ? index -= 1 : index = index_max-1; animate(index);};\n",
              "    dom_target.querySelector(\".right\").onclick = ()=>{index < index_max-1 ? index += 1 : index = 0; animate(index);};\n",
              "\n",
              "    dom_target.querySelector(\".input_filterx\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_filtery\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_filterz\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixx\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixy\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixz\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixzB\").onchange = (i)=>{dom_target.querySelector(\".input_matrixz\").value = parseInt(i.target.value); init();};\n",
              "    dom_target.querySelector(\".input_paddingx\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_paddingy\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_stridex\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_stridey\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".play_fast\").onchange = ()=>{init()}\n",
              "    <!--\n",
              "    dom_target.querySelector(\".select_maxpool\").onclick = ()=>{group_func=\"max\"; dom_target.querySelector(\".dropbtn\").innerText = \"MaxPool2d\"; init()}\n",
              "    dom_target.querySelector(\".select_avgpool\").onclick = ()=>{group_func=\"avg\"; dom_target.querySelector(\".dropbtn\").innerText = \"AvgPool2d\"; init()}\n",
              "    -->\n",
              "    })();\n",
              "  </script>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown *Run this cell to enable the widget!*\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "id_html = 2.2\n",
        "url = f'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo{id_html}.html'\n",
        "run_demo = True # @param {type:\"boolean\"}\n",
        "if run_demo:\n",
        "  display(HTML(url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "628QtxzO5Q9k"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Visualization_of_Convolution_with_Padding_and_Stride_Interactive_Demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "JNRtI4Va5Q9k"
      },
      "source": [
        "### Think! 2.2.1: Edge Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "pWv4XsCI5Q9k"
      },
      "source": [
        "One of the simpler tasks performed by a convolutional layer is edge detection; that is, finding a place in the image where there is a large and abrupt change in color. Edge-detecting filters are usually learned by the first layers in a CNN. Observe the following simple kernel and discuss whether this will detect vertical edges (where the trace of the edge is vertical; i.e. there is a boundary between left and right), or whether it will detect horizontal edges (where the trace of the edge is horizontal; i.e., there is a boundary between top and bottom).\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{Kernel} =\n",
        "\\begin{bmatrix} 1 & -1 \\\\ 1 & -1\n",
        "\\end{bmatrix}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TjLntrQy5Q9k"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_309474b2.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "SzzE5YUf5Q9l"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Edge_Detection_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Ftr1hEch5Q9l"
      },
      "source": [
        "Consider the image below, which has a black vertical stripe with white on the side. This is like a very zoomed-in vertical edge within an image!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "1dSymEBv5Q9l",
        "outputId": "a5a59f64-64a3-40ae-f1c5-5617a5589462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 1. 1.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 744,
              "height": 575
            }
          }
        }
      ],
      "source": [
        "# Prepare an image that's basically just a vertical black stripe\n",
        "X = np.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "print(X)\n",
        "plt.imshow(X, cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "jv68K9gD5Q9l",
        "outputId": "ac592bda-c9f8-4395-98e8-43949e13e56e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  2.  0.  0.  0. -2.  0.]\n",
            " [ 0.  2.  0.  0.  0. -2.  0.]\n",
            " [ 0.  2.  0.  0.  0. -2.  0.]\n",
            " [ 0.  2.  0.  0.  0. -2.  0.]\n",
            " [ 0.  2.  0.  0.  0. -2.  0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABg4AAAR3CAYAAAAvn5+IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAewgAAHsIBbtB1PgAARTRJREFUeJzs3XuQlfV5wPFnYcEFl4ugI5ddgqijRpw2KqijUawKMZGSOsZpUhFFHZugmQwaR+sN0EGTmFSiRDtqLl5obeMlWGaoJoCXNEaZIIECFhHILi5EQBcEgV3Y/mF4CroICOecXfbzmdnJ+559L884czLLfvf9nbKmpqamAAAAAAAAiIh2pR4AAAAAAABoOYQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABI5aUeoNQaGxtj5cqVERHRq1evKC9v8/9JAAAAAABow9r8EwcrV66M6urqqK6uzoAAAAAAAABtlT+v38GPfvSj6NatW6nHgFbp9ttvL/UI0KqNHz++1CMAALAPxo0bV+oRoFXzHoJ9tz9/P9fmnzgAAAAAAAD+n3AAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIBU1HLz00ksxevToOPbYY6NLly7RvXv3GDhwYFx77bUxZ86cYo4CAAAAAAA0o7wYN1m/fn1861vfiscff/wT36uvr4//+Z//icmTJ8fYsWPjrrvuig4dOhRjLAAAAAAA4GMKHg4aGxtjxIgRMXPmzHyta9eucfzxx8eWLVtiwYIF8eGHH0ZTU1P88Ic/jHfffTd+8YtfFHosAAAAAACgGQVfqujmm2/eKRrceuutUVdXF//93/8ds2fPjpqamrjyyivz+48++mg88MADhR4LAAAAAABoRkHDQU1NTUyaNCn3b7311pgwYUJ07tw5X+vZs2c89NBDcckll+Rr48ePj40bNxZyNAAAAAAAoBkFDQeTJk2KzZs3R0REv3794pZbbvnUY7cHhVWrVsXPfvazQo4GAAAAAAA0o6Dh4Jlnnsnt0aNHR8eOHXd5bI8ePeKiiy5q9lwAAAAAAKA4ChYOFi1aFG+//Xbuf+lLX9rtOeeff35uv/jii/HBBx8UZDYAAAAAAKB5BQsHc+fOze2DDjooTjzxxN2ec9ppp+V2Y2NjLFiwoCCzAQAAAAAAzSsv1IUXLlyY29XV1dGhQ4fdnlNdXR0dO3aMLVu2RMRHTy0MHjx4r+5bW1u7V8fX1dXt1fEAAAAAAHAgK1g4WL58eW7369dvj85p165d9O3bN5YuXRoREcuWLdvr+1ZXV+/1OQAAAAAAwEcKtlTR+vXrc7tbt257fF7Xrl2bvQYAAAAAAFB4BXviYMOGDbldUVGxx+d16tSp2WvsqZqamr06vq6ubq+XQwIAAAAAgANVwcJBQ0PD/9+kfM9vs+Ox2z/rYG9UVVXt9TkAAAAAAMBHCrZUUefOnXN706ZNe3zejscefPDB+3UmAAAAAADg0xUsHFRWVub2hx9+uMfnbdy4sdlrAAAAAAAAhVewcNCzZ8/crqur2+PzVq5c2ew1AAAAAACAwitYODjmmGNy+09/+tMenbNhw4ZYu3Zts9cAAAAAAAAKr2Dh4Ljjjsvtd999d4+eOnjjjTd2eQ0AAAAAAKDwChYOBg8eHB07dsz9l19+ebfn7HhMVVVVDBgwoCCzAQAAAAAAzStYOOjSpUucffbZuf/EE0/s9pwpU6bk9vDhwwsyFwAAAAAAsGsFCwcREZdddlluT5s2LebMmbPLY6dOnRrz5s3L/VGjRhVyNAAAAAAAoBkFDQcXX3xxDBw4MCIitm7dGv/wD//Q7GcdLFy4MK6++urc/8pXvhKnnHJKIUcDAAAAAACaUV7Ii7dr1y4eeuihGDJkSGzevDkWLlwYX/jCF+Laa6+NQYMGRUNDQ7z00kvx4IMPxrp16yIiomfPnjFp0qRCjgUAAAAAAOxCQcNBRMSpp54ajz76aFx66aWxefPmWLVqVdxyyy3NHtutW7d4+umn48gjjyz0WAAAAAAAQDMKulTRdhdffHG8/vrrMWTIkCgrK/vE99u3bx/Dhw+PuXPnxplnnlmMkQAAAAAAgGYU/ImD7U444YSYOXNmLF26NF599dVYsWJFtG/fPqqqquKLX/xi9OrVq1ijAAAAAAAAu1C0cLDdEUccEUcccUSxbwsAAAAAAOyBoixVBAAAAAAAtA7CAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQCov1o1WrFgRr7/+esyePTv/d+3atfn9mTNnxpAhQ4o1DgAAAAAA0IyCh4M5c+bEl7/85Vi5cmWhbwUAAAAAAOyjgi9VVF9fLxoAAAAAAEArUbSliiIi+vTpE4MGDYqTTz45+vbtG6NHjy7m7QEAAAAAgN0oeDg4+uijY+rUqTFo0KDo1atXvr5s2bJC3xoAAAAAANhLBQ8Hffv2jb59+xb6NgAAAAAAwH5Q8M84AAAAAAAAWg/hAAAAAAAASMIBAAAAAACQhAMAAAAAACAV/MORi622tnavjq+rqyvQJAAAAAAA0PoccOGgurq61CMAAAAAAECrZakiAAAAAAAgHXBPHNTU1OzV8XV1dTF48OACTQMAAAAAAK3LARcOqqqqSj0CAAAAAAC0WpYqAgAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAAqSjhYOjQoVFRUbHT1zHHHLPbY4YOHVqM8QAAAAAAgL8oL8ZNtmzZEps3b/7UYxoaGpo9DwAAAAAAKB5LFQEAAAAAAKkoTxzMmjWrGLcBAAAAAAD2kScOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkMqLcZP3338/fvOb38TMmTPjjTfeiMWLF8d7770XBx10UPTs2TO+8IUvxNChQ2PkyJFRWVlZjJEAAAAAAIBmFDQcLFq0KK6//vp4/vnno6Gh4RPfb2hoiA8++CCWL18ezz77bNx0001x7733xmWXXVbIsQAAAAAAgF0oaDiYP39+TJs2bafX2rdvH0cddVQcfvjhsXXr1li4cGGsXbs2IiLq6+vj8ssvjyVLlsQdd9xRyNEAAAAAAIBmFOUzDsrLy+OrX/1qPPvss7F27dpYtGhRvPjii/HKK6/E6tWr49lnn42+ffvm8XfeeWc899xzxRgNAAAAAADYQUHDQYcOHeLKK6+MJUuWxDPPPBMjRoyIrl277nRMWVlZjBgxIn73u99Fr1698vV/+qd/KuRoAAAAAABAMwoaDkaMGBEPPfRQ9OvXb7fHVldXx/jx43N//vz5sWTJkkKOBwAAAAAAfExRliraU8OHD99pf9GiRSWaBAAAAAAA2qYWFQ569Oix0/66detKNAkAAAAAALRNLSocLF++fKf9ww47rESTAAAAAABA29SiwsHTTz+d2+Xl5XHSSSeVcBoAAAAAAGh7yks9wHYbNmyI+++/P/eHDRsWhxxyyF5fp7a2dq+Or6ur2+t7AAAAAADAgarFhIPrr78+VqxYERERZWVlMWHChM90nerq6v05FgAAAAAAtCktYqmiJ554Ih588MHcHzt2bJx44oklnAgAAAAAANqmkj9x8PLLL8cVV1yR+yeddFJMnDjxM1+vpqZmr46vq6uLwYMHf+b7AQAAAADAgaSk4WDu3LkxfPjw2Lx5c0REDBgwIJ577rno2LHjZ75mVVXV/hoPAAAAAADanJItVfTmm2/G0KFDo76+PiIi+vTpEy+88EL07t27VCMBAAAAAECbV5JwsHTp0jj33HPjz3/+c0REHHroofHCCy/EgAEDSjEOAAAAAADwF0UPB7W1tXHOOedEbW1tRER07do1pk+fHp///OeLPQoAAAAAAPAxRQ0Hq1atinPPPTeWLl0aERGdO3eOadOmxUknnVTMMQAAAAAAgF0oWjhYu3ZtnHfeefHmm29GRMRBBx0Uzz77bJxxxhnFGgEAAAAAANiNooSDdevWxbBhw2LevHkREVFeXh7//u//Huedd14xbg8AAAAAAOyhgoeDjRs3xle+8pWYPXv2Rzds1y4ee+yx+Nu//dtC3xoAAAAAANhLBQ0HmzdvjhEjRsQrr7wSERFlZWXx8MMPx9///d8X8rYAAAAAAMBnVF7Ii0+aNCl+/etf53737t3jySefjCeffHKPzr/kkkvikksuKdR4AAAAAADAxxQ0HGzcuHGn/ffeey/+67/+a4/PP/XUU/f3SAAAAAAAwKcoyocjAwAAAAAArUNBnzgYN25cjBs3rpC3AAAAAAAA9iNPHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQCov9A22bNkSr7/+evzud7+LuXPnxptvvhl/+tOfor6+PrZu3RrdunWL/v37xymnnBJf//rX4/TTTy/0SAAAAAAAwC4UPByMGTMmHn744V1+f/Xq1bF69eqYPXt2TJ48OYYMGRKPPPJIDBgwoNCjAQAAAAAAH1PwcNDU1LTTfteuXePII4+M7t27x9atW2PFihXx9ttv53GzZs2K008/PWbNmhXHHHNMoccDAAAAAAB2UPBwcPDBB8eFF14Yw4cPjzPPPLPZJwlqamri7rvvjp/85CcREbFy5coYOXJkvPrqq9GunY9hAAAAAACAYil4OJg0adJuj6muro7JkyfHoYceGhMmTIiIiNdffz1efPHFOPvssws9IgAAAAAA8Bct6s/5b7rppqisrMz9WbNmlW4YAAAAAABog1pUOKioqIjjjjsu91euXFnCaQAAAAAAoO1pUeEgIqKxsTG3u3btWsJJAAAAAACg7WlR4WDNmjUxf/783D/ttNNKOA0AAAAAALQ9LSYcbNu2LcaMGRMNDQ0REXH00UfH8OHDSzwVAAAAAAC0LeWlvHlDQ0OsXLkyXnnllbj33nvjtddei4iIqqqqeOqpp6JDhw57fc3a2tq9Or6urm6v7wEAAAAAAAeqooaDxsbGT40BFRUV8bWvfS3uvvvu6NOnz2e6R3V19WcdDwAAAAAA2rwWs1RRRMTQoUNj1KhRnzkaAAAAAAAA+6aoTxy0a9cuhg0blvsffvhhvPPOO7FkyZJoamqKqVOnxtSpU2Po0KHxxBNPxKGHHrrX96ipqdmr4+vq6mLw4MF7fR8AAAAAADgQFT0cTJ8+/ROv19XVxX333Rf33HNPNDQ0xPPPPx/nnHNOvPrqq9GpU6e9ukdVVdX+GhcAAAAAANqcFrFUUe/evWPixInx3HPPRfv27SMi4o9//GPceeedJZ4MAAAAAADalhYRDrYbNmxYXHHFFbn/L//yL7Ft27YSTgQAAAAAAG1LiwoHEREXX3xxbq9ZsyYWL15cwmkAAAAAAKBtaXHhoLq6eqf9NWvWlGgSAAAAAABoe1pcOFi3bt1O+927dy/NIAAAAAAA0Aa1uHDw8ssv53Z5eXn069evhNMAAAAAAEDb0qLCQX19ffzoRz/K/bPOOisqKytLOBEAAAAAALQtBQ0HTz/9dNx2223x7rvv7vbYt956K84777yora3N12688cZCjgcAAAAAAHxMeSEvvm7durjjjjti4sSJcdZZZ8Xpp58eAwcOjJ49e0ZFRUWsW7cuFi9eHDNnzoxp06ZFQ0NDnnvNNdfEueeeW8jxAAAAAACAjyloONhu69atMWPGjJgxY8Zuj23fvn1897vfjYkTJxZhMgAAAAAAYEcFXaroi1/8Ylx77bVx9NFH7/bYgw8+OC699NKYPXt23HXXXVFWVlbI0QAAAAAAgGYU9ImDI488Mn784x9HRMSaNWti7ty5sXTp0lizZk1s2bIlunTpEj169Ijjjz8+Bg4cGB07dizkOAAAAAAAwG4UZamiiIiePXvG3/zN3xTrdgAAAAAAwGdQ0KWKAAAAAACA1kU4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQSh4Oli1bFpWVlVFWVpZf48aNK/VYAAAAAADQJpU8HHzzm9+MDRs2lHoMAAAAAAAgShwOpkyZEtOnTy/lCAAAAAAAwA5KFg7Wrl0b3/nOdyIi4thjj40+ffqUahQAAAAAAOAvShYOrrvuunj33XcjIuLBBx+MDh06lGoUAAAAAADgL0oSDmbMmBE///nPIyJi1KhRcdZZZ5ViDAAAAAAA4GOKHg42bdoUV199dURE9OjRI+65555ijwAAAAAAAOxC0cPBhAkT4q233oqIiO9///tx6KGHFnsEAAAAAABgF4oaDubNm5dPGJxxxhkxevToYt4eAAAAAADYjaKFg23btsVVV10VDQ0NUV5eHg888ECUlZUV6/YAAAAAAMAeKC/WjSZPnhy///3vIyLiuuuui4EDBxbkPrW1tXt1fF1dXUHmAAAAAACA1qgo4aC2tjZuvvnmiIjo379/3HbbbQW7V3V1dcGuDQAAAAAAB7qiLFU0ZsyYWL9+fURE3HfffdG5c+di3BYAAAAAANhLBX/i4Je//GVMnTo1IiIuvPDCuOCCCwp6v5qamr06vq6uLgYPHlygaQAAAAAAoHUpaDior6+Pb3/72xERUVlZGZMmTSrk7SIioqqqquD3AAAAAACAA1VBlyq64YYb8sOHJ0yY4Jf6AAAAAADQwhUsHCxYsCAeeuihiIj467/+63zyAAAAAAAAaLkKFg7+/Oc/R1NTU0REvPHGG1FeXh5lZWW7/Fq+fHmeO378+J2+t2zZskKNCQAAAAAA7KCgSxUBAAAAAACtS8E+HLlDhw7Rs2fPPT7+vffei23btkVERKdOnaJz5875vfbt2+/3+QAAAAAAgE8qWDg4/fTTY/Xq1Xt8fP/+/XO5ohtuuCHGjRtXoMkAAAAAAIBdsVQRAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAACpvNQDbLds2bJSjwAAAAAAAG2eJw4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIAkHAAAAAABAEg4AAAAAAIAkHAAAAAAAAEk4AAAAAAAAknAAAAAAAAAk4QAAAAAAAEjCAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACCVl3qAUmtsbMzt9evXl3ASaN1qa2tLPQK0avX19aUeAQAAoGT8mwj2XWNjY5SX759f+Zc1NTU17ZcrtVKvv/56DB48uNRjAAAAAADAZ1ZTUxNVVVX75VqWKgIAAAAAAFKbf+Jg06ZNMW/evIiIOOyww/bboxzsH3V1dflEyGuvvRa9e/cu8UTQ+ngfwb7xHoJ94z0E+8Z7CPaN9xDsG++h1qVXr1777ffbbf635BUVFTFo0KBSj8Ee6N2793571AbaKu8j2DfeQ7BvvIdg33gPwb7xHoJ94z3UtliqCAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOAAAAAACAJBwAAAAAAABJOAAAAAAAAJJwAAAAAAAAJOEAAAAAAABIwgEAAAAAAJCEAwAAAAAAIJU1NTU1lXoIAAAAAACgZfDEAQAAAAAAkIQDAAAAAAAgCQcAAAAAAEASDgAAAAAAgCQcAAAAAAAASTgAAAAAAACScAAAAAAAACThAAAAAAAASMIBAAAAAACQhAMAAAAAACAJBwAAAAAAQBIOaLFeeumlGD16dBx77LHRpUuX6N69ewwcODCuvfbamDNnTqnHgxZrxYoV8eyzz8Ytt9wSw4YNi549e0ZZWVl+zZo1q9QjQov1/vvvx1NPPRXXXHNNnHHGGXH44YdHx44do0uXLtG/f//4u7/7u3jggQfigw8+KPWo0OJs2bIlfvvb38Y999wTI0eOjMGDB0evXr2iU6dO0bFjxzjssMNi0KBBcc0118Rvf/vbUo8LrdKyZcuisrJyp5/txo0bV+qxoMWYNWvWTu+PPf1atGhRqUeHFmvVqlUxefLkOO+88+LII4+Mzp07R6dOneJzn/tcnH/++fG9730vXnvttdi2bVupR2U/K2tqamoq9RCwo/Xr18e3vvWtePzxx3d5TFlZWYwdOzbuuuuu6NChQxGng5Zrzpw58eUvfzlWrlz5qcfNnDkzhgwZUpyhoJVYtGhRXH/99fH8889HQ0PDbo/v1q1b3HvvvXHZZZcVfjhoJa666qp4+OGH9/j4IUOGxCOPPBIDBgwo4FRwYDn//PNj+vTpO712++23iwfwF7NmzYqzzz57r89buHBhHHvssQWYCFqvrVu3xqRJk+K2226LDRs27Pb4xYsXx1FHHVWEySiW8lIPADtqbGyMESNGxMyZM/O1rl27xvHHHx9btmyJBQsWxIcffhhNTU3xwx/+MN599934xS9+UcKJoeWor6/fbTQAmjd//vyYNm3aTq+1b98+jjrqqDj88MNj69atsXDhwli7dm1EfPR+u/zyy2PJkiVxxx13lGJkaHE+/vdIXbt2jSOPPDK6d+8eW7dujRUrVsTbb7+dx82aNStOP/30mDVrVhxzzDGlGBlalSlTpnwiGgC7VlFREWedddYeHVtZWVngaaB1aWhoiIsuuiimTp260+tHHXVU9OnTJ5qamuKdd97Z6Wc7DjzCAS3KzTffvFM0uPXWW+PGG2+Mzp07R0TEmjVr4sYbb8y/Znv00Ufj1FNPjW9+85slmRdaqj59+sSgQYPi5JNPjr59+8bo0aNLPRK0CuXl5XHBBRfEZZddFmeffXZ07do1v9fU1BRTp06NMWPGxIoVKyIi4s4774zBgwfH8OHDSzUytBgHH3xwXHjhhTF8+PA488wzm32SoKamJu6+++74yU9+EhERK1eujJEjR8arr74a7dpZRRV2Ze3atfGd73wnIiKOPfbYWLduXbzzzjulHQpauMMPP1xsg8/okksuyWjQoUOHGDt2bIwZMyaqq6t3Ou7999+P6dOnx09/+lM/yx2ALFVEi1FTUxNHH310bN68OSI+igYTJkxo9tiRI0fmUkaHH354vP322xkXoK1asWJF/OEPf4hBgwZFr1698vVly5bFEUcckfuWKoJP+tWvfhX/+Z//Gbfeemv069fvU4+tqamJwYMH5xM+AwcOjHnz5hVjTDhg3H777Tv9nDdjxozPtLQEtBWXX355/PznP4+Ij57WGTVqVCxfvjwiLFUEO9pxqaLPfe5zsWzZstIOBK3QY489FpdeemlERHTu3DmmTZvmdwhtlBREizFp0qSMBv369YtbbrnlU4/dHgpWrVoVP/vZz4oyI7Rkffv2jeHDh+8UDYA9M2LEiHjooYd2Gw0iIqqrq2P8+PG5P3/+/FiyZEkhx4MDzk033bTTshCzZs0q3TDQws2YMSOjwahRo/Z46RUA2Fvr16+PsWPH5v69994rGrRhwgEtxjPPPJPbo0ePjo4dO+7y2B49esRFF13U7LkAUGgfX5po0aJFJZoEWqeKioo47rjjct9n9EDzNm3aFFdffXVEfPRvoHvuuafEEwFwIJsyZUqsXr06Ij5aGu/KK68s8USUknBAi7Bo0aJ4++23c/9LX/rSbs85//zzc/vFF1+MDz74oCCzAcDH9ejRY6f9devWlWgSaL0aGxtze8fPEwH+34QJE+Ktt96KiIjvf//7ceihh5Z4IgAOZI888khuX3LJJVFWVlbCaSg14YAWYe7cubl90EEHxYknnrjbc0477bTcbmxsjAULFhRkNgD4uO3rSm932GGHlWgSaJ3WrFkT8+fPz/0df64DPjJv3rx8wuCMM86I0aNHl3giAA5k77//fsyePTv3ff4UwgEtwsKFC3O7uro6OnTosNtzqqurd1rOyDIRABTL008/ndvl5eVx0kknlXAaaF22bdsWY8aMiYaGhoiIOProoz+x/Be0ddu2bYurrroqGhoaory8PB544AF/9Ql76f3334+LL744+vfvH506dYouXbrEEUccEV/96lfj/vvv98QofMzs2bOjqakp90844YSIiHjppZdi5MiRMWDAgKioqIiePXvGiSeeGN/97nfjzTffLNW4FIFwQIuw419u7skHU0ZEtGvXLvr27Zv7y5Yt299jAcAnbNiwIe6///7cHzZsWBxyyCElnAhavoaGhqipqYl//dd/jdNOOy2efPLJiIioqqqKp556ao/+aATaksmTJ8fvf//7iIi47rrrYuDAgSWeCFqf+vr6+I//+I9Yvnx5bNq0KT744INYtmxZ/OpXv4prr702+vXrF/fdd1+px4QW449//GNuV1ZWRseOHeOqq66Ks846Kx5//PFYunRpbN68OdauXRtz5syJe+65J44//vi44YYbYtu2bSWcnEIpL/UAEPHRp7Zv161btz0+b8f1cHe8BgAUyvXXXx8rVqyIiIiysrKYMGFCiSeClqexsfFTY0BFRUV87Wtfi7vvvjv69OlTxMmg5autrY2bb745IiL69+8ft912W4kngtarf//+0bdv3zjooINi9erVsWDBgvyMnfr6+vj2t78db7zxxk7rukNbtWbNmtyurKyM0aNHx5QpUyIion379nHCCSfEIYccErW1tbF48eKIiNi6dWv84Ac/iLq6unjsscdKMjeF44kDWoQNGzbkdkVFxR6f16lTp2avAQCF8MQTT8SDDz6Y+2PHjt2jz+UBdjZ06NAYNWqUaADNGDNmTP5R1H333RedO3cu8UTQerRr1y7OPffceOKJJ2LNmjWxdOnSeOWVV+I3v/lNzJ07N95777144IEHdvqg8Z/+9Kfxve99r4RTQ8tQX1+f2ytXrsxo8PWvfz1qa2tjzpw5MWPGjPjf//3feOONN+Lkk0/O4x9//PF4+OGHiz4zhSUc0CJsX+M24qO1ovfUjsdu2bJlv84EADt6+eWX44orrsj9k046KSZOnFjCiaDlateuXQwbNiy/zjzzzDjqqKNyjfapU6fGueeeG8OGDYvVq1eXeFpoOX75y1/G1KlTIyLiwgsvjAsuuKDEE0HrcuaZZ8YLL7wQ3/jGN6JHjx6f+H5lZWX84z/+Y/zhD3+I/v375+sTJkyIVatWFXFSaHk2bdr0ide+8Y1vxJQpU6JXr147vf5Xf/VXMWPGjPj85z+fr40fP36n3+/R+gkHtAg7/hVNc/9HtSs7HnvwwQfv15kAYLu5c+fG8OHDY/PmzRERMWDAgHjuueeiY8eOJZ4MWqZ27drF9OnT8+vFF1+MxYsXx4oVK+Kmm27KZYyef/75OOecc+LDDz8s8cRQetuXTYn46JebkyZNKvFEcOCqrq6Of/u3f8v9jRs3Wq6INu/jv1fr1KlT/PjHP97l8V26dIl//ud/zv3a2tr49a9/XbD5KD7hgBahsrIyt/fmH44bN25s9hoAsL+8+eabMXTo0Hx0t0+fPvHCCy9E7969SzwZtD69e/eOiRMnxnPPPRft27ePiI8+iO/OO+8s8WRQejfccEPU1dVFxEd//VxVVVXiieDAdsopp8SQIUNy/4UXXijdMNACfPz3aueff370/L/27iWkqq4B4/hz1CxNLTVUwkQq0egEWXgh8xJlCVLpRKJEC4QmNYrSQddJgXQZhFDUIAqjC4RIQhlUaISWoCYoZWGaQd5LylAzv0G4OIdPP32/N91H/f9A2OucvQ6PEz3sZ++1AgP/55zU1FQFBQWZcUVFxbRkgzUoDuASHP8QjX1ZnoovX76M+xkAAPwNLS0t2rZtmzo7OyVJy5Yt05MnT7Ry5UqLkwGz244dO5yW/rp69ap+//5tYSLAWo2Njbp27Zokaf369ebJAwDTy7E4ePfunXVBABfguPeHpCnt5Waz2RQdHW3GLS0tfz0XrENxAJcQGRlpjtva2qY058ePH+rt7R33MwAA+Lfa29u1detWtbe3S5L8/Pz06NEjp3U8Afz/srKyzHFPT4+am5stTANYq7OzU6Ojo5Kkuro6eXh4yGazTfjT2tpq5p45c8bpvY8fP1r0WwCzj+MTpOy5g/kuKirKaTzVG3Qdz3O8TofZj+IALmHNmjXmuKura0pPHdTV1U34GQAA/BsdHR3atm2buWPG29tbZWVl2rhxo8XJgLljxYoVTuOenh6LkgAA5ivH5Y8d914E5qO1a9c6jcf2d5uM4/6jXl5efzUTrOVhdQBAkmJjY+Xp6amhoSFJUmVlpdNdaOOprKw0x6GhoSwbAQD4K3p7e5Wamqq3b99KkhYuXKiSkhJt3rzZ4mTA3NLf3+80Xrp0qTVBABewYMGCf7T0al9fn1ney8vLy+mC59j+IQAm19jYaI4d12kH5qOwsDCFh4ebJ9emuuyQ45NuwcHB05AMVuGJA7gEX19fbdmyxYyLi4snnXP79m1zvHPnzmnJBQCYX/r7+7Vjxw41NDRIkjw8PHTv3j2lpqZanAyYexxvAvHw8FBYWJiFaQBrJSQkqLu7e8o/jk/sHDt2bML3AEzs58+fKi0tNeNNmzZZmAZwDZmZmeZ4KhuGd3R06M2bN2YcHx8/LblgDYoDuIz9+/eb47KyMtXW1k54bmlpqbmoI0m5ubnTGQ0AMA8MDAwoPT1dNTU1kiQ3NzfdunVLu3btsjgZMPd8+/ZNFy9eNOPk5GT5+PhYmAgAMN+cOHFCHR0dZpyRkWFdGMBFHDhwQG5ufy4XNzY2OpVr4zl//rx+/folSfL09FRaWtq0Z8TMoTiAy8jKypLdbpckjYyMaN++fePuddDU1KSDBw+acXp6uuLi4mYsJwBg7hkcHNTu3bv14sULSZLNZtP169e1Z88ei5MBs8ODBw908uRJdXV1TXru+/fvlZqaajYel6SCgoLpjAcAmAfKy8t15MgRp/8v4xkeHlZBQYEuXLhgXtuwYQM3iwCS1q1bp71795pxXl6e0xMFju7cuaNLly6ZcW5urpYvXz7tGTFzbKOjo6NWhwDGVFVVKSUlxWzAEhwcrMOHDysmJkbDw8OqqKjQlStXzJq4gYGBqq6u1qpVq6yMDbiM7du3q6Kiwum10dFRs3+I9GcN3bE7CMYkJSWpvLx8RjICrqiwsFD5+flm7O/vr9jY2CnPz87OVnZ29nREA2aFGzdu6MCBA3J3d1dycrISEhJkt9sVGBioRYsWqb+/X83NzXr27JnKyso0PDxs5h46dEiXL1+2MD0w+4SHh6u1tVWSdOrUKZ0+fdraQIALKCkpUWZmptzc3JSQkKDk5GTZ7XYtW7ZMnp6e6u7u1qtXr1RcXKxPnz6ZeQEBAXr58qUiIyMtTA+4ji9fviguLk5tbW2S/uz5lpeXp+3bt8vf31+fPn3S/fv3VVJSYuasWrVKNTU17Fk1x7A5MlxKfHy8bt68qZycHA0ODqqjo0PHjx8f99wlS5bowYMHlAaAg6GhIVO8TcTxYo3jPGA+GxgYcBr39fXp8ePHU57PWp7AHyMjI3r69KmePn066bnu7u46evSozp49OwPJAADzxe/fv1VZWem0l85EIiIidPfuXUoDwEFISIjKysqUlpamz58/a3BwUEVFRSoqKhr3/MjISD18+JDSYA5iqSK4nKysLL1+/VopKSmy2Wz/9b67u7t27typ+vp6JSUlWZAQAAAAjhITE3X48GFFRERMeu7ixYuVk5OjmpoanTt3btzvewAA/FNRUVHKyMiQv7//pOeGh4ersLBQtbW1io6OnoF0wOxit9vV0NCgvLw8eXt7j3uOj4+P8vPzVV1drdWrV89wQswEliqCS2tpaVFVVZU+f/4sd3d3hYaGKjExUSEhIVZHAwAAwDh6enpUX1+vlpYW9fT0aGhoSL6+vgoICNDatWtlt9vl6elpdUwAwBz24cMHNTU1qb29XV+/ftXIyIj8/PwUFBSkmJgYrVy50uqIwKzx/ft3PX/+XG1tbfr69asCAgIUGRmphIQEvtPNcRQHAAAAAAAAAADAYKkiAAAAAAAAAABgUBwAAAAAAAAAAACD4gAAAAAAAAAAABgUBwAAAAAAAAAAwKA4AAAAAAAAAAAABsUBAAAAAAAAAAAwKA4AAAAAAAAAAIBBcQAAAAAAAAAAAAyKAwAAAAAAAAAAYFAcAAAAAAAAAAAAg+IAAAAAAAAAAAAYFAcAAAAAAAAAAMCgOAAAAAAAAAAAAAbFAQAAAAAAAAAAMCgOAAAAAAAAAACAQXEAAAAAAAAAAAAMigMAAAAAAAAAAGBQHAAAAAAAAAAAAIPiAAAAAAAAAAAAGBQHAAAAAAAAAADAoDgAAAAAAAAAAAAGxQEAAAAAAAAAADAoDgAAAAAAAAAAgEFxAAAAAAAAAAAAjP8Ar3N8WRKqQUAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "image/png": {
              "width": 775,
              "height": 571
            }
          }
        }
      ],
      "source": [
        "# Format the image that's basically just a vertical stripe\n",
        "image = torch.from_numpy(X)\n",
        "image = image.reshape(1, 1, 6, 8) # BatchSize X Channels X Height X Width\n",
        "\n",
        "# Prepare a 2x2 kernel with 1s in the first column and -1s in the\n",
        "# This exact kernel was discussed above!\n",
        "kernel = torch.Tensor([[1.0, -1.0], [1.0, -1.0]])\n",
        "net = Net(kernel=kernel)\n",
        "\n",
        "# Apply the kernel to the image and prepare for display\n",
        "processed_image = net(image.float())\n",
        "processed_image = processed_image.reshape(5, 7).detach().numpy()\n",
        "print(processed_image)\n",
        "plt.imshow(processed_image, cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "yWDfBL415Q9l"
      },
      "source": [
        "As you can see, this kernel detects vertical edges (the black stripe corresponds to a highly positive result, while the white stripe corresponds to a highly negative result. However, to display the image, all the pixels are normalized between 0=black and 1=white)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "fqCRBX0c5Q9l"
      },
      "source": [
        "### Think! 2.2.2 Kernel structure\n",
        "\n",
        "If the kernel were transposed (i.e., the columns become rows and the rows become columns), what would the kernel detect? What would be produced by running this kernel on the vertical edge image above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "E-Rse_f-5Q9l"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_7cc3340b.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "wPOAnjqc5Q9m"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Kernel_structure_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "5t6qX2M55Q9m"
      },
      "source": [
        "---\n",
        "# Section 3: Kernels, Pooling and Subsampling\n",
        "\n",
        "*Time estimate: ~50mins*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8y3wpU395Q9m"
      },
      "source": [
        "To visualize the various components of a CNN, we will build a simple CNN step by step. Recall that the MNIST dataset consists of binarized images of handwritten digits. This time, we will use the EMNIST letters dataset, which consists of binarized images of handwritten characters $(A, ..., Z)$.\n",
        "\n",
        "We will simplify the problem further by only keeping the images that correspond to $X$ (labeled as `24` in the dataset) and $O$ (labeled as `15` in the dataset). Then, we will train a CNN to classify an image either an $X$ or an $O$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCMh1r3Y5Q9m",
        "outputId": "0da3d6b7-5669-4b9f-9793-f5ec18cd0271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading EMNIST dataset...\n",
            "\n",
            "Downloading EMNIST completed.\n",
            "\n",
            "Extracting the files...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Download EMNIST dataset\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# webpage: https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
        "fname = 'EMNIST.zip'\n",
        "folder = 'EMNIST'\n",
        "url = \"https://osf.io/xwfaj/download\"\n",
        "download_data(fname, folder, url, tar=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {},
        "id": "psR1LzKd5Q9m"
      },
      "outputs": [],
      "source": [
        "# @title Dataset/DataLoader Functions *(Run me!)*\n",
        "\n",
        "def get_Xvs0_dataset(normalize=False, download=False):\n",
        "  \"\"\"\n",
        "  Load Dataset\n",
        "\n",
        "  Args:\n",
        "    normalize: boolean\n",
        "      If true, normalise dataloader\n",
        "    download: boolean\n",
        "      If true, download dataset\n",
        "\n",
        "  Returns:\n",
        "    emnist_train: torch.loader\n",
        "      Training Data\n",
        "    emnist_test: torch.loader\n",
        "      Test Data\n",
        "  \"\"\"\n",
        "  if normalize:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "  else:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "  emnist_train = datasets.EMNIST(root='.',\n",
        "                                 split='letters',\n",
        "                                 download=download,\n",
        "                                 train=True,\n",
        "                                 transform=transform)\n",
        "  emnist_test = datasets.EMNIST(root='.',\n",
        "                                split='letters',\n",
        "                                download=download,\n",
        "                                train=False,\n",
        "                                transform=transform)\n",
        "\n",
        "  # Only want O (15) and X (24) labels\n",
        "  train_idx = (emnist_train.targets == 15) | (emnist_train.targets == 24)\n",
        "  emnist_train.targets = emnist_train.targets[train_idx]\n",
        "  emnist_train.data = emnist_train.data[train_idx]\n",
        "\n",
        "  # Convert Xs predictions to 1, Os predictions to 0\n",
        "  emnist_train.targets = (emnist_train.targets == 24).type(torch.int64)\n",
        "\n",
        "  test_idx = (emnist_test.targets == 15) | (emnist_test.targets == 24)\n",
        "  emnist_test.targets = emnist_test.targets[test_idx]\n",
        "  emnist_test.data = emnist_test.data[test_idx]\n",
        "\n",
        "  # Convert Xs predictions to 1, Os predictions to 0\n",
        "  emnist_test.targets = (emnist_test.targets == 24).type(torch.int64)\n",
        "\n",
        "  return emnist_train, emnist_test\n",
        "\n",
        "\n",
        "def get_data_loaders(train_dataset, test_dataset,\n",
        "                     batch_size=32, seed=0):\n",
        "  \"\"\"\n",
        "  Helper function to fetch dataloaders\n",
        "\n",
        "  Args:\n",
        "    train_dataset: torch.tensor\n",
        "      Training data\n",
        "    test_dataset: torch.tensor\n",
        "      Test data\n",
        "    batch_size: int\n",
        "      Batch Size\n",
        "    seed: int\n",
        "      Set seed for reproducibility\n",
        "\n",
        "  Returns:\n",
        "    emnist_train: torch.loader\n",
        "      Training Data\n",
        "    emnist_test: torch.loader\n",
        "      Test Data\n",
        "  \"\"\"\n",
        "  g_seed = torch.Generator()\n",
        "  g_seed.manual_seed(seed)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=2,\n",
        "                            worker_init_fn=seed_worker,\n",
        "                            generator=g_seed)\n",
        "  test_loader = DataLoader(test_dataset,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=True,\n",
        "                           num_workers=2,\n",
        "                           worker_init_fn=seed_worker,\n",
        "                           generator=g_seed)\n",
        "\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {},
        "id": "tUsc5ark5Q9m"
      },
      "outputs": [],
      "source": [
        "emnist_train, emnist_test = get_Xvs0_dataset(normalize=False, download=False)\n",
        "train_loader, test_loader = get_data_loaders(emnist_train, emnist_test,\n",
        "                                             seed=SEED)\n",
        "\n",
        "# Index of an image in the dataset that corresponds to an X and O\n",
        "x_img_idx = 4\n",
        "o_img_idx = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "zjhN7lSI5Q9n"
      },
      "source": [
        "Let's view a couple samples from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ti0dmIWLWUGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "fF2d247P5Q9n",
        "outputId": "53d5075b-359a-4567-a575-2b194e1954ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1175,
              "height": 289
            }
          }
        }
      ],
      "source": [
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(12, 6))\n",
        "ax1.imshow(emnist_train[0][0].reshape(28, 28), cmap='gray')\n",
        "ax2.imshow(emnist_train[10][0].reshape(28, 28), cmap='gray')\n",
        "ax3.imshow(emnist_train[4][0].reshape(28, 28), cmap='gray')\n",
        "ax4.imshow(emnist_train[6][0].reshape(28, 28), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3X_VP5z15Q9n"
      },
      "source": [
        "## Interactive Demo 3: Visualization of Convolution with Multiple Filters\n",
        "\n",
        "Change the number of input channels (e.g., the color channels of an image or the output channels of a previous layer) and the output channels (number of different filters to apply)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Rj2ym3Jo5Q9n"
      },
      "source": [
        "**Important:** Change the bool variable `run_demo` to `True` by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "QEcDIpIb5Q9n",
        "outputId": "e40876e7-1217-4944-ccfc-e48ea23cbd52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "    <style>\n",
              "        svg {\n",
              "            #border: 1px solid black;\n",
              "        }\n",
              "    .matrix {\n",
              "        font-family: sans-serif;\n",
              "        transition: all 700ms ease-in-out;\n",
              "    }\n",
              "    .cell rect {\n",
              "        fill:white;stroke-width:1;stroke:rgb(0,0,0)\n",
              "    }\n",
              "    .padding rect {\n",
              "        stroke: rgba(0, 0, 0, 0.25);\n",
              "    }\n",
              "    .padding text {\n",
              "        fill: lightgray;\n",
              "    }\n",
              "    .highlight1 {\n",
              "        fill:none;stroke-width:4;stroke: rgb(236, 58, 58);stroke-dasharray:10,5;\n",
              "    }\n",
              "    .highlight2 {\n",
              "        fill:rgba(229, 132, 66, 0.25);stroke-width:5;stroke: rgb(229, 132, 66);\n",
              "    }\n",
              "    .highlight3 {\n",
              "        fill:rgba(236, 58, 58, 0.25);stroke-width:2;stroke: rgb(236, 58, 58);;\n",
              "    }\n",
              "    .title {\n",
              "        text-anchor: middle;\n",
              "    }\n",
              "    .button_play {\n",
              "        display: inline-block;\n",
              "        background: none;\n",
              "        border: none;\n",
              "        position: relative;\n",
              "        top: -3px;\n",
              "    }\n",
              "    .button_play path {\n",
              "        fill: darkgray;\n",
              "    }\n",
              "    .button_play:hover path {\n",
              "        fill: rgb(236, 58, 58);\n",
              "    }\n",
              "    .display_vis_input input:not(:hover)::-webkit-outer-spin-button,\n",
              "    .display_vis_input input:not(:hover)::-webkit-inner-spin-button {\n",
              "        /* display: none; <- Crashes Chrome on hover */\n",
              "        -webkit-appearance: none;\n",
              "        margin: 0; /* <-- Apparently some margin are still there even though it's hidden */\n",
              "    }\n",
              "\n",
              "    .display_vis_input input:not(:hover)[type=number] {\n",
              "        -moz-appearance:textfield; /* Firefox */\n",
              "        width: 1ch;\n",
              "        margin-right: 0px;\n",
              "        z-index: 0;\n",
              "    }\n",
              "    .display_vis_input input[type=number] {\n",
              "        width: 4ch;\n",
              "        border: 0px;\n",
              "        margin-right: -3ch;\n",
              "        z-index: 6;\n",
              "        display: inline-block;\n",
              "        position: relative;\n",
              "        padding: 0;\n",
              "        border-bottom: 2px solid red;\n",
              "        background: white;\n",
              "        color: black\n",
              "    }\n",
              "    .display_vis_input .pair {\n",
              "        display: inline-block;\n",
              "        white-space:nowrap;\n",
              "            position: relative;\n",
              "    }\n",
              "    .display_vis_input .pair .pair_hide {\n",
              "        max-width: 4em;\n",
              "        transition: max-width 1s ease-in;\n",
              "        display: inline-block;\n",
              "        overflow: hidden;\n",
              "        position: relative;\n",
              "        top: 5px;\n",
              "    }\n",
              "    .pair:not(:hover) .pair_hide {\n",
              "        max-width: 0;\n",
              "    }\n",
              "    .pairX .pair_hide {\n",
              "        max-width: 4em;\n",
              "        transition: max-width 1s ease-in;\n",
              "    }\n",
              "\n",
              "    /* Dropdown Button */\n",
              "    .dropbtn {\n",
              "      border-bottom: 2px solid red;\n",
              "    }\n",
              "\n",
              "    /* The container <div> - needed to position the dropdown content */\n",
              "    .dropdown {\n",
              "      position: relative;\n",
              "      display: inline-block;\n",
              "    }\n",
              "\n",
              "    /* Dropdown Content (Hidden by Default) */\n",
              "    .dropdown-content {\n",
              "      display: none;\n",
              "      position: absolute;\n",
              "      background-color: #f1f1f1;\n",
              "      min-width: 160px;\n",
              "      box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);\n",
              "      z-index: 1;\n",
              "    }\n",
              "\n",
              "    /* Links inside the dropdown */\n",
              "    .dropdown-content a {\n",
              "      color: black;\n",
              "      padding: 5px 2px;\n",
              "      text-decoration: none;\n",
              "      display: block;\n",
              "    }\n",
              "\n",
              "    /* Change color of dropdown links on hover */\n",
              "    .dropdown-content a:hover {background-color: #ddd;}\n",
              "\n",
              "    /* Show the dropdown menu on hover */\n",
              "    .dropdown:hover .dropdown-content {display: block;}\n",
              "\n",
              "    </style>\n",
              "    <script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\" > </script>\n",
              "\n",
              "\n",
              "    <div id=\"animation_conv_filters\" style=\"background: white\">\n",
              "        <div class=\"display_vis_input language-python\" style=\"font-family: monospace; color: black; padding: 10px;\">\n",
              "            import torch<br><br>\n",
              "            input = torch.rand(1, <input class=\"input_matrixz\" type=\"number\" min=\"1\" max=\"3\" value=\"3\">, <input class=\"input_matrixx\" type=\"number\" min=\"3\" max=\"5\" value=\"4\">, <input class=\"input_matrixy\" type=\"number\" min=\"3\" max=\"5\" value=\"4\">)<br>\n",
              "            conv = torch.nn.Conv2d(in_channels=<input class=\"input_matrixzB\" type=\"number\" min=\"1\" max=\"3\" value=\"3\">, out_channels=<input class=\"input_filterz\" type=\"number\" min=\"1\" max=\"3\" value=\"2\">,\n",
              "            kernel_size=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_filterx\" type=\"number\" min=\"2\" max=\"4\" value=\"2\"><span class=\"pair_hide\">,\n",
              "                                                                           <input class=\"input_filtery\" type=\"number\" min=\"2\" max=\"4\" value=\"2\">)</span></span>,\n",
              "            stride=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_stridex\" type=\"number\" min=\"1\" max=\"2\" value=\"1\"><span class=\"pair_hide\">,\n",
              "                                                                      <input class=\"input_stridey\" type=\"number\" min=\"1\" max=\"2\" value=\"1\">)</span></span>,\n",
              "            padding=<span class=\"pair\"><span class=\"pair_hide\">(</span><input class=\"input_paddingx\" type=\"number\" min=\"0\" max=\"4\" value=\"0\"><span class=\"pair_hide\">,\n",
              "                                                                       <input class=\"input_paddingy\" type=\"number\" min=\"0\" max=\"4\" value=\"0\">)</span></span>)<br>\n",
              "            result = conv(input)\n",
              "\n",
              "        </div>\n",
              "        <button class=\"button_play play\"><svg width=\"15\" height=\"15\" viewbox=\"0 0 10 10\"><path d=\"M 1.5,0 9.5,5 1.5,10 z\"/></svg></button>\n",
              "        <button class=\"button_play pause\" style=\"display: none\"><svg width=\"15\" height=\"15\" viewbox=\"0 0 10 10\"><path d=\"M 0,0 4,0 4,10, 0,10 z\"/><path d=\"M 6,0 10,0 10,10, 6,10 z\"/></svg></button>\n",
              "        <input type=\"range\" min=\"1\" max=\"100\" value=\"50\" class=\"slider\" style=\"width: 300px; display: inline-block\">\n",
              "        <button class=\"button_play left\"><svg width=\"7\" height=\"15\" viewbox=\"0 0 4 10\"><path d=\"M 0,5 4,0 4,10 z\"/></svg></button>\n",
              "        <button class=\"button_play right\"><svg width=\"7\" height=\"15\" viewbox=\"0 0 4 10\"><path d=\"M 0,0 4,5 0,10 z\"/></svg></button>\n",
              "        <input type=\"checkbox\" class=\"play_fast\">fast play mode\n",
              "        <br/>\n",
              "        <svg height=\"0\" width=\"0\">\n",
              "            <defs>\n",
              "            <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\"\n",
              "            refX=\"0\" refY=\"1.5\" orient=\"auto\" fill=\"rgb(236, 58, 58)\">\n",
              "            <polygon points=\"0 0, 4 1.5, 0 3\" />\n",
              "            </marker>\n",
              "            </defs>\n",
              "        </svg>\n",
              "        <svg class=\"image\" height=\"460\" width=\"600\"></svg>\n",
              "    </div>\n",
              "    \n",
              "<script>\n",
              "    (function() {\n",
              "    var dom_target = document.getElementById(\"animation_conv_filters\")\n",
              "    const divmod = (x, y) => [Math.floor(x / y), x % y];\n",
              "    var svg = d3.select(dom_target).select(\".image\")\n",
              "\n",
              "    var box_s = 50;\n",
              "    var box_z = 10;\n",
              "    var show_single_elements = true;\n",
              "    var group_func = undefined;\n",
              "    function mulberry32(a) {\n",
              "        return function() {\n",
              "          var t = a += 0x6D2B79F5;\n",
              "          t = Math.imul(t ^ t >>> 15, t | 1);\n",
              "          t ^= t + Math.imul(t ^ t >>> 7, t | 61);\n",
              "          return ((t ^ t >>> 14) >>> 0) / 4294967296;\n",
              "        }\n",
              "    }\n",
              "\n",
              "    function numberGenerator(seed, max, digits) {\n",
              "        var random = mulberry32(seed)\n",
              "        return () => parseFloat((random() * max).toFixed(digits));\n",
              "    }\n",
              "    window.numberGenerator = numberGenerator\n",
              "    window.mulberry32 = mulberry32\n",
              "    function generateMatrix2(number, dims) {\n",
              "        var res = [];\n",
              "        for (var i = 0; i < dims[0]; i++) {\n",
              "            if(dims.length == 1)\n",
              "                res.push(number())\n",
              "            else\n",
              "                res.push(generateMatrix2(number, dims.slice(1)));\n",
              "        }\n",
              "        return res\n",
              "    }\n",
              "    window.generateMatrix2 = generateMatrix2\n",
              "\n",
              "    function addPadding(matrix, paddingx, paddingy) {\n",
              "        matrix = JSON.parse(JSON.stringify(matrix));\n",
              "        var ly = matrix.length; var lx = matrix[0].length;\n",
              "        for (var i = 0; i < ly; i++) {\n",
              "            for(var p = 0; p < paddingx; p++) {\n",
              "                matrix[i].splice(0, 0, 0);\n",
              "                matrix[i].splice(matrix[i].length, 0, 0);\n",
              "            }\n",
              "        }\n",
              "        for(var p = 0; p < paddingy; p++) {\n",
              "            matrix.splice(0, 0, []);\n",
              "            matrix.splice(matrix.length, 0, []);\n",
              "            for (var i = 0; i < lx + paddingx * 2; i++) {\n",
              "                matrix[0].push(0);\n",
              "                matrix[matrix.length - 1].push(0);\n",
              "            }\n",
              "        }\n",
              "        matrix.paddingx = paddingx;\n",
              "        matrix.paddingy = paddingy;\n",
              "        return matrix;\n",
              "    }\n",
              "\n",
              "    var stride_x = 1;\n",
              "    var stride_y = 1;\n",
              "    function convolve(matrix, filter) {\n",
              "        var ress = [];\n",
              "        for(var zz = 0; zz < filter.length; zz++) {\n",
              "            var res = [];\n",
              "            for (var i = 0; i < parseInt((matrix[0].length - filter[0][0].length + stride_y) / stride_y); i++) {\n",
              "                res.push([]);\n",
              "                for (var j = 0; j < parseInt((matrix[0][0].length - filter[0][0][0].length + stride_x) / stride_x); j++) {\n",
              "                    var answer = 0;\n",
              "                    var text = \"\";\n",
              "                    for (var ii = 0; ii < filter[0][0].length; ii++) {\n",
              "                        for (var jj = 0; jj < filter[0][0][0].length; jj++) {\n",
              "                            for (var z = 0; z < matrix.length; z++) {\n",
              "                                answer += matrix[z][i * stride_y + ii][j * stride_x + jj] * filter[zz][z][ii][jj];\n",
              "                                text +=matrix[z][i * stride_y + ii][j * stride_x + jj] + \"*\" + filter[zz][z][ii][jj]+\"+\";\n",
              "                            }\n",
              "                        }\n",
              "                    }\n",
              "                    console.log(i, j, text, \"=\", answer)\n",
              "                    res[res.length - 1].push(answer.toFixed(1))\n",
              "                }\n",
              "            }\n",
              "            ress.push(res)\n",
              "        }\n",
              "        return ress;\n",
              "    }\n",
              "    function pool(matrix, filter, func) {\n",
              "        var res = [];\n",
              "        for (var i = 0; i < parseInt((matrix.length - filter.length + stride_y) / stride_y); i++) {\n",
              "            res.push([]);\n",
              "            for (var j = 0; j < parseInt((matrix[0].length - filter[0].length + stride_x) / stride_x); j++) {\n",
              "                var answer = [];\n",
              "                for(var ii = 0; ii < filter.length; ii++) {\n",
              "                    for(var jj = 0; jj < filter[0].length; jj++) {\n",
              "                        answer.push(matrix[i* stride_y + ii][j* stride_x + jj]);\n",
              "                    }\n",
              "                }\n",
              "                if(func == \"max\")\n",
              "                    res[res.length-1].push(Math.max(...answer))\n",
              "                else {\n",
              "                    var sum = 0;\n",
              "                    for( var ii = 0; ii < answer.length; ii++)\n",
              "                        sum += answer[ii]; //don't forget to add the base\n",
              "                    var avg = sum/answer.length;\n",
              "                    res[res.length-1].push(parseFloat(avg.toFixed(1)));\n",
              "                }\n",
              "\n",
              "            }\n",
              "        }\n",
              "        return res;\n",
              "    }\n",
              "\n",
              "    class Matrix {\n",
              "        constructor(x, y, matrix, title) {\n",
              "            this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`);\n",
              "            for(var z = 0; z < matrix.length; z++) {\n",
              "                var gg = this.g.append(\"g\").attr(\"class\", \"matrix_layer\").attr(\"transform\", `translate(${- z*box_z}, ${+ z*box_z})`);\n",
              "                for (var j = 0; j < matrix[0].length; j++) {\n",
              "                    for (var i = 0; i < matrix[0][0].length; i++) {\n",
              "                        var element = gg.append(\"g\").attr(\"class\", \"cell\").attr(\"transform\", `translate(${i * box_s}, ${j * box_s})`);\n",
              "                        var rect = element.append(\"rect\")\n",
              "                            .attr(\"class\", \"number\")\n",
              "                            .attr(\"x\", -box_s / 2 + \"px\")\n",
              "                            .attr(\"y\", -box_s / 2 + \"px\")\n",
              "                            .attr(\"width\", box_s + \"px\")\n",
              "                            .attr(\"height\", box_s + \"px\")\n",
              "                        if (i < matrix.paddingx || j < matrix.paddingy || i > matrix[0][0].length - matrix.paddingx - 1 || j > matrix[0].length - matrix.paddingy - 1)\n",
              "                            element.attr(\"class\", \"cell padding\")\n",
              "                        element.append(\"text\").text(matrix[z][j][i]).attr(\"text-anchor\", \"middle\").attr(\"alignment-baseline\", \"center\").attr(\"dy\", \"0.3em\")\n",
              "                    }\n",
              "                }\n",
              "                gg.append(\"rect\").attr(\"class\", \"highlight3\")\n",
              "                gg.append(\"rect\").attr(\"class\", \"highlight1\")\n",
              "                gg.append(\"rect\").attr(\"class\", \"highlight2\")\n",
              "            }\n",
              "            this.arrow = gg.append(\"line\").attr(\"transform\", `translate(${(-0.5)*box_s}, ${(-0.5+filter.length/2)*box_s})`).attr(\"marker-end\", \"url(#arrowhead)\").attr(\"x1\", 0).attr(\"y1\", 0).attr(\"x2\", 50).attr(\"y2\", 0)\n",
              "                .attr(\"stroke\", \"#000\").attr(\"stroke-width\", 8).attr(\"stroke\", \"rgb(236, 58, 58)\").style(\"opacity\", 0)\n",
              "\n",
              "\n",
              "            gg.append(\"text\").attr(\"class\", \"title\").text(title)\n",
              "                .attr(\"x\", (matrix[0][0].length/2-0.5)*box_s+\"px\")\n",
              "                .attr(\"y\", (matrix[0].length)*box_s+\"px\")\n",
              "                .attr(\"dy\", \"0em\")\n",
              "            this.highlight2_hidden = true\n",
              "        }\n",
              "\n",
              "        setHighlight1(i, j, w, h) {\n",
              "            if(this.old_i == i && this.old_j == j && this.old_w == w)\n",
              "                return\n",
              "            if(i == this.old_i+stride_x || j == this.old_j+stride_y) {\n",
              "                if (this.old_j == j)\n",
              "                    this.arrow.attr(\"x1\", this.old_i * box_s).attr(\"y1\", j * box_s)\n",
              "                        .attr(\"x2\", i * box_s - 30).attr(\"y2\", j * box_s).attr(\"transform\", `translate(${(-0.5) * box_s}, ${(-0.5 + h / 2) * box_s})`)\n",
              "                else\n",
              "                    this.arrow.attr(\"x1\", i * box_s).attr(\"y1\", this.old_j * box_s)\n",
              "                        .attr(\"x2\", i * box_s).attr(\"y2\", j * box_s - 30).attr(\"transform\", `translate(${(-0.5 + w / 2) * box_s}, ${(-0.5) * box_s})`)\n",
              "                this.arrow.transition().style(\"opacity\", 1)\n",
              "                    .transition()\n",
              "                    .duration(1000)\n",
              "                    .style(\"opacity\", 0)\n",
              "            }\n",
              "            this.old_i = i; this.old_j = j; this.old_w = w;\n",
              "            this.g.selectAll(\".highlight1\")\n",
              "                .style(\"fill\", \"rgba(236, 58, 58, 0)\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\")\n",
              "                .style(\"fill\", \"rgba(236, 58, 58, 0.25)\")\n",
              "            this.g.selectAll(\".highlight3\")\n",
              "                .style(\"opacity\", 1)\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .style(\"opacity\", 0)\n",
              "            this.g.selectAll(\".highlight3\")\n",
              "                .transition()\n",
              "                .delay(900)\n",
              "                .duration(0)\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\")\n",
              "        }\n",
              "\n",
              "        setHighlight2(i, j, w, h) {\n",
              "            if(this.highlight2_hidden == true) {\n",
              "                this.g.selectAll(\".highlight2\")\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .style(\"opacity\", 1)\n",
              "                this.highlight2_hidden = false\n",
              "                return\n",
              "            }\n",
              "            this.g.selectAll(\".highlight2\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"x\", (-box_s/2+i*box_s)+\"px\").attr(\"y\", (-box_s/2+j*box_s)+\"px\")\n",
              "                .attr(\"width\", box_s*w+\"px\")\n",
              "                .attr(\"height\", box_s*h+\"px\");\n",
              "        }\n",
              "        hideHighlight2() {\n",
              "            this.highlight2_hidden = true\n",
              "            this.g.selectAll(\".highlight2\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .style(\"opacity\", 0)\n",
              "        }\n",
              "    }\n",
              "\n",
              "    class Calculation {\n",
              "        constructor(x, y, matrix, title) {\n",
              "            this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`)\n",
              "            this.g.append(\"text\").text(title).attr(\"dy\", \"-1.5em\").attr(\"dx\", \"2em\")\n",
              "            this.g = this.g.append(\"text\")\n",
              "            for (var j in matrix) {\n",
              "                for (var i in matrix[j]) {\n",
              "                    var element = this.g;\n",
              "                    var a = element.append(\"tspan\")\n",
              "                        .text(i+\"·\"+j)\n",
              "                    if(i == 0 && j > 0)\n",
              "                        a.attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                    if(i == matrix[0].length - 1 && j == matrix.length - 1) {\n",
              "                        a = element.append(\"tspan\")\n",
              "                        .attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                        .text(\" = 12 \")\n",
              "                    }\n",
              "                    else {\n",
              "                        a = element.append(\"tspan\")\n",
              "                            .text(\" + \")\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "        setText(i, text) {\n",
              "            d3.select(this.g.selectAll(\"tspan\")[0][i*2]).text(text)\n",
              "        }\n",
              "        hideAll() {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .attr(\"fill\", \"white\")\n",
              "        }\n",
              "        setHighlight1(i) {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"fill\",\n",
              "                (d, ii) => ii==i*2 ? \"rgb(229, 132, 66)\" : ii> i*2 ? \"white\" : \"black\")\n",
              "        }\n",
              "    }\n",
              "\n",
              "    class CalculationPool {\n",
              "        constructor(x, y, matrix, title) {\n",
              "            this.g = svg.append(\"g\").attr(\"class\", \"matrix\").attr(\"transform\", `translate(${x}, ${y})`)\n",
              "            this.g.append(\"text\").text(title).attr(\"dy\", \"-3em\").attr(\"dx\", \"-2em\")\n",
              "            this.g.append(\"text\").text(group_func+\"([\").attr(\"dy\", \"-1.5em\").attr(\"dx\", \"-0.5em\")\n",
              "            this.g = this.g.append(\"text\")\n",
              "            for (var j in matrix) {\n",
              "                for (var i in matrix[j]) {\n",
              "                    var element = this.g;\n",
              "                    var a = element.append(\"tspan\")\n",
              "                        .text(\"\")\n",
              "                    if(i == 0 && j > 0)\n",
              "                        a.attr(\"dy\", \"1.5em\").attr(\"x\", 0)\n",
              "                    if(i == matrix[0].length - 1 && j == matrix.length - 1) {\n",
              "                        a = element.append(\"tspan\")\n",
              "                        .attr(\"dy\", \"1.5em\").attr(\"x\", 0).attr(\"dx\", \"-0.5em\")\n",
              "                        .text(\"\")\n",
              "                    }\n",
              "                    else {\n",
              "                        a = element.append(\"tspan\")\n",
              "                            .text(\"\")\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "        setText(i, text) {\n",
              "            d3.select(this.g.selectAll(\"tspan\")[0][i*2]).text(text)\n",
              "        }\n",
              "        hideAll() {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .attr(\"fill\", \"white\")\n",
              "        }\n",
              "        setHighlight1(i) {\n",
              "            this.g.selectAll(\"tspan\")\n",
              "                .transition()\n",
              "                .duration(1000)\n",
              "                .attr(\"fill\",\n",
              "                (d, ii) => ii==i*2 ? \"rgb(229, 132, 66)\" : ii> i*2 ? \"white\" : \"black\")\n",
              "        }\n",
              "    }\n",
              "\n",
              "    var matrix, res, m, f, r, c, last_pos, index_max;\n",
              "    function init() {\n",
              "        show_single_elements = dom_target.querySelector(\".play_fast\").checked == false\n",
              "        svg.selectAll(\"*\").remove();\n",
              "        dom_target.querySelector(\".input_matrixzB\").value = dom_target.querySelector(\".input_matrixz\").value\n",
              "\n",
              "        console.log(\"dom_target\", dom_target)\n",
              "        console.log(\"dom_target.querySelector(\\\".input_filterx\\\").value)\", dom_target.querySelector(\".input_filterx\").value)\n",
              "        filter = generateMatrix2(numberGenerator(17, 0.9, 1), [parseInt(dom_target.querySelector(\".input_filterz\").value), parseInt(dom_target.querySelector(\".input_matrixz\").value), parseInt(dom_target.querySelector(\".input_filtery\").value), parseInt(dom_target.querySelector(\".input_filterx\").value)]);\n",
              "        if(dom_target.querySelector(\".input_filterx\").value == dom_target.querySelector(\".input_filtery\").value)\n",
              "            dom_target.querySelector(\".input_filterx\").parentElement.className = \"pair\"\n",
              "        else\n",
              "            dom_target.querySelector(\".input_filterx\").parentElement.className = \"pairX\"\n",
              "        matrix_raw = generateMatrix2(numberGenerator(4, 9, 0), [parseInt(dom_target.querySelector(\".input_matrixz\").value), parseInt(dom_target.querySelector(\".input_matrixy\").value), parseInt(dom_target.querySelector(\".input_matrixx\").value)]);\n",
              "\n",
              "        matrix = JSON.parse(JSON.stringify(matrix_raw));\n",
              "        for(var z = 0; z < matrix.length; z++)\n",
              "            matrix[z] = addPadding(matrix_raw[z], parseInt(dom_target.querySelector(\".input_paddingx\").value), parseInt(dom_target.querySelector(\".input_paddingy\").value));\n",
              "        matrix.paddingx = matrix[0].paddingx\n",
              "        matrix.paddingy = matrix[0].paddingy\n",
              "        stride_x = parseInt(dom_target.querySelector(\".input_stridex\").value)\n",
              "        stride_y = parseInt(dom_target.querySelector(\".input_stridey\").value)\n",
              "\n",
              "        if(dom_target.querySelector(\".input_stridex\").value == dom_target.querySelector(\".input_stridey\").value)\n",
              "            dom_target.querySelector(\".input_stridex\").parentElement.className = \"pair\"\n",
              "        else\n",
              "            dom_target.querySelector(\".input_stridex\").parentElement.className = \"pairX\"\n",
              "            if(dom_target.querySelector(\".input_paddingx\").value == dom_target.querySelector(\".input_paddingy\").value)\n",
              "            dom_target.querySelector(\".input_paddingx\").parentElement.className = \"pair\"\n",
              "        else\n",
              "            dom_target.querySelector(\".input_paddingx\").parentElement.className = \"pairX\"\n",
              "\n",
              "        res = convolve(matrix, filter);\n",
              "            window.matrix = matrix\n",
              "            window.filter = filter\n",
              "            window.res = res\n",
              "        if(group_func != undefined)\n",
              "            res = [pool(matrix[0], filter[0][0], group_func)]\n",
              "\n",
              "        m = new Matrix(1*box_s, (1+filter[0][0].length+1.5)*box_s, matrix, \"Matrix\");\n",
              "\n",
              "        f = []\n",
              "        for(var zz = 0; zz < filter.length; zz++)\n",
              "            f.push(new Matrix((1+(matrix[0][0].length-filter[zz][0][0].length)/2 + zz*(1+filter[zz][0][0].length))*box_s, 1*box_s, filter[zz], group_func == undefined ? (filter.length != 1? `Filter ${zz}` : `Filter`) : \"Pooling\"));\n",
              "        if(group_func != undefined)\n",
              "            f[0].g.selectAll(\".cell text\").attr(\"fill\", \"white\")\n",
              "\n",
              "        console.log(\"res\", res)\n",
              "        r = new Matrix((2+(matrix[0][0].length)+1)*box_s, (1+filter[0][0].length+1.5)*box_s, res, \"Result\");\n",
              "\n",
              "        var c_x = Math.max((1+(matrix[0][0].length))*box_s, (3+filter.length*(1+(filter[0][0].length)))*box_s)\n",
              "        console.log(\"m,ax\", (1+(matrix[0][0].length)), filter.length*(1+(filter[0][0].length)))\n",
              "        if(group_func != undefined)\n",
              "            c = new CalculationPool(c_x, (1+0.5)*box_s, filter[0][0], \"Calculation\");\n",
              "        else\n",
              "            c = new Calculation(c_x, (1+0.5)*box_s, filter[0][0], \"Calculation\");\n",
              "\n",
              "        last_pos = undefined;\n",
              "        if(show_single_elements)\n",
              "            index_max = filter.length*res[0].length*res[0][0].length*(filter[0][0].length * filter[0][0][0].length * filter[0].length + 2)\n",
              "        else\n",
              "            index_max = filter.length*res[0].length*res[0][0].length\n",
              "        window.index_max = index_max\n",
              "        window.filter = filter\n",
              "        setHighlights(0, 0)\n",
              "        svg.attr(\"width\", box_s*(matrix[0][0].length+res[0][0].length+4)+(c.g.node().getBoundingClientRect().width)+\"px\");\n",
              "        svg.attr(\"height\", box_s*(matrix[0].length+filter[0][0].length+3.0)+\"px\");\n",
              "    }\n",
              "    init()\n",
              "\n",
              "    function setHighlights(pos_zz, subpos) {\n",
              "        var [zz, pos] = divmod(pos_zz, res[0].length*res[0][0].length)\n",
              "        var [i, j] = divmod(pos, res[0][0].length)\n",
              "        i *= stride_y;\n",
              "        j *= stride_x;\n",
              "        var [j2, i2] = divmod(subpos, filter[0][0][0].length * filter[0].length)\n",
              "        var [i2, z2] = divmod(i2, filter[0].length)\n",
              "        subpos = Math.floor(subpos/filter[0].length)\n",
              "        console.log(zz, i, j, j2, i2, z2)\n",
              "        if(last_pos != pos || 1) {\n",
              "            var answer = 0;\n",
              "            for(var ii = 0; ii < filter[0][0].length; ii++) {\n",
              "                for(var jj = 0; jj < filter[0][0][0].length; jj++) {\n",
              "                    var text = []\n",
              "                    if(filter[0].length == 1) {\n",
              "                        for(var z = 0; z < filter[0].length; z++) {\n",
              "                            if (group_func != undefined)\n",
              "                                text.push(matrix[0][i + ii][j + jj] + \", \");\n",
              "                            else\n",
              "                                text.push(matrix[z][i + ii][j + jj] + \" · \" + filter[zz][z][ii][jj]);\n",
              "                        }\n",
              "                        if (group_func != undefined)\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, text.join(\", \"));\n",
              "                        else\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, text.join(\"+\"));\n",
              "                    }\n",
              "                    else {\n",
              "                        let max_z = (ii == j2 && jj == i2) ? z2+1 : filter[0].length\n",
              "                        for (var z = 0; z < max_z; z++) {\n",
              "                            if (group_func != undefined)\n",
              "                                text.push(matrix[0][i + ii][j + jj] + \", \");\n",
              "                            else\n",
              "                                text.push(matrix[z][i + ii][j + jj] + \"·\" + filter[zz][z][ii][jj]);\n",
              "                            console.log(z, z2, text)\n",
              "                        }\n",
              "                        console.log(\"----------\")\n",
              "                        if (group_func != undefined)\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, text.join(\", \"));\n",
              "                        else\n",
              "                            c.setText(ii * filter[0][0][0].length + jj, \"(\" + text.join(\"+\") + ((filter[0].length==max_z)?\")\":\"\"));\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "            if(group_func != undefined)\n",
              "                c.setText(filter[0][0].length * filter[0][0][0].length - 0.5, \"   ]) = \"+res[zz][i/stride_y][j/stride_x])\n",
              "            else\n",
              "                c.setText(filter[0][0].length * filter[0][0][0].length - 0.5, \"   = \"+res[zz][i/stride_y][j/stride_x])\n",
              "            if(last_pos != pos)\n",
              "                c.hideAll();\n",
              "            last_pos = pos;\n",
              "        }\n",
              "        m.setHighlight1(j, i, filter[0][0][0].length, filter[0][0].length)\n",
              "        for(var zzz = 0; zzz < filter.length; zzz++) {\n",
              "            console.log(zzz, zz, zzz == zz)\n",
              "            if (zzz == zz)\n",
              "                f[zzz].setHighlight1(0, 0, filter[0][0][0].length, filter[0][0].length)\n",
              "            else\n",
              "                f[zzz].setHighlight1(0, 0, 0, 0)\n",
              "        }\n",
              "        window.f = f\n",
              "\n",
              "        r.setHighlight1(j/stride_x, i/stride_y, 1, 1)\n",
              "        r.g.selectAll(\".matrix_layer\").attr(\"opacity\", (d,i) => i > zz ? 0.2 : 1 )\n",
              "        r.g.selectAll(\".matrix_layer .highlight1\").attr(\"visibility\", (d,i)=>i==zz ? \"visible\" : \"hidden\")\n",
              "        r.g.selectAll(\".matrix_layer .highlight3\").attr(\"visibility\", (d,i)=>i==zz ? \"visible\" : \"hidden\")\n",
              "        window.r = r\n",
              "\n",
              "        let matrixpos = (i + j2) * matrix[0][0].length + (j + i2)\n",
              "        m.g.selectAll(\".matrix_layer\").each(function(p, j){\n",
              "            console.log(d3.select(this).select(\"highlight2\"))\n",
              "            d3.select(this).selectAll(\".cell\").attr(\"opacity\", (d,i) => (i == matrixpos && j > z2 && subpos < filter[0][0].length * filter[0][0][0].length) ? 0 : 1 );\n",
              "            d3.select(this).select(\".highlight2\").style(\"stroke\", (d,i) => (j != z2) ? \"transparent\" : \"rgb(229, 132, 66)\");\n",
              "        })\n",
              "        f[zz].g.selectAll(\".matrix_layer\").each(function(p, j){\n",
              "            console.log(d3.select(this).select(\"highlight2\"), subpos, i2, j2, z2)\n",
              "            d3.select(this).selectAll(\".cell\").attr(\"opacity\", (d,i) => (i == subpos && j > z2 && subpos < filter[0][0].length * filter[0][0][0].length) ? 0 : 1 );\n",
              "            d3.select(this).select(\".highlight2\").style(\"stroke\", (d,i) => (j != z2) ? \"transparent\" : \"rgb(229, 132, 66)\");\n",
              "        })\n",
              "\n",
              "        if(subpos < filter[0][0].length * filter[0][0][0].length) {\n",
              "            m.setHighlight2(j + i2, i + j2, 1, 1)\n",
              "            if(group_func == undefined)\n",
              "                for(var zzz = 0; zzz < filter.length; zzz++) {\n",
              "                    if (zzz == zz)\n",
              "                        f[zzz].setHighlight2(i2, j2, 1, 1)\n",
              "                    else\n",
              "                        f[zzz].hideHighlight2()\n",
              "                }\n",
              "            r.g.selectAll(\".cell text\").attr(\"fill\", (d, i) => i >= pos_zz ? \"white\" : \"black\")\n",
              "            c.setHighlight1(subpos);\n",
              "        }\n",
              "        else {\n",
              "            m.hideHighlight2()\n",
              "            for(var zzz = 0; zzz < filter.length; zzz++)\n",
              "                f[zzz].hideHighlight2()\n",
              "            r.g.selectAll(\".cell text\").attr(\"fill\", (d, i) => i > pos_zz ? \"white\" : \"black\")\n",
              "            if(subpos > filter[0][0].length * filter[0][0][0].length) {\n",
              "                c.hideAll()\n",
              "            }\n",
              "            else\n",
              "                c.setHighlight1(subpos);\n",
              "        }\n",
              "\n",
              "        function p(x) { console.log(x); return x}\n",
              "    }\n",
              "    function animate(frame) {\n",
              "        dom_target.querySelector(\"input[type=range]\").value = index;\n",
              "        dom_target.querySelector(\"input[type=range]\").max = index_max - 1;\n",
              "        dom_target.querySelector(\"input[type=range]\").min = 0;\n",
              "        if(show_single_elements) {\n",
              "            var [pos, subpos] = divmod(frame, filter[0][0].length * filter[0][0][0].length * filter[0].length + 2)\n",
              "            setHighlights(pos, subpos);\n",
              "        }\n",
              "        else\n",
              "            setHighlights(frame, filter[0][0].length * filter[0][0][0].length * filter[0].length);\n",
              "    }\n",
              "    var index = -1\n",
              "    animate(0)\n",
              "    var interval = undefined;\n",
              "\n",
              "    function PlayStep() {\n",
              "        index += 1;\n",
              "        if(index >= index_max)\n",
              "            index = 0;\n",
              "        animate(index);\n",
              "    }\n",
              "\n",
              "    function playPause() {\n",
              "        if(interval === undefined) {\n",
              "            dom_target.querySelector(\".play\").style.display = \"none\"\n",
              "            dom_target.querySelector(\".pause\").style.display = \"inline-block\"\n",
              "            interval = window.setInterval(PlayStep, 1000);\n",
              "            PlayStep();\n",
              "        }\n",
              "        else {\n",
              "            dom_target.querySelector(\".play\").style.display = \"inline-block\"\n",
              "            dom_target.querySelector(\".pause\").style.display = \"none\"\n",
              "            window.clearInterval(interval);\n",
              "            interval = undefined;\n",
              "        }\n",
              "    }\n",
              "    dom_target.querySelector(\"input[type=range]\").value = 0;\n",
              "    dom_target.querySelector(\"input[type=range]\").max = index_max;\n",
              "    dom_target.querySelector(\"input[type=range]\").onchange = (i)=>{var v = parseInt(i.target.value); index = v; animate(v);};\n",
              "    dom_target.querySelector(\".play\").onclick = playPause;\n",
              "    dom_target.querySelector(\".pause\").onclick = playPause;\n",
              "    dom_target.querySelector(\".left\").onclick = ()=>{index > 0 ? index -= 1 : index = index_max-1; animate(index);};\n",
              "    dom_target.querySelector(\".right\").onclick = ()=>{index < index_max-1 ? index += 1 : index = 0; animate(index);};\n",
              "\n",
              "    dom_target.querySelector(\".input_filterx\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_filtery\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_filterz\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixx\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixy\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixz\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_matrixzB\").onchange = (i)=>{dom_target.querySelector(\".input_matrixz\").value = parseInt(i.target.value); init();};\n",
              "    dom_target.querySelector(\".input_paddingx\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_paddingy\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_stridex\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".input_stridey\").onchange = ()=>{init()}\n",
              "    dom_target.querySelector(\".play_fast\").onchange = ()=>{init()}\n",
              "    })();\n",
              "    </script>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown *Run this cell to enable the widget!*\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "id_html = 3\n",
        "url = f'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo{id_html}.html'\n",
        "run_demo = True # @param {type:\"boolean\"}\n",
        "if run_demo:\n",
        "  display(HTML(url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "e29U3ozW5Q9n"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Visualization_of_Convolution_with_Multiple_Filters_Interactive_Demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "aAZlRI6C5Q9n"
      },
      "source": [
        "## Section 3.1: Multiple Filters\n",
        "\n",
        "The following network sets up 3 filters and runs them on an image of the dataset from the $X$ class. Note that we are using \"thicker\" filters than those presented in the videos. Here, the filters are $5 \\times 5$, whereas in the videos $3 \\times 3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "z-YBG2PC5Q9n"
      },
      "outputs": [],
      "source": [
        "class Net2(nn.Module):\n",
        "  \"\"\"\n",
        "  Neural Network instance\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, padding=0):\n",
        "    \"\"\"\n",
        "    Initialize parameters of Net2\n",
        "\n",
        "    Args:\n",
        "      padding: int or tuple, optional\n",
        "        Zero-padding added to both sides of the input. Default: 0\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(Net2, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5,\n",
        "                           padding=padding)\n",
        "\n",
        "    # First kernel - leading diagonal\n",
        "    kernel_1 = torch.Tensor([[[1., 1., -1., -1., -1.],\n",
        "                              [1., 1., 1., -1., -1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [-1., -1., 1., 1., 1.],\n",
        "                              [-1., -1., -1., 1., 1.]]])\n",
        "\n",
        "    # Second kernel - other diagonal\n",
        "    kernel_2 = torch.Tensor([[[-1., -1., -1., 1., 1.],\n",
        "                              [-1., -1., 1., 1., 1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [1., 1., 1., -1., -1.],\n",
        "                              [1., 1., -1., -1., -1.]]])\n",
        "\n",
        "    # tThird kernel - checkerboard pattern\n",
        "    kernel_3 = torch.Tensor([[[1., 1., -1., 1., 1.],\n",
        "                              [1., 1., 1., 1., 1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [1., 1., 1., 1., 1.],\n",
        "                              [1., 1., -1., 1., 1.]]])\n",
        "\n",
        "\n",
        "    # Stack all kernels in one tensor with (3, 1, 5, 5) dimensions\n",
        "    multiple_kernels = torch.stack([kernel_1, kernel_2, kernel_3], dim=0)\n",
        "\n",
        "    self.conv1.weight = torch.nn.Parameter(multiple_kernels)\n",
        "\n",
        "    # Negative bias\n",
        "    self.conv1.bias = torch.nn.Parameter(torch.Tensor([-4, -4, -12]))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward Pass of Net2\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Convolution output\n",
        "    \"\"\"\n",
        "    x = self.conv1(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "A6LfkJOh5Q9o"
      },
      "source": [
        "**Note:** We add a negative bias to give a threshold to select the high output value, which corresponds to the features we want to detect (e.g., 45 degree oriented bar).\n",
        "\n",
        "Now, let's visualize the filters using the code given below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "yp0l92UU5Q9o"
      },
      "outputs": [],
      "source": [
        "net2 = Net2().to(DEVICE)\n",
        "fig, (ax11, ax12, ax13) = plt.subplots(1, 3)\n",
        "# Show the filters\n",
        "ax11.set_title(\"filter 1\")\n",
        "ax11.imshow(net2.conv1.weight[0, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax12.set_title(\"filter 2\")\n",
        "ax12.imshow(net2.conv1.weight[1, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax13.set_title(\"filter 3\")\n",
        "ax13.imshow(net2.conv1.weight[2, 0].detach().cpu().numpy(), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "2iePgfro5Q9o"
      },
      "source": [
        "### Think! 3.1: Do you see how these filters would help recognize an `X`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RjIZT3Ae5Q9o"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_800ed014.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "mUjz-BHO5Q9o"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Multiple_Filters_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "yUnWuJCq5Q9o"
      },
      "source": [
        "We apply the filters to the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "K0YlgjsH5Q9o"
      },
      "outputs": [],
      "source": [
        "net2 = Net2().to(DEVICE)\n",
        "x_img = emnist_train[x_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "output_x = net2(x_img)\n",
        "output_x = output_x.squeeze(dim=0).detach().cpu().numpy()\n",
        "\n",
        "o_img = emnist_train[o_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "output_o = net2(o_img)\n",
        "output_o = output_o.squeeze(dim=0).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "nZvoH9pj5Q9o"
      },
      "source": [
        "Let us view the image of $X$ and $O$ and what the output of the filters applied to them looks like. Pay special attention to the areas with very high vs. very low output patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "E3fhhG0r5Q9o"
      },
      "outputs": [],
      "source": [
        "fig, ((ax11, ax12, ax13, ax14),\n",
        "      (ax21, ax22, ax23, ax24),\n",
        "      (ax31, ax32, ax33, ax34)) = plt.subplots(3, 4)\n",
        "\n",
        "# Show the filters\n",
        "ax11.axis(\"off\")\n",
        "ax12.set_title(\"filter 1\")\n",
        "ax12.imshow(net2.conv1.weight[0, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax13.set_title(\"filter 2\")\n",
        "ax13.imshow(net2.conv1.weight[1, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax14.set_title(\"filter 3\")\n",
        "ax14.imshow(net2.conv1.weight[2, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "\n",
        "vmin, vmax = -6, 10\n",
        "# Show x and the filters applied to x\n",
        "ax21.set_title(\"image x\")\n",
        "ax21.imshow(emnist_train[x_img_idx][0].reshape(28, 28), cmap='gray')\n",
        "ax22.set_title(\"output filter 1\")\n",
        "ax22.imshow(output_x[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax23.set_title(\"output filter 2\")\n",
        "ax23.imshow(output_x[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax24.set_title(\"output filter 3\")\n",
        "ax24.imshow(output_x[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "\n",
        "# Show o and the filters applied to o\n",
        "ax31.set_title(\"image o\")\n",
        "ax31.imshow(emnist_train[o_img_idx][0].reshape(28, 28), cmap='gray')\n",
        "ax32.set_title(\"output filter 1\")\n",
        "ax32.imshow(output_o[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax33.set_title(\"output filter 2\")\n",
        "ax33.imshow(output_o[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax34.set_title(\"output filter 3\")\n",
        "ax34.imshow(output_o[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NylAaSME5Q9p"
      },
      "source": [
        "## Section 3.2: ReLU after convolutions\n",
        "\n",
        "Up until now we've talked about the convolution operation, which is linear. But the real strength of neural networks comes from the incorporation of non-linear functions.  Furthermore, in the real world, we often have learning problems where the relationship between the input and output is non-linear and complex.\n",
        "\n",
        "The ReLU (Rectified Linear Unit) introduces non-linearity into our model, allowing us to learn a more complex function that can better predict the class of an image.\n",
        "\n",
        "The ReLU function is shown below.\n",
        "\n",
        "<br>\n",
        "\n",
        "<figure>\n",
        "  <center><img src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/relu.png width=400px>\n",
        "  <figcaption>The Rectified Linear Unit (ReLU) Activation Function<figcaption>\n",
        "  </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "2rB3SiMW5Q9p"
      },
      "source": [
        "Now let us incorporate ReLU into our previous model and visualize the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "0Bh3WQ_d5Q9p"
      },
      "outputs": [],
      "source": [
        "class Net3(nn.Module):\n",
        "  \"\"\"\n",
        "  Neural Network Instance\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, padding=0):\n",
        "    \"\"\"\n",
        "    Initialize Net3 parameters\n",
        "\n",
        "    Args:\n",
        "      padding: int or tuple, optional\n",
        "        Zero-padding added to both sides of the input. Default: 0\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(Net3, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5,\n",
        "                           padding=padding)\n",
        "\n",
        "    # First kernel - leading diagonal\n",
        "    kernel_1 = torch.Tensor([[[1., 1., -1., -1., -1.],\n",
        "                              [1., 1., 1., -1., -1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [-1., -1., 1., 1., 1.],\n",
        "                              [-1., -1., -1., 1., 1.]]])\n",
        "\n",
        "    # Second kernel - other diagonal\n",
        "    kernel_2 = torch.Tensor([[[-1., -1., -1., 1., 1.],\n",
        "                              [-1., -1., 1., 1., 1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [1., 1., 1., -1., -1.],\n",
        "                              [1., 1., -1., -1., -1.]]])\n",
        "\n",
        "    # Third kernel -checkerboard pattern\n",
        "    kernel_3 = torch.Tensor([[[1., 1., -1., 1., 1.],\n",
        "                              [1., 1., 1., 1., 1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [1., 1., 1., 1., 1.],\n",
        "                              [1., 1., -1., 1., 1.]]])\n",
        "\n",
        "\n",
        "    # Stack all kernels in one tensor with (3, 1, 5, 5) dimensions\n",
        "    multiple_kernels = torch.stack([kernel_1, kernel_2, kernel_3], dim=0)\n",
        "\n",
        "    self.conv1.weight = torch.nn.Parameter(multiple_kernels)\n",
        "\n",
        "    # Negative bias\n",
        "    self.conv1.bias = torch.nn.Parameter(torch.Tensor([-4, -4, -12]))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward Pass of Net3\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Convolution output\n",
        "    \"\"\"\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "xUNoqD5w5Q9p"
      },
      "source": [
        "We apply the filters and relus to the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "fYwaNMlt5Q9p"
      },
      "outputs": [],
      "source": [
        "net3 = Net3().to(DEVICE)\n",
        "x_img = emnist_train[x_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "output_x_relu = net3(x_img)\n",
        "output_x_relu = output_x_relu.squeeze(dim=0).detach().cpu().numpy()\n",
        "\n",
        "o_img = emnist_train[o_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "output_o_relu = net3(o_img)\n",
        "output_o_relu = output_o_relu.squeeze(dim=0).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "06YBJLSn5Q9p"
      },
      "source": [
        "Let us view the image of $X$ and $O$ and what the output of the filters applied to them look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "rxOjVFSj5Q9p"
      },
      "outputs": [],
      "source": [
        "# @markdown *Execute this cell to view the filtered images*\n",
        "fig, ((ax11, ax12, ax13, ax14, ax15, ax16, ax17),\n",
        "      (ax21, ax22, ax23, ax24, ax25, ax26, ax27),\n",
        "      (ax31, ax32, ax33, ax34, ax35, ax36, ax37)) = plt.subplots(3, 4 + 3,\n",
        "                                                                 figsize=(14, 6))\n",
        "# Show the filters\n",
        "ax11.axis(\"off\")\n",
        "ax12.set_title(\"filter 1\")\n",
        "ax12.imshow(net3.conv1.weight[0, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax13.set_title(\"filter 2\")\n",
        "ax13.imshow(net3.conv1.weight[1, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax14.set_title(\"filter 3\")\n",
        "ax14.imshow(net3.conv1.weight[2, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "\n",
        "ax15.set_title(\"filter 1\")\n",
        "ax15.imshow(net3.conv1.weight[0, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax16.set_title(\"filter 2\")\n",
        "ax16.imshow(net3.conv1.weight[1, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax17.set_title(\"filter 3\")\n",
        "ax17.imshow(net3.conv1.weight[2, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "\n",
        "vmin, vmax = -6, 10\n",
        "# Show x and the filters applied to `x`\n",
        "ax21.set_title(\"image x\")\n",
        "ax21.imshow(emnist_train[x_img_idx][0].reshape(28, 28), cmap='gray')\n",
        "ax22.set_title(\"output filter 1\")\n",
        "ax22.imshow(output_x[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax23.set_title(\"output filter 2\")\n",
        "ax23.imshow(output_x[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax24.set_title(\"output filter 3\")\n",
        "ax24.imshow(output_x[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "\n",
        "ax25.set_title(\"filter 1 + ReLU\")\n",
        "ax25.imshow(output_x_relu[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax26.set_title(\"filter 2 + ReLU\")\n",
        "ax26.imshow(output_x_relu[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax27.set_title(\"filter 3 + ReLU\")\n",
        "ax27.imshow(output_x_relu[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "\n",
        "# Show o and the filters applied to `o`\n",
        "ax31.set_title(\"image o\")\n",
        "ax31.imshow(emnist_train[o_img_idx][0].reshape(28, 28), cmap='gray')\n",
        "ax32.set_title(\"output filter 1\")\n",
        "ax32.imshow(output_o[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax33.set_title(\"output filter 2\")\n",
        "ax33.imshow(output_o[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax34.set_title(\"output filter 3\")\n",
        "ax34.imshow(output_o[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "\n",
        "ax35.set_title(\"filter 1 + ReLU\")\n",
        "ax35.imshow(output_o_relu[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax36.set_title(\"filter 2 + ReLU\")\n",
        "ax36.imshow(output_o_relu[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax37.set_title(\"filter 3 + ReLU\")\n",
        "ax37.imshow(output_o_relu[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "hQ3XpRXq5Q9p"
      },
      "source": [
        "Discuss with your pod how the ReLU activations help strengthen the features necessary to detect an $X$.\n",
        "\n",
        "<br>\n",
        "\n",
        "[Here](https://stats.stackexchange.com/a/226927) you can found a discussion which talks about how ReLU is useful as an activation funciton.\n",
        "\n",
        "[Here](https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks?sfb=2) you can found a another excellent discussion about the advantages of using ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "F6iph3m-5Q9q"
      },
      "source": [
        "## Section 3.3: Pooling\n",
        "\n",
        "Convolutional layers create feature maps that summarize the presence of particular features (e.g., edges) in the input. However, these feature maps record the _precise_ position of features in the input. That means that small changes to the position of an object in an image can result in a very different feature map. But a cup is a cup (and an $X$ is an $X$) no matter where it appears in the image!  We need to achieve _translational invariance_.\n",
        "\n",
        "A common approach to this problem is called downsampling. Downsampling creates a lower-resolution version of an image, retaining the large structural elements and removing some of the fine detail that may be less relevant to the task. In CNNs, Max-Pooling and Average-Pooling are used to downsample.  These operations shrink the size of the hidden layers, and produce features that are more translationally invariant, which can be better leveraged by subsequent layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "_YVpRmaT5Q9q"
      },
      "outputs": [],
      "source": [
        "# @title Video 4: Pooling\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', 'XOss-NUlpo0'), ('Bilibili', 'BV1264y1z7JZ')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Q861qJUT5Q9q"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Pooling_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NXVDxrcY5Q9q"
      },
      "source": [
        "Like convolutional layers, pooling layers have fixed-shape windows (pooling windows) that are systematically applied to the input.  As with filters, we can change the shape of the window and the size of the stride.  And, just like with filters, every time we apply a pooling operation we produce a single output.\n",
        "\n",
        "Pooling performs a kind of information compression that provides summary statistics for a _neighborhood_ of the input.\n",
        "- In Maxpooling, we compute the maximum value of all pixels in the pooling window.\n",
        "- In Avgpooling, we compute the average value of all pixels in the pooling window.\n",
        "\n",
        "The example below shows the result of Maxpooling within the yellow pooling windows to create the red pooling output matrix.\n",
        "\n",
        "<figure>\n",
        "    <center><img src=https://developers.google.com/machine-learning/glossary/images/PoolingConvolution.svg?hl=fr width=400px>\n",
        "    <figcaption>An Example of Pooling with a kernel size of 2</figcaption>\n",
        "    </center>\n",
        "</figure>\n",
        "\n",
        "Pooling gives our network translational invariance by providing a summary of the values in each pooling window. Thus, a small change in the features of the underlying image won't make a huge difference to the output.\n",
        "\n",
        "Note that, unlike a convolutional layer, the pooling layer contains no learned parameters! Pooling just computes a pre-determined summary of the input and passes that along.  This is in contrast to the convolutional layer, where there are filters to be learned.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cLtUAVw45Q9q"
      },
      "source": [
        "### Interactive Demo 3.3: The effect of the stride"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "INpNKmYi5Q9q"
      },
      "source": [
        "**Important:** Change the bool variable `run_demo` to `True` by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "PVFvXF1Y5Q9q"
      },
      "source": [
        "The following animation depicts how changing the stride changes the output. The stride defines how much the pooling region is moved over the input matrix to produce the next output (red arrows in the animation).  Give it a try! Change the stride and see how it affects the output shape.  You can also try MaxPool or AvgPool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "8eBJBcku5Q9q"
      },
      "outputs": [],
      "source": [
        "# @markdown *Run this cell to enable the widget!*\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "id_html = 3.3\n",
        "url = f'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo{id_html}.html'\n",
        "run_demo = False # @param {type:\"boolean\"}\n",
        "if run_demo:\n",
        "  display(HTML(url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "qQ_xLb2l5Q9q"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_The_effect_of_the_stride_Interactive_Demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tzSvlp6J5Q9r"
      },
      "source": [
        "### Coding Exercise 3.3: Implement MaxPooling\n",
        "\n",
        "Let us now implement MaxPooling in PyTorch and observe the effects of Pooling on the dimension of the input image. Use a kernel of size 2 and stride of 2 for the MaxPooling layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "TDxdQ79b5Q9r"
      },
      "outputs": [],
      "source": [
        "class Net4(nn.Module):\n",
        "  \"\"\"\n",
        "  Neural Network instance\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, padding=0, stride=2):\n",
        "    \"\"\"\n",
        "    Initialise parameters of Net4\n",
        "\n",
        "    Args:\n",
        "      padding: int or tuple, optional\n",
        "        Zero-padding added to both sides of the input. Default: 0\n",
        "      stride: int\n",
        "        Stride\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(Net4, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5,\n",
        "                            padding=padding)\n",
        "\n",
        "    # First kernel - leading diagonal\n",
        "    kernel_1 = torch.Tensor([[[1., 1., -1., -1., -1.],\n",
        "                              [1., 1., 1., -1., -1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [-1., -1., 1., 1., 1.],\n",
        "                              [-1., -1., -1., 1., 1.]]])\n",
        "\n",
        "    # Second kernel - other diagonal\n",
        "    kernel_2 = torch.Tensor([[[-1., -1., -1., 1., 1.],\n",
        "                              [-1., -1., 1., 1., 1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [1., 1., 1., -1., -1.],\n",
        "                              [1., 1., -1., -1., -1.]]])\n",
        "\n",
        "    # Third kernel -checkerboard pattern\n",
        "    kernel_3 = torch.Tensor([[[1., 1., -1., 1., 1.],\n",
        "                              [1., 1., 1., 1., 1.],\n",
        "                              [-1., 1., 1., 1., -1.],\n",
        "                              [1., 1., 1., 1., 1.],\n",
        "                              [1., 1., -1., 1., 1.]]])\n",
        "\n",
        "\n",
        "    # Stack all kernels in one tensor with (3, 1, 5, 5) dimensions\n",
        "    multiple_kernels = torch.stack([kernel_1, kernel_2, kernel_3], dim=0)\n",
        "\n",
        "    self.conv1.weight = torch.nn.Parameter(multiple_kernels)\n",
        "\n",
        "    # Negative bias\n",
        "    self.conv1.bias = torch.nn.Parameter(torch.Tensor([-4, -4, -12]))\n",
        "    ####################################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your function\n",
        "    raise NotImplementedError(\"Define the maxpool layer\")\n",
        "    ####################################################################\n",
        "    self.pool = nn.MaxPool2d(kernel_size=..., stride=...)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward Pass of Net4\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Convolution + ReLU output\n",
        "    \"\"\"\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    ####################################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your function\n",
        "    raise NotImplementedError(\"Define the maxpool layer\")\n",
        "    ####################################################################\n",
        "    x = ...  # Pass through a max pool layer\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "## Check if your implementation is correct\n",
        "# net4 = Net4().to(DEVICE)\n",
        "# check_pooling_net(net4, device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-v2uKCPg5Q9r"
      },
      "source": [
        "```\n",
        "✅ Your network produced the correct output.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KasZPP1K5Q9r"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_168b8fcf.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "i5_K1mF05Q9r"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Implement_MaxPooling_Exercise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "oUm1SAZ15Q9r"
      },
      "outputs": [],
      "source": [
        "x_img = emnist_train[x_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "output_x_pool = net4(x_img)\n",
        "output_x_pool = output_x_pool.squeeze(dim=0).detach().cpu().numpy()\n",
        "\n",
        "o_img = emnist_train[o_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "output_o_pool = net4(o_img)\n",
        "output_o_pool = output_o_pool.squeeze(dim=0).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "LmExsWUQ5Q9r"
      },
      "outputs": [],
      "source": [
        "# @markdown *Run the cell to plot the outputs!*\n",
        "\n",
        "fig, ((ax11, ax12, ax13, ax14),\n",
        "      (ax21, ax22, ax23, ax24),\n",
        "      (ax31, ax32, ax33, ax34)) = plt.subplots(3, 4)\n",
        "# Show the filters\n",
        "ax11.axis(\"off\")\n",
        "ax12.set_title(\"filter 1\")\n",
        "ax12.imshow(net4.conv1.weight[0, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax13.set_title(\"filter 2\")\n",
        "ax13.imshow(net4.conv1.weight[1, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "ax14.set_title(\"filter 3\")\n",
        "ax14.imshow(net4.conv1.weight[2, 0].detach().cpu().numpy(), cmap=\"gray\")\n",
        "\n",
        "vmin, vmax = -6, 10\n",
        "# Show x and the filters applied to x\n",
        "ax21.set_title(\"image x\")\n",
        "ax21.imshow(emnist_train[x_img_idx][0].reshape(28, 28), cmap='gray')\n",
        "ax22.set_title(\"output filter 1\")\n",
        "ax22.imshow(output_x_pool[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax23.set_title(\"output filter 2\")\n",
        "ax23.imshow(output_x_pool[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax24.set_title(\"output filter 3\")\n",
        "ax24.imshow(output_x_pool[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "\n",
        "# Show o and the filters applied to o\n",
        "ax31.set_title(\"image o\")\n",
        "ax31.imshow(emnist_train[o_img_idx][0].reshape(28, 28), cmap='gray')\n",
        "ax32.set_title(\"output filter 1\")\n",
        "ax32.imshow(output_o_pool[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax33.set_title(\"output filter 2\")\n",
        "ax33.imshow(output_o_pool[1], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "ax34.set_title(\"output filter 3\")\n",
        "ax34.imshow(output_o_pool[2], cmap='gray', vmin=vmin, vmax=vmax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "xYDsWLZJ5Q9r"
      },
      "source": [
        "You should observe the size of the output as being half of what you saw after the ReLU section, which is due to the Maxpool layer.\n",
        "\n",
        "Despite the reduction in the size of the output, the important or high-level features in the output still remains intact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "s25HKHkO5Q9r"
      },
      "source": [
        "---\n",
        "# Section 4: Putting it all together\n",
        "\n",
        "*Time estimate: ~33mins*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "aIAsRvxj5Q9s"
      },
      "outputs": [],
      "source": [
        "# @title Video 5: Putting it all together\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', '-TJixd9fRCw'), ('Bilibili', 'BV1Fy4y1j7dU')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "DpQZusRK5Q9s"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Putting_it_all_together_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "e_SlesoV5Q9s"
      },
      "source": [
        "## Section 4.1: Number of Parameters in Convolutional vs. Fully-connected Models\n",
        "Convolutional networks encourage weight-sharing by learning a single kernel that is repeated over the entire input image. In general, this kernel is just a few parameters, compared to the huge number of parameters in a dense network.\n",
        "\n",
        "Let's use the animation below to calculate few-layer network parameters for image data of shape $32\\times32$ using both convolutional layers and dense layers. The `Num_Dense` in this exercise is the number of dense layers we use in the network, with each dense layer having the same input and output dimensions. `Num_Convs` is the number of convolutional blocks in the network, with each block containing a single kernel. The kernel size is the length and width of this kernel.\n",
        "\n",
        "**Note:** you must run the cell before you can use the sliders.\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "  <img src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/img_params.png>\n",
        "  <figcaption> Parameter comparison</figcaption>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4Js4OLpf5Q9s"
      },
      "source": [
        "### Interactive Demo 4.1: Number of Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "XGOl3xTe5Q9s"
      },
      "outputs": [],
      "source": [
        "# @markdown *Run this cell to enable the widget*\n",
        "import io, base64\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "\n",
        "def do_plot(image_size, batch_size, number_of_Linear, number_of_Conv2d,\n",
        "            kernel_size, pooling, Final_Layer):\n",
        "  sample_image = torch.rand(batch_size, 1, image_size, image_size)\n",
        "  linear_layer = []\n",
        "  linear_nets = []\n",
        "  code_dense = \"\"\n",
        "\n",
        "  code_dense += f\"model_dense = nn.Sequential(\\n\"\n",
        "  code_dense += f\"    nn.Flatten(),\\n\"\n",
        "  for i in range(number_of_Linear):\n",
        "    linear_layer.append(nn.Linear(image_size * image_size * 1,\n",
        "                                  image_size * image_size * 1,\n",
        "                                  bias=False))\n",
        "    linear_nets.append(nn.Sequential(*linear_layer))\n",
        "    code_dense += f\"    nn.Linear({image_size}*{image_size}*1, {image_size}*{image_size}*1, bias=False),\\n\"\n",
        "  if Final_Layer is True:\n",
        "    linear_layer.append(nn.Linear(image_size * image_size * 1, 10,\n",
        "                                  bias=False))\n",
        "    linear_nets.append(nn.Sequential(*linear_layer))\n",
        "    code_dense += f\"    nn.Linear({image_size}*{image_size}*1, 10, bias=False)\\n\"\n",
        "  code_dense += \")\\n\"\n",
        "  code_dense += \"result_dense = model_dense(sample_image)\\n\"\n",
        "  linear_layer = nn.Sequential(*linear_layer)\n",
        "\n",
        "  conv_layer = []\n",
        "  conv_nets = []\n",
        "  code_conv = \"\"\n",
        "\n",
        "  code_conv += f\"model_conv = nn.Sequential(\\n\"\n",
        "  for i in range(number_of_Conv2d):\n",
        "    conv_layer.append(nn.Conv2d(in_channels=1,\n",
        "                                out_channels=1,\n",
        "                                kernel_size=kernel_size,\n",
        "                                padding=kernel_size // 2,\n",
        "                                bias=False))\n",
        "\n",
        "    conv_nets.append(nn.Sequential(*conv_layer))\n",
        "    code_conv += f\"    nn.Conv2d(in_channels=1, out_channels=1, kernel_size={kernel_size}, padding={kernel_size//2}, bias=False),\\n\"\n",
        "    if pooling > 0:\n",
        "      conv_layer.append(nn.MaxPool2d(2, 2))\n",
        "      code_conv += f\"    nn.MaxPool2d(2, 2),\\n\"\n",
        "    conv_nets.append(nn.Sequential(*conv_layer))\n",
        "  if Final_Layer is True:\n",
        "    conv_layer.append(nn.Flatten())\n",
        "    code_conv += f\"    nn.Flatten(),\\n\"\n",
        "    conv_nets.append(nn.Sequential(*conv_layer))\n",
        "    shape_conv = conv_nets[-1](sample_image).shape\n",
        "    conv_layer.append(nn.Linear(shape_conv[1], 10, bias=False))\n",
        "    code_conv += f\"    nn.Linear({shape_conv[1]}, 10, bias=False),\\n\"\n",
        "    conv_nets.append(nn.Sequential(*conv_layer))\n",
        "  conv_layer = nn.Sequential(*conv_layer)\n",
        "  code_conv += \")\\n\"\n",
        "  code_conv += \"result_conv = model_conv(sample_image)\\n\"\n",
        "\n",
        "\n",
        "  t_1 = time.time()\n",
        "  shape_linear = linear_layer(torch.flatten(sample_image, 1)).shape\n",
        "  t_2 = time.time()\n",
        "  shape_conv = conv_layer(sample_image).shape\n",
        "  t_3 = time.time()\n",
        "\n",
        "  print(\"Time taken by Dense Layer {}\".format(t_2 - t_1))\n",
        "  print(\"Time taken by Conv Layer  {}\".format(t_3 - t_2))\n",
        "\n",
        "  ax = plt.axes((0, 0, 1, 1))\n",
        "  ax.spines[\"left\"].set_visible(False)\n",
        "  plt.yticks([])\n",
        "  ax.spines[\"bottom\"].set_visible(False)\n",
        "  ax.spines[\"right\"].set_visible(False)\n",
        "  ax.spines[\"top\"].set_visible(False)\n",
        "  plt.xticks([])\n",
        "  p1 = sum(p.numel() for p in linear_layer.parameters())\n",
        "  nl = '\\n'\n",
        "  p2 = sum(p.numel() for p in conv_layer.parameters())\n",
        "  plt.text(0.1, 0.8,\n",
        "           f\"Total Parameters in Dense Layer {p1:10,d}{nl}Total Parameters in Conv Layer   {p2:10,d}\")\n",
        "\n",
        "  plt.text(0.23, 0.62, \"Dense Net\", rotation=90,\n",
        "           color='k', ha=\"center\", va=\"center\")\n",
        "\n",
        "  def addBox(x, y, w, h, color, text1, text2, text3):\n",
        "      \"\"\"\n",
        "      Function to render widget\n",
        "      \"\"\"\n",
        "      ax.add_patch(plt.Rectangle((x, y), w, h, fill=True, color=color,\n",
        "                                 alpha=0.5, zorder=1000, clip_on=False))\n",
        "      plt.text(x + 0.02, y + h / 2, text1, rotation=90,\n",
        "               va=\"center\", ha=\"center\", size=12)\n",
        "      plt.text(x + 0.05, y + h / 2, text2, rotation=90,\n",
        "               va=\"center\", ha=\"center\")\n",
        "      plt.text(x + 0.08, y + h / 2, text3, rotation=90,\n",
        "               va=\"center\", ha=\"center\", size=12)\n",
        "\n",
        "  x = 0.25\n",
        "  if 1:\n",
        "    addBox(x, 0.5, 0.08, 0.25, [1, 0.5, 0], \"Flatten\",\n",
        "           tuple(torch.flatten(sample_image, 1).shape), \"\")\n",
        "    x += 0.08 + 0.01\n",
        "\n",
        "  for i in range(number_of_Linear):\n",
        "    addBox(x, 0.5, 0.1, 0.25, \"g\", \"Dense\",\n",
        "           tuple(linear_nets[i](torch.flatten(sample_image, 1)).shape),\n",
        "           list(linear_layer.parameters())[i].numel())\n",
        "    x += 0.11\n",
        "\n",
        "  if Final_Layer is True:\n",
        "    i = number_of_Linear\n",
        "    addBox(x, 0.5, 0.1, 0.25, \"g\", \"Dense\",\n",
        "           tuple(linear_nets[i](torch.flatten(sample_image, 1)).shape),\n",
        "           list(linear_layer.parameters())[i].numel())\n",
        "\n",
        "  plt.text(0.23, 0.1 + 0.35 / 2, \"Conv Net\",\n",
        "           rotation=90, color='k',\n",
        "           ha=\"center\", va=\"center\")\n",
        "  x = 0.25\n",
        "\n",
        "  for i in range(number_of_Conv2d):\n",
        "    addBox(x, 0.1, 0.1, 0.35, \"r\", \"Conv\",\n",
        "           tuple(conv_nets[i * 2](sample_image).shape),\n",
        "           list(conv_nets[i * 2].parameters())[-1].numel())\n",
        "    x += 0.11\n",
        "    if pooling > 0:\n",
        "      addBox(x, 0.1, 0.08, 0.35, [0, 0.5, 1], \"Pooling\",\n",
        "             tuple(conv_nets[i * 2 + 1](sample_image).shape), \"\")\n",
        "      x += 0.08 + 0.01\n",
        "\n",
        "  if Final_Layer is True:\n",
        "    i = number_of_Conv2d\n",
        "    addBox(x, 0.1, 0.08, 0.35, [1, 0.5, 0], \"Flatten\",\n",
        "           tuple(conv_nets[i * 2](sample_image).shape), \"\")\n",
        "    x += 0.08 + 0.01\n",
        "\n",
        "    addBox(x, 0.1, 0.1, 0.35, \"g\", \"Dense\",\n",
        "            tuple(conv_nets[i * 2 + 1](sample_image).shape),\n",
        "            list(conv_nets[i * 2 + 1].parameters())[-1].numel())\n",
        "    x += 0.11\n",
        "\n",
        "  plt.text(0.08, 0.3 + 0.35 / 2,\n",
        "           \"Input\", rotation=90, color='b', ha=\"center\", va=\"center\")\n",
        "\n",
        "  ax.add_patch(plt.Rectangle((0.1, 0.3), 0.1, 0.35, fill=True, color='b',\n",
        "                             alpha=0.5, zorder=1000, clip_on=False))\n",
        "  plt.text(0.1 + 0.1 / 2, 0.3 + 0.35 / 2, tuple(sample_image.shape),\n",
        "           rotation=90, va=\"center\", ha=\"center\")\n",
        "\n",
        "  # Plot\n",
        "  plt.gcf().set_tight_layout(False)\n",
        "  my_stringIObytes = io.BytesIO()\n",
        "  plt.savefig(my_stringIObytes, format='png', dpi=90)\n",
        "  my_stringIObytes.seek(0)\n",
        "  my_base64_jpgData = base64.b64encode(my_stringIObytes.read())\n",
        "\n",
        "  del linear_layer, conv_layer\n",
        "\n",
        "  plt.close()\n",
        "  mystring = \"\"\"<img src=\"data:image/png;base64,\"\"\" + str(my_base64_jpgData)[2:-1] + \"\"\"\" alt=\"Graph\">\"\"\"\n",
        "\n",
        "  return code_dense, code_conv, mystring\n",
        "\n",
        "\n",
        "# Parameters\n",
        "caption = widgets.Label(value='The values of range1 and range2 are synchronized')\n",
        "slider_batch_size = widgets.IntSlider(value=100, min=10, max=100, step=10,\n",
        "                                      description=\"BatchSize\")\n",
        "slider_image_size = widgets.IntSlider(value=32, min=32, max=128, step=32,\n",
        "                                      description=\"ImageSize\")\n",
        "slider_number_of_Linear = widgets.IntSlider(value=1,min=1, max=3, step=1,\n",
        "                                            description=\"NumDense\")\n",
        "slider_number_of_Conv2d = widgets.IntSlider(value=1, min=1, max=2, step=1,\n",
        "                                            description=\"NumConv\")\n",
        "slider_kernel_size = widgets.IntSlider(value=5, min=3, max=21, step=2,\n",
        "                                       description=\"KernelSize\")\n",
        "input_pooling = widgets.Checkbox(value=False,\n",
        "                                 description=\"Pooling\")\n",
        "input_Final_Layer = widgets.Checkbox(value=False,\n",
        "                                     description=\"Final_Layer\")\n",
        "\n",
        "output_code1 = widgets.HTML(value=\"\", )\n",
        "\n",
        "output_plot = widgets.HTML(value=\"\", )\n",
        "\n",
        "\n",
        "def plot_func(batch_size, image_size,\n",
        "              number_of_Linear, number_of_Conv2d,\n",
        "              kernel_size, pooling, Final_Layer):\n",
        "\n",
        "    code1, code2, plot = do_plot(image_size, batch_size,\n",
        "                                 number_of_Linear, number_of_Conv2d,\n",
        "                                 kernel_size, pooling, Final_Layer)\n",
        "    output_plot.value = plot\n",
        "\n",
        "    output_code1.value = \"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "      <head>\n",
        "        <style>\n",
        "          * {\n",
        "            box-sizing: border-box;\n",
        "          }\n",
        "          .column {\n",
        "            float: left;\n",
        "            /*width: 33.33%;*/\n",
        "            padding: 5px;\n",
        "          }\n",
        "          /* Clearfix (clear floats) */\n",
        "          .row::after {\n",
        "            content: \"\";\n",
        "            clear: both;\n",
        "            display: table;\n",
        "          }\n",
        "          pre {\n",
        "            line-height: 1.2em;\n",
        "          }\n",
        "        </style>\n",
        "      </head>\n",
        "\n",
        "      <body>\n",
        "        <div class=\"row\">\n",
        "          <div class=\"column\" style=\"overflow-x: scroll;\">\n",
        "          <h2>Code for Dense Network</h2>\n",
        "          <pre>\"\"\" + code1 + \"\"\"</pre>\n",
        "        </div>\n",
        "          <div class=\"column\" style=\"overflow-x: scroll;\">\n",
        "          <h2>Code for Conv Network</h2>\n",
        "          <pre>\"\"\" + code2 + \"\"\"</pre>\n",
        "          </div>\n",
        "        </div>\n",
        "      </body>\n",
        "    </html>\n",
        "\"\"\"\n",
        "\n",
        "out = widgets.interactive_output(plot_func, {\n",
        "    \"batch_size\": slider_batch_size,\n",
        "    \"image_size\": slider_image_size,\n",
        "    \"number_of_Linear\": slider_number_of_Linear,\n",
        "    \"number_of_Conv2d\": slider_number_of_Conv2d,\n",
        "    \"kernel_size\": slider_kernel_size,\n",
        "    \"pooling\": input_pooling,\n",
        "    \"Final_Layer\": input_Final_Layer,\n",
        "})\n",
        "\n",
        "ui = widgets.VBox([slider_batch_size, slider_image_size,\n",
        "                   slider_number_of_Linear,\n",
        "                   widgets.HBox([slider_number_of_Conv2d,\n",
        "                                 slider_kernel_size,\n",
        "                                 input_pooling]),\n",
        "                   input_Final_Layer])\n",
        "display(widgets.HBox([output_plot, output_code1]), ui)\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "qetHVJoN5Q9t"
      },
      "source": [
        "The difference in parameters is huge, and it continues to increase as the input image size increases. Larger images require that the linear layer use a matrix that can be directly multiplied with the input pixels.\n",
        "\n",
        "<br>\n",
        "\n",
        "While pooling does not reduce the number of parameters for a subsequent convolutional layer, it does decreases the image size. Therefore, later dense layers will need fewer parameters.\n",
        "\n",
        "<br>\n",
        "\n",
        "The CNN parameter size, however, is invariant of the image size, as irrespective of the input that it gets, it keeps sliding the same learnable filter over the images.\n",
        "\n",
        "The reduced parameter set not only brings down memory usage by huge chunks, but it also allows the model to generalize better.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "F1G0KiBW5Q9t"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Number_of_Parameters_Interactive_Demo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "cWm13DrW5Q9t"
      },
      "outputs": [],
      "source": [
        "# @title Video 6: Implement your own CNN\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', '_gkF9Vv7MgE'), ('Bilibili', 'BV18f4y1j7e4')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "knfMJbtR5Q9t"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Implement_your_own_CNN_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4bX-JOy75Q9t"
      },
      "source": [
        "## Coding Exercise 4: Implement your own CNN\n",
        "\n",
        "Let's stack up all we have learnt. Create a CNN with the following structure. <br>\n",
        "- Convolution `nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)`\n",
        "- Convolution `nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)`\n",
        "- Pool Layer `nn.MaxPool2d(kernel_size=2)`\n",
        "- Fully Connected Layer `nn.Linear(in_features=9216, out_features=128)`\n",
        "- Fully Connected layer `nn.Linear(in_features=128, out_features=2)`\n",
        "\n",
        "Note: As discussed in the video, we would like to flatten the output from the Convolutional Layers before passing on the Linear layers, thereby converting an input of shape $[\\text{BatchSize}, \\text{Channels}, \\text{Height}, \\text{Width}]$ to $[\\text{BatchSize}, \\text{Channels} \\times \\text{Height} \\times \\text{Width}]$, which in this case would be from $[32, 64, 12, 12]$ (output of second convolution layer) to $[32, 64 \\times 12 \\times 12] = [32, 9216]$. Recall that the input images have size $[28, 28]$.\n",
        "\n",
        "Hint: You could use `torch.flatten(x, 1)` in order to flatten the input at this stage. The $1$ means it flattens dimensions starting with dimensions 1 in order to exclude the batch dimension from the flattening.\n",
        "\n",
        "We should also stop to think about how we get the output of the pooling layer to be $12 \\times 12$. It is because first, the two `Conv2d` with a `kernel_size=3` operations cause the image to be reduced to $26 \\times 26$ and the second `Conv2d` reduces it to $24 \\times 24$. Finally, the `MaxPool2d` operation reduces the output size by half to $12 \\times 12$.\n",
        "\n",
        "Also, don't forget the ReLUs (use e.g., `F.ReLU`)! No need to add a ReLU after the final fully connected layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Efv_Fh1T5Q9t"
      },
      "outputs": [],
      "source": [
        "# @title Train/Test Functions (Run Me)\n",
        "\n",
        "# @markdown Double-click to see the contents!\n",
        "\n",
        "def train(model, device, train_loader, epochs):\n",
        "  \"\"\"\n",
        "  Training function\n",
        "\n",
        "  Args:\n",
        "    model: nn.module\n",
        "      Neural network instance\n",
        "    device: string\n",
        "      GPU/CUDA if available, CPU otherwise\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    train_loader: torch.loader\n",
        "      Training Set\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "  for epoch in range(epochs):\n",
        "    with tqdm(train_loader, unit='batch') as tepoch:\n",
        "      for data, target in tepoch:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tepoch.set_postfix(loss=loss.item())\n",
        "        time.sleep(0.1)\n",
        "\n",
        "def test(model, device, data_loader):\n",
        "  \"\"\"\n",
        "  Test function\n",
        "\n",
        "  Args:\n",
        "    model: nn.module\n",
        "      Neural network instance\n",
        "    device: string\n",
        "      GPU/CUDA if available, CPU otherwise\n",
        "    data_loader: torch.loader\n",
        "      Test Set\n",
        "\n",
        "  Returns:\n",
        "    acc: float\n",
        "      Test accuracy\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for data in data_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device).float()\n",
        "    labels = labels.to(device).long()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = 100 * correct / total\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8Y3W1Sx65Q9t"
      },
      "source": [
        "We download the data. Notice that here, we normalize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "5LA6nRBI5Q9t"
      },
      "outputs": [],
      "source": [
        "set_seed(SEED)\n",
        "emnist_train, emnist_test = get_Xvs0_dataset(normalize=True)\n",
        "train_loader, test_loader = get_data_loaders(emnist_train, emnist_test,\n",
        "                                             seed=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "NPFqoszU5Q9u"
      },
      "outputs": [],
      "source": [
        "class EMNIST_Net(nn.Module):\n",
        "  \"\"\"\n",
        "  Neural network instance with following structure\n",
        "  nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3) # Convolutional Layer 1\n",
        "  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3) + max-pooling # Convolutional Block 2\n",
        "  nn.Linear(in_features=9216, out_features=128) # Fully Connected Layer 1\n",
        "  nn.Linear(in_features=128, out_features=2) # Fully Connected Layer 2\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialize parameters of EMNISTNet\n",
        "\n",
        "    Args:\n",
        "      None\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(EMNIST_Net, self).__init__()\n",
        "\n",
        "    ####################################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your function\n",
        "    raise NotImplementedError(\"Define the required layers\")\n",
        "    ####################################################################\n",
        "    self.conv1 = nn.Conv2d(...)\n",
        "    self.conv2 = nn.Conv2d(...)\n",
        "    self.fc1 = nn.Linear(...)\n",
        "    self.fc2 = nn.Linear(...)\n",
        "    self.pool = nn.MaxPool2d(...)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of EMNISTNet\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Output of final fully connected layer\n",
        "    \"\"\"\n",
        "    ####################################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your function\n",
        "    # Hint: Do not forget to flatten the image as it goes from\n",
        "    # Convolution Layers to Linear Layers!\n",
        "    raise NotImplementedError(\"Define forward pass for any input x\")\n",
        "    ####################################################################\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = ...\n",
        "    x = ...\n",
        "    x = ...\n",
        "    x = ...\n",
        "    x = ...\n",
        "    x = ...\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "## Uncomment the lines below to train your network\n",
        "# emnist_net = EMNIST_Net().to(DEVICE)\n",
        "# print(\"Total Parameters in Network {:10d}\".format(sum(p.numel() for p in emnist_net.parameters())))\n",
        "# train(emnist_net, DEVICE, train_loader, 1)\n",
        "## Uncomment to test your model\n",
        "# print(f'Test accuracy is: {test(emnist_net, DEVICE, test_loader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "O3Ulty3D5Q9u"
      },
      "source": [
        "You should have been able to get a test accuracy of around $99%$!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "34BeaIiQ5Q9u"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_c295e530.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "mOz1M08p5Q9u"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Implement_your_own_CNN_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "pMA34sxF5Q9u"
      },
      "source": [
        "**Note:** We are using a softmax function here which converts a real value to a value between 0 and 1, which can be interpreted as a probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "Ye-VVu6V5Q9u"
      },
      "outputs": [],
      "source": [
        "# Index of an image in the dataset that corresponds to an X and O\n",
        "x_img_idx = 11\n",
        "o_img_idx = 0\n",
        "\n",
        "print(\"Input:\")\n",
        "x_img = emnist_train[x_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "plt.imshow(emnist_train[x_img_idx][0].reshape(28, 28),\n",
        "           cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "output = emnist_net(x_img)\n",
        "result = F.softmax(output, dim=1)\n",
        "print(\"\\nResult:\", result)\n",
        "print(\"Confidence of image being an 'O':\", result[0, 0].item())\n",
        "print(\"Confidence of image being an 'X':\", result[0, 1].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "OLRUer-N5Q9u"
      },
      "source": [
        "The network is quite confident that this image is an $X$!\n",
        "\n",
        "Note that this is evident from the softmax output, which shows the probabilities of the image belonging to each of the classes. There is a higher probability of belonging to class 1; i.e., class $X$.\n",
        "\n",
        "Let us also test the network on an $O$ image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "X5hYkJo05Q9u"
      },
      "outputs": [],
      "source": [
        "print(\"Input:\")\n",
        "o_img = emnist_train[o_img_idx][0].unsqueeze(dim=0).to(DEVICE)\n",
        "plt.imshow(emnist_train[o_img_idx][0].reshape(28, 28),\n",
        "           cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "output = emnist_net(o_img)\n",
        "result = F.softmax(output, dim=1)\n",
        "print(\"\\nResult:\", result)\n",
        "print(\"Confidence of image being an 'O':\", result[0, 0].item())\n",
        "print(\"Confidence of image being an 'X':\", result[0, 1].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "asTpDz_x5Q9u"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "In this Tutorial we have familiarized ouselves with CNNs. We have leaned how the convolution operation works and be applied in various images. Also, we have learned to implement our own CNN. In the next Tutorial, we will go deeper in the training of CNNs!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "79HUDerJ5Q9v"
      },
      "source": [
        "---\n",
        "# Bonus 1: Write your own training loop revisited\n",
        "\n",
        "*Time estimate: ~20mins*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "xJ9ahfOR5Q9v"
      },
      "source": [
        "In the last section we coded up a CNN, but trained it with some predefined functions.  In this section, we will walk through an example of training loop for a convolution net. In this section, we will train a CNN using convolution layers and maxpool and then observe what the training and validation curves look like. In Section 6, we will add regularization and data augmentation to see what effects they have on the curves and why it is important to incorporate them while training our network.\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "kR-KQaUp5Q9v"
      },
      "outputs": [],
      "source": [
        "# @title Video 7: Writing your own training loop\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', 'L0XG-QKv5_w'), ('Bilibili', 'BV1Ko4y1Q7UG')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Nm7czNnr5Q9v"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Writing_your_own_training_loop_Bonus_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ISUqHY7u5Q9v"
      },
      "source": [
        "## Bonus 1.1: Understand the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "fqw4s9UH5Q9v"
      },
      "source": [
        "The dataset we are going to use for this task is called Fashion-MNIST. It consists of a training set of 60,000 examples and a test set of 10,000 examples. We further divide the test set into a validation set and a test set (8,000 and 2,000, respectively). Each example is a $28 \\times 28$ gray scale image, associated with a label from 10 classes. Following are the labels of the dataset:\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{matrix}\n",
        "\\text{label} && \\text{category} \\\\\n",
        "\\hline\n",
        "0 && \\text{T-shirt/top} \\\\\n",
        "1 && \\text{Trouser} \\\\\n",
        "2 && \\text{Pullover} \\\\\n",
        "3 && \\text{Dress} \\\\\n",
        "4 && \\text{Coat} \\\\\n",
        "5 && \\text{Sandal} \\\\\n",
        "6 && \\text{Shirt} \\\\\n",
        "7 && \\text{Sneaker} \\\\\n",
        "8 && \\text{Bag} \\\\\n",
        "9 && \\text{Ankle boot} \\\\\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VKFuL-DN5Q9v"
      },
      "source": [
        "**Note:** We will reduce the dataset to just the two categories T-shirt/top and Shirt to reduce the training time from about 10min to 2min. We later provide pretrained results to give you an idea how the results would look on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "tA2TzEpg5Q9v"
      },
      "outputs": [],
      "source": [
        "# @title Download Fashion MNIST dataset\n",
        "\n",
        "# webpage: https://github.com/zalandoresearch/fashion-mnist\n",
        "fname = 'FashionMNIST.tar.gz'\n",
        "folder = 'FashionMNIST'\n",
        "url = \"https://osf.io/dfhu5/download\"\n",
        "download_data(fname, folder, url, tar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "GAfvfiZp5Q9v"
      },
      "outputs": [],
      "source": [
        "# @title Loading Fashion-MNIST Data\n",
        "\n",
        "# @markdown `reduce_classes(data)` to reduce Fashion-MNIST Data to two-categories\n",
        "\n",
        "# need to split into train, validation, test\n",
        "def reduce_classes(data):\n",
        "  \"\"\"\n",
        "  Reducing classes in Fashion MNIST\n",
        "  to T-Shirts and Shirts\n",
        "\n",
        "  Args:\n",
        "    data: torch.tensor\n",
        "      Training Data\n",
        "\n",
        "  Returns:\n",
        "    data: torch.tensor\n",
        "      Data with two classes\n",
        "  \"\"\"\n",
        "  # Only want T-Shirts (0) and Shirts (6) labels\n",
        "  train_idx = (data.targets == 0) | (data.targets == 6)\n",
        "  data.targets = data.targets[train_idx]\n",
        "  data.data = data.data[train_idx]\n",
        "\n",
        "  # Convert Xs predictions to 1, Os predictions to 0\n",
        "  data.targets[data.targets == 6] = 1\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def get_fashion_mnist_dataset(binary=False, download=False, seed=0):\n",
        "  \"\"\"\n",
        "  Helper function to get Fashion MNIST data\n",
        "\n",
        "  Args:\n",
        "    binary: boolean\n",
        "      If True, training data has only two classes\n",
        "    download: boolean\n",
        "      If True, download training data\n",
        "    seed: int\n",
        "      Set seed for reproducibility [default: 0]\n",
        "\n",
        "  Returns:\n",
        "    train_data: torch.tensor\n",
        "      Training data\n",
        "    test_data: torch.tensor\n",
        "      Test data\n",
        "    validation_data: torch.tensor\n",
        "      Validation data\n",
        "  \"\"\"\n",
        "  transform = transforms.Compose([\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                  ])\n",
        "\n",
        "  train_data = datasets.FashionMNIST(root='.',\n",
        "                                     download=download,\n",
        "                                     train=True,\n",
        "                                     transform=transform)\n",
        "\n",
        "\n",
        "  test_data = datasets.FashionMNIST(root='.',\n",
        "                                    download=download,\n",
        "                                    train=False,\n",
        "                                    transform=transform)\n",
        "\n",
        "  if binary:\n",
        "    train_data = reduce_classes(train_data)\n",
        "    test_data = reduce_classes(test_data)\n",
        "\n",
        "  set_seed(seed)\n",
        "  validation_data, test_data = torch.utils.data.random_split(test_data,\n",
        "                                                             [int(0.8*len(test_data)),\n",
        "                                                              int(0.2*len(test_data))])\n",
        "\n",
        "  return train_data, validation_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "rQ5wbf9y5Q9v"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "train_data, validation_data, test_data = get_fashion_mnist_dataset(seed=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "bAoZUPfU5Q9v"
      },
      "source": [
        "If you want to continue with the 10 class dataset, skip the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "3-JLiXsL5Q9w"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "train_data, validation_data, test_data = get_fashion_mnist_dataset(binary=True, seed=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "z6E36SyN5Q9w"
      },
      "source": [
        "Here's some code to visualize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "EJY1khuN5Q9w"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
        "ax1.imshow(train_data[0][0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
        "ax2.imshow(train_data[1][0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
        "ax3.imshow(train_data[2][0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
        "ax4.imshow(train_data[3][0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "f-_emRpN5Q9w"
      },
      "source": [
        "Take a minute with your pod and talk about which classes you think would be most confusable.  How hard will it be to differentiate t-shirt/tops from shirts?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "wQOfOxzo5Q9w"
      },
      "outputs": [],
      "source": [
        "# @title Video 8: The Training Loop\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class PlayVideo(IFrame):\n",
        "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
        "    self.id = id\n",
        "    if source == 'Bilibili':\n",
        "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
        "    elif source == 'Osf':\n",
        "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
        "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "\n",
        "def display_videos(video_ids, W=400, H=300, fs=1):\n",
        "  tab_contents = []\n",
        "  for i, video_id in enumerate(video_ids):\n",
        "    out = widgets.Output()\n",
        "    with out:\n",
        "      if video_ids[i][0] == 'Youtube':\n",
        "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
        "                             height=H, fs=fs, rel=0)\n",
        "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
        "      else:\n",
        "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
        "                          height=H, fs=fs, autoplay=False)\n",
        "        if video_ids[i][0] == 'Bilibili':\n",
        "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
        "        elif video_ids[i][0] == 'Osf':\n",
        "          print(f'Video available at https://osf.io/{video.id}')\n",
        "      display(video)\n",
        "    tab_contents.append(out)\n",
        "  return tab_contents\n",
        "\n",
        "\n",
        "video_ids = [('Youtube', 'ZgYYgktqaP8'), ('Bilibili', 'BV1av411n7VJ')]\n",
        "tab_contents = display_videos(video_ids, W=854, H=480)\n",
        "tabs = widgets.Tab()\n",
        "tabs.children = tab_contents\n",
        "for i in range(len(tab_contents)):\n",
        "  tabs.set_title(i, video_ids[i][0])\n",
        "display(tabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "bf6-9i1R5Q9w"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_The_training_loop_Bonus_Video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "AoPelJTp5Q9w"
      },
      "source": [
        "## Bonus 1.2: Backpropagation Reminder\n",
        "\n",
        "_Feel free to skip if you've got a good handle on Backpropagation_\n",
        "\n",
        "We know that we multiply the input data/tensors with weight matrices to obtain some output. Initially, we don't know what the actual weight matrices are so we initialize them with some random values. These random weight matrices when applied as a transformation on the input gives us some output. At first the outputs/predictions will match the true labels only by chance.\n",
        "\n",
        "To improve performance, we need to change the weight matrices so that the predicted outputs are similar to the true outputs (labels). We first calculate how far away the predicted outputs are to the true outputs using a loss function. Based on the loss function, we change the values of our weight matrices using the gradients of the error with respect to the weight matrices.\n",
        "\n",
        "Since we are using PyTorch throughout the course, we will use the built-in functions to update the weights. We call the `backward()` method on our 'loss' variable to calculate the gradients/derivatives with respect to all the weight matrices and biases. And then we call the `step()` method on the optimizer variable to apply the gradient updates to our weight matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "bZG4x3BL5Q9w"
      },
      "source": [
        "Here's an animation of backpropagation works.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/Backpropagation.gif\">\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "In [this article](https://machinelearningknowledge.ai/animated-explanation-of-feed-forward-neural-network-architecture/) you can find more animations!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TyaYIlFQ5Q9w"
      },
      "source": [
        "Let's first see a sample training loop. First, we create the network and load a dataset. Then we look at the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "3j4EyFAe5Q9w"
      },
      "outputs": [],
      "source": [
        "class emnist_net(nn.Module):\n",
        "  \"\"\"\n",
        "  Create a sample network\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialise parameters of sample network\n",
        "\n",
        "    Args:\n",
        "      None\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    # First define the layers.\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "    self.fc1 = nn.Linear(7 * 7 * 64, 256)\n",
        "    self.fc2 = nn.Linear(256, 26)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of sample network\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Output after passing through sample network\n",
        "    \"\"\"\n",
        "    # Conv layer 1.\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2)\n",
        "\n",
        "    # Conv layer 2.\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2)\n",
        "\n",
        "    # Fully connected layer 1.\n",
        "    x = x.view(-1, 7 * 7 * 64)  # You have to first flatten the ourput from the\n",
        "                            # previous convolution layer.\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Fully connected layer 2.\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "573D7Pu55Q9x"
      },
      "outputs": [],
      "source": [
        "# @title Load a sample dataset (EMNIST)\n",
        "# Download the data if there are not downloaded\n",
        "fname = 'EMNIST.zip'\n",
        "folder = 'EMNIST'\n",
        "url = \"https://osf.io/xwfaj/download\"\n",
        "download_data(fname, folder, url, tar=False)\n",
        "\n",
        "mnist_train = datasets.EMNIST(root=\".\",\n",
        "                              train=True,\n",
        "                              transform=transforms.ToTensor(),\n",
        "                              download=False,\n",
        "                              split='letters')\n",
        "mnist_test = datasets.EMNIST(root=\".\",\n",
        "                             train=False,\n",
        "                             transform=transforms.ToTensor(),\n",
        "                             download=False,\n",
        "                             split='letters')\n",
        "\n",
        "# Labels should start from 0\n",
        "mnist_train.targets -= 1\n",
        "mnist_test.targets -= 1\n",
        "\n",
        "# Create data loaders\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=2,\n",
        "                                           worker_init_fn=seed_worker,\n",
        "                                           generator=g_seed)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=2,\n",
        "                                          worker_init_fn=seed_worker,\n",
        "                                          generator=g_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "v1eRDMiY5Q9x"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "# Instantiate model\n",
        "# Puts the Model on the GPU (Select runtime-type as GPU\n",
        "#                            from the 'Runtime->Change Runtime type' option).\n",
        "\n",
        "model = emnist_net().to(DEVICE)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Make changes here, if necessary\n",
        "\n",
        "# Iterate through train set minibatchs\n",
        "for epoch in trange(3):  # Make changes here, if necessary\n",
        "  for images, labels in tqdm(train_loader):\n",
        "\n",
        "    # Zero out the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    x = images\n",
        "    # Move the data to GPU for faster execution.\n",
        "    x, labs = x.to(DEVICE), labels.to(DEVICE)\n",
        "    y = model(x)\n",
        "\n",
        "    # Calculate loss.\n",
        "    loss = criterion(y, labs)\n",
        "\n",
        "    # Backpropagation and gradient update.\n",
        "    loss.backward() # Calculate gradients.\n",
        "    optimizer.step() # Apply gradient udpate.\n",
        "\n",
        "\n",
        "## Testing\n",
        "correct = 0\n",
        "total = len(mnist_test)\n",
        "\n",
        "with torch.no_grad():\n",
        "  # Iterate through test set minibatchs\n",
        "  for images, labels in tqdm(test_loader):\n",
        "    # Forward pass\n",
        "    x = images\n",
        "      # Move the data to GPU for faster execution.\n",
        "    x, labs = x.to(DEVICE), labels.to(DEVICE)\n",
        "    y = model(x)\n",
        "\n",
        "    predictions = torch.argmax(y, dim=1)\n",
        "    correct += torch.sum((predictions == labs).float())\n",
        "\n",
        "print(f'Test accuracy: {correct / total * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "E_VjNGZO5Q9x"
      },
      "source": [
        "You already coded the structure of a CNN. Now, you are going to implement the training loop for a CNN.\n",
        "- Choose the correct criterion\n",
        "- Code up the training part (calculating gradients, loss, stepping forward)\n",
        "- Keep a track of the running loss i.e for each epoch we want to to know the average loss of the batch size. We have already done the same for accuracy for you.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "zM2AkygC5Q9x"
      },
      "source": [
        "## Bonus 1.3: Fashion-MNIST dataset\n",
        "Now Let us train on the actual Fashion-MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Pu9C2ff05Q9x"
      },
      "outputs": [],
      "source": [
        "# @markdown ##### Getting the DataLoaders (Run Me)\n",
        "\n",
        "\n",
        "def get_data_loaders(train_dataset, validation_dataset,\n",
        "                     test_dataset, seed,\n",
        "                     batch_size=64):\n",
        "  \"\"\"\n",
        "  Helper function to fetch dataloaders\n",
        "\n",
        "  Args:\n",
        "    train_dataset: torch.tensor\n",
        "      Training data\n",
        "    test_dataset: torch.tensor\n",
        "      Test data\n",
        "    validation_dataset: torch.tensor\n",
        "      Validation data\n",
        "    batch_size: int\n",
        "      Batch Size  [default: 64]\n",
        "    seed: int\n",
        "      Set seed for reproducibility\n",
        "\n",
        "  Returns:\n",
        "    train_loader: torch.loader\n",
        "      Training Data\n",
        "    test_loader: torch.loader\n",
        "      Test Data\n",
        "    validation_loader: torch.loader\n",
        "      Validation Data\n",
        "  \"\"\"\n",
        "\n",
        "  g_seed = torch.Generator()\n",
        "  g_seed.manual_seed(seed)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=2,\n",
        "                            worker_init_fn=seed_worker,\n",
        "                            generator=g_seed)\n",
        "  validation_loader = DataLoader(validation_dataset,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 num_workers=2,\n",
        "                                 worker_init_fn=seed_worker,\n",
        "                                 generator=g_seed)\n",
        "  test_loader = DataLoader(test_dataset,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=True,\n",
        "                           num_workers=2,\n",
        "                           worker_init_fn=seed_worker,\n",
        "                           generator=g_seed)\n",
        "\n",
        "  return train_loader, validation_loader, test_loader\n",
        "\n",
        "\n",
        "train_loader, validation_loader, test_loader = get_data_loaders(train_data,\n",
        "                                                                validation_data,\n",
        "                                                                test_data, SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "rVAOWUR45Q9x"
      },
      "outputs": [],
      "source": [
        "class FMNIST_Net1(nn.Module):\n",
        "  \"\"\"\n",
        "  Convolutional Neural Network\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_classes):\n",
        "    \"\"\"\n",
        "    Initialise parameters of CNN\n",
        "\n",
        "    Args:\n",
        "      num_classes: int\n",
        "        Number of classes\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(FMNIST_Net1, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of CNN\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Output after passing through CNN\n",
        "    \"\"\"\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ky8mmaTS5Q9x"
      },
      "source": [
        "## Coding Exercise Bonus 1: Code the training loop\n",
        "\n",
        "Now try coding the training loop.\n",
        "\n",
        "You should first have a `criterion` defined (you can use `CrossEntropyLoss` here, which you learned about last week) so that you can calculate the loss. Next, you should to put everything together. Start the training process by first obtaining the model output, calculating the loss, and finally updating the weights.\n",
        "\n",
        "*Don't forget to zero out the gradients.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "pTm-l8q35Q9x"
      },
      "source": [
        "**Note:** The comments in the `train` function provides many hints that will help you fill in the missing code. This will give you a solid understanding of the different steps involved in the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "WRHGuGC95Q9y"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, validation_loader, epochs):\n",
        "  \"\"\"\n",
        "  Training loop\n",
        "\n",
        "  Args:\n",
        "    model: nn.module\n",
        "      Neural network instance\n",
        "    device: string\n",
        "      GPU/CUDA if available, CPU otherwise\n",
        "    epochs: int\n",
        "      Number of epochs\n",
        "    train_loader: torch.loader\n",
        "      Training Set\n",
        "    validation_loader: torch.loader\n",
        "      Validation set\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  criterion =  nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "  train_loss, validation_loss = [], []\n",
        "  train_acc, validation_acc = [], []\n",
        "  with tqdm(range(epochs), unit='epoch') as tepochs:\n",
        "    tepochs.set_description('Training')\n",
        "    for epoch in tepochs:\n",
        "      model.train()\n",
        "      # Keeps track of the running loss\n",
        "      running_loss = 0.\n",
        "      correct, total = 0, 0\n",
        "      for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        ####################################################################\n",
        "        # Fill in missing code below (...),\n",
        "        # then remove or comment the line below to test your function\n",
        "        raise NotImplementedError(\"Update the steps of the train loop\")\n",
        "        ####################################################################\n",
        "        # COMPLETE CODE FOR TRAINING LOOP by following these steps\n",
        "        # 1. Get the model output (call the model with the data from this batch)\n",
        "        output = ...\n",
        "\n",
        "        # 2. Zero the gradients out (i.e. reset the gradient that the optimizer\n",
        "        #                       has collected so far with optimizer.zero_grad())\n",
        "        ...\n",
        "\n",
        "        # 3. Get the Loss (call the loss criterion with the model's output\n",
        "        #                  and the target values)\n",
        "        loss = ...\n",
        "\n",
        "        # 4. Calculate the gradients (do the pass backwards from the loss\n",
        "        #                             with loss.backward())\n",
        "        ...\n",
        "\n",
        "        # 5. Update the weights (using the training step of the optimizer,\n",
        "        #                        optimizer.step())\n",
        "        ...\n",
        "\n",
        "        ####################################################################\n",
        "        # Fill in missing code below (...),\n",
        "        # then remove or comment the line below to test your function\n",
        "        raise NotImplementedError(\"Update the set_postfix function\")\n",
        "        ####################################################################\n",
        "        # Set loss to whatever you end up naming your variable when\n",
        "        # calling criterion\n",
        "        # For example, loss = criterion(output, target)\n",
        "        # then set loss = loss.item() in the set_postfix function\n",
        "        tepochs.set_postfix(loss=...)\n",
        "        running_loss += ...  # Add the loss for this batch\n",
        "\n",
        "        # Get accuracy\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "      ####################################################################\n",
        "      # Fill in missing code below (...),\n",
        "      # then remove or comment the line below to test your function\n",
        "      raise NotImplementedError(\"Append the train_loss\")\n",
        "      ####################################################################\n",
        "      train_loss.append(...)  # Append the loss for this epoch (running loss divided by the number of batches e.g. len(train_loader))\n",
        "      train_acc.append(correct / total)\n",
        "\n",
        "      # Evaluate on validation data\n",
        "      model.eval()\n",
        "      running_loss = 0.\n",
        "      correct, total = 0, 0\n",
        "      for data, target in validation_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        tepochs.set_postfix(loss=loss.item())\n",
        "        running_loss += loss.item()\n",
        "        # Get accuracy\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "      validation_loss.append(running_loss / len(validation_loader))\n",
        "      validation_acc.append(correct / total)\n",
        "\n",
        "  return train_loss, train_acc, validation_loss, validation_acc\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "## Uncomment to test your training loop\n",
        "# net = FMNIST_Net1(num_classes=2).to(DEVICE)\n",
        "# train_loss, train_acc, validation_loss, validation_acc = train(net, DEVICE, train_loader, validation_loader, 20)\n",
        "# print(f'Test accuracy is: {test(net, DEVICE, test_loader)}')\n",
        "# plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "A5XFTLGA5Q9y"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_1279086f.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=1524.0 height=525.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_1279086f_3.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "uQNphiDd5Q9y"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Code_the_training_loop_Bonus_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "SatdBUJY5Q9y"
      },
      "source": [
        "## Think! Bonus 1: Overfitting\n",
        "Do you think this network is overfitting?\n",
        "If yes, what can you do to combat this?\n",
        "\n",
        "**Hint**: Overfitting occurs when the training accuracy greatly exceeds the validation accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "f79C8Lgp5Q9y"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_3ef24bd7.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "yhb3ig3T5Q9y"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Overfitting_Bonus_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "FZUzXOHv5Q9y"
      },
      "source": [
        "---\n",
        "# Bonus 2: Overfitting - symptoms and cures\n",
        "\n",
        "*Time estimate: ~30mins*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BXtD9Qdu5Q9y"
      },
      "source": [
        "So you spent some time last week learning about regularization techniques. Below is a copy of the CNN model we used previously.  Now we want you to add some dropout regularization, and check if that helps reduce overfitting. If you're up for a challenge, you can try methods other than dropout as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Qd0lXSkg5Q9y"
      },
      "source": [
        "## Bonus 2.1: Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6v2qitUs5Q9y"
      },
      "source": [
        "### Coding Exercise Bonus 2.1: Adding Regularization\n",
        "\n",
        "Add various regularization methods, feel free to add any and play around!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "5lT2pfdO5Q9y"
      },
      "outputs": [],
      "source": [
        "class FMNIST_Net2(nn.Module):\n",
        "  \"\"\"\n",
        "  Neural Network instance\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_classes):\n",
        "    \"\"\"\n",
        "    Initialise parameters of FMNIST_Net2\n",
        "\n",
        "    Args:\n",
        "      num_classes: int\n",
        "        Number of classes\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    super(FMNIST_Net2, self).__init__()\n",
        "    ####################################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your function\n",
        "    raise NotImplementedError(\"Add regularization layers\")\n",
        "    ####################################################################\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout1 = ...\n",
        "    self.dropout2 = ...\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of FMNIST_Net2\n",
        "\n",
        "    Args:\n",
        "      x: torch.tensor\n",
        "        Input features\n",
        "\n",
        "    Returns:\n",
        "      x: torch.tensor\n",
        "        Output after passing through FMNIST_Net2\n",
        "    \"\"\"\n",
        "    ####################################################################\n",
        "    # Now add the layers in your forward pass in appropriate order\n",
        "    # then remove or comment the line below to test your function\n",
        "    raise NotImplementedError(\"Add regularization in the forward pass\")\n",
        "    ####################################################################\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = ...\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = ...\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "## Uncomment below to check your code\n",
        "# net2 = FMNIST_Net2(num_classes=2).to(DEVICE)\n",
        "# train_loss, train_acc, validation_loss, validation_acc = train(net2, DEVICE, train_loader, validation_loader, 20)\n",
        "# print(f'Test accuracy is: {test(net2, DEVICE, test_loader)}')\n",
        "# plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1gZI79cB5Q9z"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_0adbc972.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=1525.0 height=525.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_0adbc972_3.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "MDCh-_lB5Q9z"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Adding_Regularization_Bonus_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "LDlaG6Ef5Q9z"
      },
      "source": [
        "### Think! Bonus 2.1: Regularization\n",
        "\n",
        "1. Is the training accuracy slightly reduced from before adding regularization? What accuracy were you able to reduce it to?\n",
        "\n",
        "2. Why does the validation accuracy start higher than training accuracy?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HHA8r9xC5Q9z"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_6e9ea2ef.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "a5b-to155Q9z"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Adding_Regularization_Bonus_Discussion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "xODNWoYg5Q9z"
      },
      "source": [
        "### Interactive Demo Bonus 2.1: Dropout exploration\n",
        "\n",
        "If you want to try out more dropout parameter combinations, but do not have the time to run them, we have here precalculated some combinations you can use the sliders to explore them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "X7RV4VIK5Q9z"
      },
      "outputs": [],
      "source": [
        "# @markdown *Run this cell to enable the widget*\n",
        "\n",
        "import io, base64\n",
        "from ipywidgets import widgets, interactive_output\n",
        "\n",
        "data = [[0, 0, [0.3495898238046372, 0.2901147632522786, 0.2504794800931469, 0.23571575765914105, 0.21297093365896255, 0.19087818914905508, 0.186408187797729, 0.19487689035211472, 0.16774938120803934, 0.1548648244958926, 0.1390149021382503, 0.10919439224922593, 0.10054351237820501, 0.09900783193594914, 0.08370604479507088, 0.07831853718318521, 0.06859792241866285, 0.06152600247383197, 0.046342475851873885, 0.055123823092992796], [0.83475, 0.8659166666666667, 0.8874166666666666, 0.8913333333333333, 0.8998333333333334, 0.9140833333333334, 0.9178333333333333, 0.9138333333333334, 0.9251666666666667, 0.92975, 0.939, 0.9525833333333333, 0.9548333333333333, 0.9585833333333333, 0.9655833333333333, 0.9661666666666666, 0.9704166666666667, 0.9743333333333334, 0.9808333333333333, 0.9775], [0.334623601436615, 0.2977438402175903, 0.2655304968357086, 0.25506321132183074, 0.2588835284113884, 0.2336345863342285, 0.3029863876104355, 0.240766831189394, 0.2719801160693169, 0.25231350839138034, 0.2500132185220718, 0.26699506521224975, 0.2934862145781517, 0.361227530837059, 0.33196919202804565, 0.36985905408859254, 0.4042587959766388, 0.3716402840614319, 0.3707024946808815, 0.4652537405490875], [0.866875, 0.851875, 0.8775, 0.889375, 0.881875, 0.900625, 0.85, 0.898125, 0.885625, 0.876875, 0.899375, 0.90625, 0.89875, 0.87, 0.898125, 0.884375, 0.874375, 0.89375, 0.903125, 0.890625]], [0, 0.25, [0.35404509995528993, 0.30616586227366266, 0.2872369573946963, 0.27564131199045383, 0.25969504263806853, 0.24728168408445855, 0.23505379509260046, 0.21552803914280647, 0.209761732277718, 0.19977611067526518, 0.19632092922767427, 0.18672360206379535, 0.16564940239124476, 0.1654047035671612, 0.1684555298985636, 0.1627526102349796, 0.13878319327263755, 0.12881529055773577, 0.12628930977525862, 0.11346105090837846], [0.8324166666666667, 0.8604166666666667, 0.8680833333333333, 0.8728333333333333, 0.8829166666666667, 0.88625, 0.89425, 0.90125, 0.9015833333333333, 0.90925, 0.9114166666666667, 0.917, 0.9268333333333333, 0.92475, 0.921, 0.9255833333333333, 0.9385, 0.9428333333333333, 0.9424166666666667, 0.9484166666666667], [0.3533937376737595, 0.29569859683513644, 0.27531551957130435, 0.2576177391409874, 0.26947550356388095, 0.25361743807792664, 0.2527468180656433, 0.24179009914398195, 0.28664454460144045, 0.23347773611545564, 0.24672816634178163, 0.27822364538908007, 0.2380720081925392, 0.24426509588956832, 0.2443918392062187, 0.24207917481660843, 0.2519641682505608, 0.3075403380393982, 0.2798181238770485, 0.26709021866321564], [0.826875, 0.87, 0.870625, 0.8875, 0.883125, 0.88625, 0.891875, 0.891875, 0.890625, 0.903125, 0.89375, 0.885625, 0.903125, 0.888125, 0.899375, 0.898125, 0.905, 0.905625, 0.898125, 0.901875]], [0, 0.5, [0.39775496332886373, 0.33771887778284704, 0.321900939132939, 0.3079229625774191, 0.304149763301966, 0.28249239723416086, 0.2861261191044716, 0.27356165798103554, 0.2654648520686525, 0.2697350280557541, 0.25354846321204877, 0.24612889034633942, 0.23482802549892284, 0.2389904112416379, 0.23742155821875055, 0.232423192127905, 0.22337309338469455, 0.2141852991932884, 0.20677659985549907, 0.19355326712607068], [0.8155, 0.83625, 0.8481666666666666, 0.8530833333333333, 0.8571666666666666, 0.86775, 0.8623333333333333, 0.8711666666666666, 0.8748333333333334, 0.8685833333333334, 0.8785, 0.8804166666666666, 0.8835833333333334, 0.8840833333333333, 0.88875, 0.8919166666666667, 0.8946666666666667, 0.8960833333333333, 0.906, 0.9063333333333333], [0.3430288594961166, 0.4062050700187683, 0.29745822548866274, 0.27728439271450045, 0.28092808067798614, 0.2577864158153534, 0.2651400637626648, 0.25632822573184966, 0.3082498562335968, 0.2812121778726578, 0.26345942318439486, 0.2577408078312874, 0.25757989794015884, 0.26434457510709763, 0.24917411386966706, 0.27261342853307724, 0.2445397639274597, 0.26001051396131514, 0.24147838801145555, 0.2471102523803711], [0.82875, 0.795625, 0.87, 0.87375, 0.865625, 0.8825, 0.8825, 0.87625, 0.848125, 0.87875, 0.8675, 0.889375, 0.8925, 0.866875, 0.87375, 0.87125, 0.895625, 0.90375, 0.90125, 0.88625]], [0, 0.75, [0.4454924576777093, 0.43416607585993217, 0.42200265769311723, 0.40520024616667566, 0.41137005166804536, 0.404100904280835, 0.40118067664034823, 0.40139733080534223, 0.3797615355158106, 0.3596332479030528, 0.3600061919460905, 0.3554147962242999, 0.34480382890460337, 0.3329520877054397, 0.33164913056695716, 0.31860941466181836, 0.30702565340919696, 0.30605297186907304, 0.2953788426486736, 0.2877389984403519], [0.7788333333333334, 0.7825, 0.7854166666666667, 0.7916666666666666, 0.7885, 0.7833333333333333, 0.7923333333333333, 0.79525, 0.805, 0.81475, 0.8161666666666667, 0.8188333333333333, 0.817, 0.8266666666666667, 0.82225, 0.8360833333333333, 0.8456666666666667, 0.8430833333333333, 0.8491666666666666, 0.8486666666666667], [0.3507828885316849, 0.3337512403726578, 0.34320746660232543, 0.3476085543632507, 0.3326113569736481, 0.33033264458179473, 0.32014619171619413, 0.3182142299413681, 0.30076164126396177, 0.3263852882385254, 0.27597591280937195, 0.29062016785144806, 0.2765174686908722, 0.269492534995079, 0.2679423809051514, 0.2691828978061676, 0.2726386785507202, 0.2541181230545044, 0.2580208206176758, 0.26315389811992645], [0.839375, 0.843125, 0.823125, 0.821875, 0.81875, 0.819375, 0.8225, 0.826875, 0.835625, 0.865, 0.868125, 0.855625, 0.868125, 0.884375, 0.883125, 0.875, 0.87375, 0.883125, 0.8975, 0.885]], [0.25, 0, [0.34561181647029326, 0.2834314257699124, 0.2583787844298368, 0.23892096465730922, 0.23207981773513428, 0.20245029634617745, 0.183908417583146, 0.17489413774393975, 0.17696723581707857, 0.15615438255778652, 0.14469048382833283, 0.12424647461305907, 0.11314761043189371, 0.11249036608422373, 0.10725672634199579, 0.09081190969160896, 0.0942245383271353, 0.08525650047677312, 0.06622548752583246, 0.06039895973307021], [0.8356666666666667, 0.8675833333333334, 0.88175, 0.8933333333333333, 0.8975833333333333, 0.91175, 0.91825, 0.9249166666666667, 0.9238333333333333, 0.9305, 0.938, 0.9465833333333333, 0.9525833333333333, 0.9539166666666666, 0.9555, 0.9615, 0.9606666666666667, 0.96275, 0.9725, 0.9764166666666667], [0.31630186855792997, 0.2702121251821518, 0.2915778249502182, 0.26050266206264494, 0.27837209939956664, 0.24276352763175965, 0.3567117482423782, 0.2752074319124222, 0.2423130339384079, 0.2565067422389984, 0.28710135877132414, 0.266545415520668, 0.31818037331104276, 0.28757534325122835, 0.2777567034959793, 0.2998969575762749, 0.3292293107509613, 0.30775387287139894, 0.32681577146053314, 0.44882203072309496], [0.85375, 0.879375, 0.875625, 0.89, 0.86125, 0.884375, 0.851875, 0.8875, 0.89625, 0.875625, 0.8675, 0.895, 0.888125, 0.89125, 0.889375, 0.880625, 0.87875, 0.8875, 0.894375, 0.891875]], [0.25, 0.25, [0.35970850011452715, 0.31336131549261986, 0.2881505932421126, 0.2732012960267194, 0.26232245425753137, 0.2490472443639598, 0.24866499093935845, 0.22930880945096624, 0.21745950407645803, 0.20700296882460725, 0.197304340356842, 0.20665066804182022, 0.19864868348900308, 0.184807124210799, 0.1684703354703936, 0.17377675851767369, 0.16638460063791655, 0.15944768343754906, 0.14876513817208878, 0.1388207479835825], [0.83375, 0.85175, 0.86725, 0.8719166666666667, 0.8761666666666666, 0.8865833333333333, 0.88275, 0.8956666666666667, 0.8995833333333333, 0.9034166666666666, 0.90825, 0.9043333333333333, 0.9093333333333333, 0.9145, 0.9196666666666666, 0.9196666666666666, 0.9216666666666666, 0.9273333333333333, 0.9299166666666666, 0.93675], [0.3166788029670715, 0.28422485530376435, 0.38055971562862395, 0.2586472672224045, 0.2588653892278671, 0.27983254253864287, 0.25693483114242555, 0.26412731170654297, 0.2733065390586853, 0.24399636536836625, 0.24481021404266357, 0.2689305514097214, 0.2527604129910469, 0.24829535871744157, 0.2654112687706947, 0.23074268400669098, 0.24625462979078294, 0.26423920392990113, 0.25540480852127073, 0.25536185175180437], [0.856875, 0.86625, 0.815, 0.8825, 0.88125, 0.875625, 0.89, 0.8775, 0.870625, 0.895, 0.8975, 0.87375, 0.88625, 0.89125, 0.903125, 0.9, 0.893125, 0.89, 0.8925, 0.899375]], [0.25, 0.5, [0.3975753842040579, 0.34884724409339274, 0.3296900932142075, 0.3150389680361494, 0.31285368667003954, 0.30415422033439293, 0.29553352716438314, 0.289314468094009, 0.2806722329969102, 0.2724469883486311, 0.26634286379719035, 0.2645016222241077, 0.2619251853766594, 0.2551752221473354, 0.26411766035759704, 0.24515971153023394, 0.2390686312412962, 0.23573122312255362, 0.221005061562074, 0.22358600648635246], [0.8106666666666666, 0.8286666666666667, 0.844, 0.8513333333333334, 0.84975, 0.8570833333333333, 0.8624166666666667, 0.8626666666666667, 0.866, 0.8706666666666667, 0.8738333333333334, 0.8748333333333334, 0.8778333333333334, 0.8798333333333334, 0.87375, 0.8865, 0.8898333333333334, 0.8885833333333333, 0.8991666666666667, 0.8968333333333334], [0.3597823417186737, 0.31115993797779085, 0.29929635107517244, 0.2986589139699936, 0.2938830828666687, 0.28118040919303894, 0.2711684626340866, 0.2844697123765945, 0.26613601863384245, 0.2783134698867798, 0.2540236383676529, 0.25821100890636445, 0.2618845862150192, 0.2554920208454132, 0.26543013513088226, 0.24074569433927537, 0.26475649774074556, 0.25578504264354707, 0.2648500043153763, 0.25700133621692656], [0.825, 0.8375, 0.85875, 0.855625, 0.861875, 0.868125, 0.875, 0.85375, 0.886875, 0.86375, 0.88375, 0.885625, 0.875625, 0.87375, 0.8875, 0.895, 0.874375, 0.89125, 0.88625, 0.895625]], [0.25, 0.75, [0.4584837538447786, 0.4506375778545725, 0.4378386567089152, 0.4066803843734112, 0.3897064097542712, 0.3855383962868376, 0.39160584618753574, 0.3731403942120836, 0.37915910170116324, 0.36966170814443144, 0.35735995298687445, 0.35630573094525236, 0.346426092167484, 0.34040802899510303, 0.32829743726773464, 0.3284692421872565, 0.3186114077713895, 0.32295761503120685, 0.3201326223764014, 0.30581602454185486], [0.7803333333333333, 0.7709166666666667, 0.7723333333333333, 0.7850833333333334, 0.7885, 0.7903333333333333, 0.7986666666666666, 0.805, 0.8011666666666667, 0.8068333333333333, 0.8095833333333333, 0.8226666666666667, 0.8285, 0.83125, 0.8369166666666666, 0.8395, 0.8441666666666666, 0.8393333333333334, 0.8490833333333333, 0.8546666666666667], [0.43526833415031435, 0.3598956459760666, 0.3492005372047424, 0.33501910269260404, 0.31689528703689573, 0.3113307124376297, 0.32388085544109346, 0.3084335786104202, 0.3013568025827408, 0.28992725372314454, 0.28726822674274444, 0.26945948660373686, 0.276592333316803, 0.27462401330471037, 0.27574350595474245, 0.2710308712720871, 0.2702724140882492, 0.27323003828525544, 0.25551479041576386, 0.26488787233829497], [0.808125, 0.81625, 0.805, 0.8325, 0.846875, 0.835625, 0.850625, 0.838125, 0.836875, 0.861875, 0.85375, 0.866875, 0.858125, 0.8825, 0.879375, 0.874375, 0.874375, 0.886875, 0.883125, 0.86875]], [0.5, 0, [0.3579516930783049, 0.29596046564426826, 0.2779693031247626, 0.2563994538356015, 0.24771526356802342, 0.2324555875693864, 0.2139121579362991, 0.20474095547452886, 0.19138856208387842, 0.18883306279461434, 0.1763652620757831, 0.1698919345248253, 0.16033914366221808, 0.1557997044651432, 0.1432509447467771, 0.13817814606776896, 0.12609625801919622, 0.11830132696381275, 0.11182412960903441, 0.112559904720872], [0.8314166666666667, 0.8611666666666666, 0.8736666666666667, 0.8800833333333333, 0.885, 0.8944166666666666, 0.9036666666666666, 0.9090833333333334, 0.9193333333333333, 0.9161666666666667, 0.92225, 0.9255, 0.93075, 0.93225, 0.939, 0.9414166666666667, 0.94375, 0.9485833333333333, 0.9535833333333333, 0.9524166666666667], [0.30677567660808563, 0.32954772651195524, 0.25747098088264464, 0.2736126834154129, 0.2561805549263954, 0.23671718776226044, 0.24553639352321624, 0.2338863667845726, 0.24586652517318724, 0.23423030972480774, 0.26579618513584136, 0.2781539523601532, 0.27084136098623274, 0.23948652744293214, 0.26023868829011915, 0.2419952344894409, 0.2511997854709625, 0.23935708701610564, 0.2701922015845776, 0.27307246536016466], [0.870625, 0.855625, 0.886875, 0.875625, 0.878125, 0.8925, 0.885, 0.890625, 0.876875, 0.896875, 0.881875, 0.8875, 0.89, 0.898125, 0.896875, 0.89, 0.89875, 0.904375, 0.906875, 0.894375]], [0.5, 0.25, [0.3712943946903056, 0.3198322071594761, 0.29978102302931725, 0.295274139798068, 0.2861913934032968, 0.27165328782606635, 0.25972246442069397, 0.2543164194819141, 0.24795781916126292, 0.24630710007028378, 0.23296909834793272, 0.23382153587931015, 0.2239028559799524, 0.21443849290780564, 0.2149274461367663, 0.20642021417300752, 0.19801520536396097, 0.1978839404009124, 0.19118623847657062, 0.18144798041024107], [0.8235833333333333, 0.8538333333333333, 0.8604166666666667, 0.86075, 0.8664166666666666, 0.8754166666666666, 0.8799166666666667, 0.8815833333333334, 0.88725, 0.8848333333333334, 0.8936666666666667, 0.8935, 0.895, 0.8995, 0.89625, 0.9068333333333334, 0.9098333333333334, 0.9120833333333334, 0.91375, 0.9175833333333333], [0.3184810388088226, 0.2948088157176971, 0.29438531696796416, 0.27669853866100313, 0.2634278678894043, 0.25847582578659056, 0.2500907778739929, 0.2538330048322678, 0.25127841770648957, 0.2519759064912796, 0.2455715072154999, 0.2437664610147476, 0.259639236330986, 0.24515749186277389, 0.2553828465938568, 0.2324645048379898, 0.24492083072662355, 0.24482838332653045, 0.23327024638652802, 0.2520161652565002], [0.855, 0.865, 0.8525, 0.856875, 0.876875, 0.88125, 0.8825, 0.8875, 0.8925, 0.8925, 0.88875, 0.889375, 0.87375, 0.895, 0.889375, 0.90625, 0.883125, 0.895, 0.899375, 0.901875]], [0.5, 0.5, [0.40442772225496615, 0.36662670541951, 0.355034276367502, 0.3396551510755052, 0.3378269396563794, 0.32084332002287214, 0.31314464951766297, 0.2982726935693558, 0.2885229691387491, 0.2888992782285873, 0.2893476904706752, 0.281817957996688, 0.2771622718490185, 0.2693793097550565, 0.2617615883416952, 0.2657115764995205, 0.25631817549150043, 0.24793559907281654, 0.2538738044652533, 0.23912971732305718], [0.8093333333333333, 0.82825, 0.8341666666666666, 0.84525, 0.84525, 0.8515, 0.8583333333333333, 0.8626666666666667, 0.8688333333333333, 0.8685, 0.8689166666666667, 0.8693333333333333, 0.8711666666666666, 0.8766666666666667, 0.88275, 0.88175, 0.8839166666666667, 0.8866666666666667, 0.8839166666666667, 0.8929166666666667], [0.38392188608646394, 0.3653419762849808, 0.3050421380996704, 0.30614266455173494, 0.2937217426300049, 0.30008585572242735, 0.2794034606218338, 0.27541795969009397, 0.31378355383872986, 0.2670704126358032, 0.26745485186576845, 0.2471194839477539, 0.26509816259145735, 0.25458798944950106, 0.2481587851047516, 0.25591064751148224, 0.2596563971042633, 0.2569611769914627, 0.2435744071006775, 0.2507249677181244], [0.820625, 0.846875, 0.856875, 0.868125, 0.860625, 0.87125, 0.86625, 0.87375, 0.865625, 0.87875, 0.878125, 0.889375, 0.87875, 0.886875, 0.89125, 0.89, 0.87375, 0.884375, 0.88875, 0.89375]], [0.5, 0.75, [0.46106574311852455, 0.4519433615372536, 0.4446939624687459, 0.4284856241751224, 0.4527993325857406, 0.4220876024758562, 0.40969764266876463, 0.39233948219012704, 0.42498463344700793, 0.3869199570506177, 0.38021832910623954, 0.3855376149270129, 0.3721433773319772, 0.3662295250340979, 0.3629763710530514, 0.358500304691335, 0.3490118366131123, 0.34879197790584665, 0.33399240054348683, 0.3347948451149971], [0.7866666666666666, 0.7865, 0.784, 0.79375, 0.7755833333333333, 0.79125, 0.7973333333333333, 0.8085833333333333, 0.7913333333333333, 0.8125833333333333, 0.81675, 0.812, 0.8173333333333334, 0.8235833333333333, 0.831, 0.8306666666666667, 0.8353333333333334, 0.8320833333333333, 0.84375, 0.8410833333333333], [0.35159709095954894, 0.3579048192501068, 0.3501501774787903, 0.33594816565513613, 0.3741619431972504, 0.34183687329292295, 0.3353554099798203, 0.32617265462875367, 0.3640907108783722, 0.33187183618545535, 0.32401839792728426, 0.30536725163459777, 0.31303414940834046, 0.2893040508031845, 0.3063929396867752, 0.2909839802980423, 0.2858921372890472, 0.2850045281648636, 0.28049838364124297, 0.2873564797639847], [0.816875, 0.793125, 0.810625, 0.821875, 0.8175, 0.82, 0.816875, 0.814375, 0.828125, 0.83875, 0.818125, 0.843125, 0.834375, 0.85875, 0.874375, 0.85375, 0.870625, 0.85375, 0.883125, 0.848125]], [0.75, 0, [0.37716902824158366, 0.3260373148195287, 0.3128290904012132, 0.2998493126732238, 0.29384377892030045, 0.2759418967873492, 0.26431119905665834, 0.2577077782455277, 0.25772295725789474, 0.24954422610871335, 0.24065862928933285, 0.23703582263848882, 0.23237684028262787, 0.2200249534575863, 0.22110319957929722, 0.21804759631607126, 0.21419822757548473, 0.19927451733816812, 0.19864692467641323, 0.18966749441274938], [0.8215833333333333, 0.848, 0.8526666666666667, 0.8585, 0.8639166666666667, 0.8716666666666667, 0.8783333333333333, 0.8849166666666667, 0.88325, 0.88325, 0.8918333333333334, 0.8913333333333333, 0.896, 0.9010833333333333, 0.8996666666666666, 0.9016666666666666, 0.902, 0.9120833333333334, 0.9105833333333333, 0.9160833333333334], [0.3255926352739334, 0.3397491586208343, 0.3148202610015869, 0.30447013437747955, 0.27427292466163633, 0.2607581865787506, 0.2583494257926941, 0.24150457441806794, 0.24839721441268922, 0.24157819360494615, 0.24594406485557557, 0.2547012311220169, 0.24132476687431337, 0.2433958488702774, 0.2358475297689438, 0.24675665378570558, 0.23343635857105255, 0.22841362684965133, 0.2247604575753212, 0.24281086921691894], [0.85125, 0.85125, 0.853125, 0.851875, 0.876875, 0.87875, 0.883125, 0.888125, 0.89, 0.888125, 0.88375, 0.86625, 0.88375, 0.888125, 0.898125, 0.88875, 0.896875, 0.894375, 0.899375, 0.88625]], [0.75, 0.25, [0.3795942336796446, 0.33614943612446174, 0.3235826115024851, 0.3267444484728448, 0.30353531146303137, 0.29750882636042353, 0.2964640334248543, 0.28714796314214136, 0.2744278162717819, 0.27310871372514584, 0.2624819800257683, 0.2579742945889209, 0.25963644726954876, 0.25635017161356644, 0.2501001837960583, 0.24249463702769988, 0.23696896695393196, 0.23254455582417072, 0.22419108628751117, 0.22851746232110134], [0.8204166666666667, 0.839, 0.847, 0.8506666666666667, 0.8571666666666666, 0.8635, 0.8639166666666667, 0.8711666666666666, 0.8711666666666666, 0.87475, 0.87875, 0.87925, 0.8805833333333334, 0.8845, 0.88675, 0.8908333333333334, 0.8926666666666667, 0.89525, 0.8985, 0.8955833333333333], [0.3383863967657089, 0.31120560944080355, 0.32110977828502657, 0.3080899566411972, 0.2866462391614914, 0.27701647162437437, 0.29040718913078306, 0.2702513742446899, 0.2590403389930725, 0.26199558019638064, 0.26484714448451996, 0.2940529054403305, 0.2654808533191681, 0.25154681205749513, 0.26637687146663663, 0.24435366928577423, 0.24174826145172118, 0.2444209086894989, 0.247626873254776, 0.24192263156175614], [0.843125, 0.8575, 0.86, 0.86375, 0.87, 0.875625, 0.865, 0.88, 0.879375, 0.885, 0.888125, 0.85625, 0.87625, 0.88375, 0.879375, 0.888125, 0.8875, 0.886875, 0.8825, 0.8925]], [0.75, 0.5, [0.41032169133107715, 0.37122817583223605, 0.35897897873470125, 0.3438001747064768, 0.33858899811797954, 0.3389760729797343, 0.32536247420184156, 0.3152934226425404, 0.30936657058748795, 0.3078679118226183, 0.30974164977669716, 0.30031369174731537, 0.29489042173991814, 0.28921707251921613, 0.28369594476324445, 0.2849519875772456, 0.27076949349584734, 0.26930386248104116, 0.26349931491657774, 0.26431971300948176], [0.8086666666666666, 0.82875, 0.8284166666666667, 0.8381666666666666, 0.837, 0.8389166666666666, 0.8490833333333333, 0.8488333333333333, 0.8533333333333334, 0.8551666666666666, 0.8509166666666667, 0.8615, 0.8628333333333333, 0.86225, 0.8715, 0.86775, 0.8748333333333334, 0.8719166666666667, 0.8814166666666666, 0.8835], [0.3464747530221939, 0.3193131250143051, 0.3464068531990051, 0.3129056388139725, 0.3131117367744446, 0.30689118325710296, 0.2929005026817322, 0.3131696957349777, 0.302835636138916, 0.27934255003929137, 0.300513002872467, 0.26962003886699676, 0.2676294481754303, 0.26430738389492037, 0.2525753951072693, 0.2508367341756821, 0.25303518533706665, 0.24774718701839446, 0.24518848478794097, 0.26084545016288757], [0.8225, 0.85375, 0.849375, 0.853125, 0.85875, 0.848125, 0.856875, 0.8575, 0.87, 0.869375, 0.863125, 0.886875, 0.8725, 0.878125, 0.894375, 0.888125, 0.8875, 0.89125, 0.88875, 0.86875]], [0.75, 0.75, [0.4765880586619073, 0.4503744399928032, 0.4249279998401378, 0.42333967214886176, 0.4236916420941657, 0.4269233151002133, 0.4192506206479478, 0.41413671872083174, 0.41084911515738104, 0.389948022413127, 0.39566395788433706, 0.3741930383951106, 0.3794517093040842, 0.3692300356131919, 0.3640432547223061, 0.3608953575504587, 0.3419572095129084, 0.34907091543712515, 0.33601277535583113, 0.3408893179544743], [0.77625, 0.7823333333333333, 0.7916666666666666, 0.80075, 0.7973333333333333, 0.7810833333333334, 0.7928333333333333, 0.7930833333333334, 0.7951666666666667, 0.8015833333333333, 0.8000833333333334, 0.8126666666666666, 0.811, 0.81775, 0.8236666666666667, 0.8215, 0.8305833333333333, 0.8251666666666667, 0.8299166666666666, 0.836], [0.3674533206224442, 0.36733597874641416, 0.35894496202468873, 0.3514183223247528, 0.35345671892166136, 0.36494161546230314, 0.35217500329017637, 0.3447349113225937, 0.34697150766849516, 0.36931039452552794, 0.3350031852722168, 0.3416145300865173, 0.32389605045318604, 0.3109715062379837, 0.3322615468502045, 0.327584428191185, 0.31910278856754304, 0.311815539598465, 0.2950947880744934, 0.2948034608364105], [0.808125, 0.789375, 0.826875, 0.821875, 0.81375, 0.804375, 0.80625, 0.83, 0.820625, 0.848125, 0.816875, 0.8125, 0.83, 0.84625, 0.824375, 0.828125, 0.825625, 0.840625, 0.8475, 0.844375]]]\n",
        "data = [[0, 0, [0.400307985173582, 0.2597426520640662, 0.20706942731312025, 0.17091670006251475, 0.13984850759524653, 0.11444453444522518, 0.0929887340481538, 0.07584588486117436, 0.06030314570384176, 0.04997897459031356, 0.037156337104278056, 0.02793900864590992, 0.02030197833807442, 0.01789472087045391, 0.0175876492686666, 0.019220354652448274, 0.013543135874294319, 0.006956856955481477, 0.0024507183060002227, 0.00206579088377317], [0.8547833333333333, 0.9049, 0.9241666666666667, 0.9360166666666667, 0.94695, 0.9585833333333333, 0.9658666666666667, 0.9723166666666667, 0.9780333333333333, 0.9820166666666666, 0.9868, 0.9906666666666667, 0.9936833333333334, 0.9941333333333333, 0.99405, 0.9932833333333333, 0.9960666666666667, 0.9979666666666667, 0.9996666666666667, 0.9995666666666667], [0.36797549843788147, 0.2586278670430183, 0.24208260095119477, 0.24353929474949837, 0.24164094921946525, 0.2638056704550982, 0.2579395814836025, 0.27675500786304474, 0.2851512663513422, 0.30380481338500975, 0.3235128371268511, 0.3284085538983345, 0.3443841063082218, 0.41086878085136413, 0.457796107493341, 0.4356938077956438, 0.4109785168170929, 0.4433729724138975, 0.4688420155197382, 0.4773445381522179], [0.87, 0.908375, 0.91475, 0.915125, 0.91525, 0.91725, 0.924875, 0.91975, 0.922375, 0.92025, 0.920375, 0.924875, 0.9235, 0.918125, 0.91525, 0.918875, 0.923625, 0.9235, 0.92625, 0.925]], [0, 0.25, [0.4710115425463424, 0.3166707545550647, 0.25890692547440275, 0.22350736999753187, 0.19296910860009794, 0.17304379170113154, 0.15315235079105285, 0.13728606270383925, 0.12178339355929034, 0.10961619754736898, 0.10074329449495337, 0.08793247367408294, 0.07651288138686625, 0.06934997136779089, 0.06243234033510685, 0.056774082654433795, 0.05116950291028218, 0.04961718403588313, 0.04289388027836952, 0.040430180404756245], [0.8289666666666666, 0.8851833333333333, 0.9045166666666666, 0.9167666666666666, 0.9294166666666667, 0.93545, 0.94275, 0.9486666666666667, 0.95365, 0.95855, 0.9618833333333333, 0.9667, 0.9717666666666667, 0.9745833333333334, 0.9765833333333334, 0.9793, 0.9809833333333333, 0.9820333333333333, 0.9839166666666667, 0.9849166666666667], [0.3629846270084381, 0.31240448981523516, 0.24729759228229523, 0.2697310926616192, 0.24718070650100707, 0.23403583562374114, 0.2295891786813736, 0.22117181441187858, 0.2475375788807869, 0.23771390727162361, 0.2562992911040783, 0.25533875498175623, 0.27057862806320193, 0.2820998176634312, 0.29471745146811007, 0.2795617451965809, 0.3008101430237293, 0.28815430629253386, 0.31814645100384953, 0.3106237706840038], [0.874125, 0.88875, 0.908875, 0.9045, 0.9145, 0.918125, 0.919375, 0.9245, 0.91975, 0.926, 0.923625, 0.925875, 0.92475, 0.926375, 0.925125, 0.92525, 0.924625, 0.930875, 0.924875, 0.926625]], [0, 0.5, [0.6091368444629316, 0.40709905083309106, 0.33330900164873106, 0.29541655938063605, 0.26824146830864043, 0.24633059249535552, 0.22803501166832219, 0.21262132842689435, 0.20038021789160745, 0.18430457027680647, 0.1744787511763288, 0.165271017740149, 0.15522625095554507, 0.1432937567076608, 0.13617747858651222, 0.12876031456241158, 0.12141566201230325, 0.11405601029369686, 0.11116664642408522, 0.10308189516060992], [0.7803833333333333, 0.8559166666666667, 0.8823, 0.89505, 0.9027333333333334, 0.9099166666666667, 0.9162333333333333, 0.9224833333333333, 0.9243166666666667, 0.9321, 0.9345833333333333, 0.9375333333333333, 0.9418833333333333, 0.9456666666666667, 0.9482333333333334, 0.9513666666666667, 0.9527333333333333, 0.9559, 0.9576166666666667, 0.9611], [0.36491659212112426, 0.29200539910793305, 0.2840233483910561, 0.2591339669823646, 0.24114771646261215, 0.2436459481716156, 0.2374294084906578, 0.24284198743104934, 0.22679156363010405, 0.2229055170416832, 0.21932773572206496, 0.23045065227150918, 0.23631879675388337, 0.22048399156332016, 0.2563135535418987, 0.2494968646839261, 0.24099056956171988, 0.23974315640330315, 0.24684958010911942, 0.25887142738699914], [0.8665, 0.8925, 0.897, 0.907375, 0.914125, 0.9125, 0.913875, 0.911875, 0.921125, 0.922625, 0.923375, 0.924125, 0.922625, 0.926, 0.915625, 0.926125, 0.932625, 0.927875, 0.93, 0.92525]], [0, 0.75, [1.187068938827718, 0.9080034740316842, 0.6863665148329887, 0.5706229420867301, 0.5069490017921432, 0.46316734996876485, 0.42913920047885573, 0.4107565824855874, 0.3908677859061054, 0.37283689377785745, 0.3606657798388111, 0.353545261082301, 0.34009441143986, 0.3239413740506559, 0.3193119444620253, 0.31045137204404577, 0.3003838519091164, 0.29092520530194615, 0.28635713599447504, 0.2760026559138349], [0.5551333333333334, 0.6467, 0.7338666666666667, 0.7841333333333333, 0.8128, 0.82845, 0.8430833333333333, 0.8501666666666666, 0.8580833333333333, 0.8646166666666667, 0.8667666666666667, 0.8709833333333333, 0.8766166666666667, 0.8816666666666667, 0.8812, 0.88465, 0.8898833333333334, 0.8934666666666666, 0.8940833333333333, 0.8977666666666667], [0.6463955206871033, 0.5193838343620301, 0.4155286856889725, 0.3316091845035553, 0.3148408111333847, 0.29354524302482604, 0.2875490103960037, 0.26903486740589144, 0.27737221759557723, 0.262776792883873, 0.25498255288600924, 0.2390553195178509, 0.24918611392378806, 0.23830307483673097, 0.23538302001357078, 0.24996423116326333, 0.2464654156267643, 0.24081429636478424, 0.23204647853970528, 0.23771219885349273], [0.763875, 0.81925, 0.8685, 0.8885, 0.8895, 0.895625, 0.902, 0.904125, 0.906125, 0.908, 0.909375, 0.9145, 0.916125, 0.9175, 0.91875, 0.91425, 0.915375, 0.918875, 0.91975, 0.91825]], [0.25, 0, [0.4140813298491654, 0.27481235485118843, 0.22397600941614174, 0.1890777693286951, 0.16538111197112848, 0.1448796250478132, 0.12440053254032313, 0.10817898457734855, 0.09634132136696025, 0.08548538653410352, 0.07339220296349257, 0.06470446296305314, 0.060030178171393875, 0.053294485403614034, 0.04429284706704323, 0.04014099264770115, 0.03974721442450951, 0.03304463665041803, 0.02955428938137994, 0.026940144761875052], [0.8496666666666667, 0.8982666666666667, 0.9162166666666667, 0.9292166666666667, 0.93805, 0.9457666666666666, 0.9534333333333334, 0.9596, 0.9645833333333333, 0.9679, 0.9726166666666667, 0.9761666666666666, 0.9775, 0.9800166666666666, 0.9842, 0.9855333333333334, 0.9857, 0.98805, 0.9895666666666667, 0.9905833333333334], [0.3327465409040451, 0.27738857254385946, 0.23834018683433533, 0.24359044748544692, 0.23630736249685289, 0.26239568686485293, 0.23089197066426276, 0.23183160039782524, 0.2287161501646042, 0.23795067170262338, 0.2680365410447121, 0.28079107534885406, 0.2745736412107945, 0.27641161236166956, 0.2967236565724015, 0.29836027943715454, 0.28526886811852453, 0.3188628684282303, 0.3159900237545371, 0.33990017675608397], [0.876875, 0.899875, 0.918125, 0.9105, 0.918125, 0.91, 0.92075, 0.922625, 0.924, 0.921, 0.920875, 0.921, 0.9285, 0.927625, 0.9265, 0.927375, 0.925875, 0.927, 0.92575, 0.925875]], [0.25, 0.25, [0.48859380523978013, 0.3269256727337075, 0.275135099903734, 0.24039912359244914, 0.21368402032566858, 0.19328243048317523, 0.17890911489359732, 0.16624130663682402, 0.15215728174088827, 0.1416037013468299, 0.13273427299440288, 0.12227611260405227, 0.11463099068699917, 0.10616964906720179, 0.09988978996809357, 0.09424899211093815, 0.08670466838887077, 0.0835973875783781, 0.0778748192367698, 0.07327510508696741], [0.82055, 0.8806666666666667, 0.9004333333333333, 0.9117333333333333, 0.9206333333333333, 0.92785, 0.9333, 0.9384166666666667, 0.9430333333333333, 0.9471833333333334, 0.95055, 0.9540166666666666, 0.9568833333333333, 0.9601666666666666, 0.9620333333333333, 0.9652, 0.9676833333333333, 0.9682666666666667, 0.9706, 0.9724333333333334], [0.34025013536214826, 0.29788709819316866, 0.2680273652672768, 0.2463292105793953, 0.23471139985322953, 0.22580294385552407, 0.21676637730002404, 0.20925517010688782, 0.23552959233522416, 0.21975916308164598, 0.23494828915596008, 0.21611644634604454, 0.22251244640350343, 0.22066593673825263, 0.2214409472346306, 0.22849382662773132, 0.24493269926309585, 0.2397777333110571, 0.23578458192944526, 0.2563280282020569], [0.870875, 0.8875, 0.900375, 0.906625, 0.9145, 0.921125, 0.92125, 0.92425, 0.916, 0.923125, 0.920375, 0.92675, 0.92575, 0.924875, 0.925, 0.924875, 0.922875, 0.931125, 0.932375, 0.929]], [0.25, 0.5, [0.6104797730917362, 0.42115319246994154, 0.3527538229359874, 0.3136731511446586, 0.2857721160565104, 0.26646374052426197, 0.24732486170523965, 0.23057452346613286, 0.21953405395769743, 0.20952929538100767, 0.19584925043811677, 0.18926965880162044, 0.18003955145856973, 0.17379174885878176, 0.16635702809354644, 0.15807223409366633, 0.1509416516620054, 0.1477138751140758, 0.14028569269798266, 0.13906246528172417], [0.7786833333333333, 0.8482166666666666, 0.8730833333333333, 0.888, 0.8978, 0.9033666666666667, 0.9089166666666667, 0.9147666666666666, 0.91955, 0.9221833333333334, 0.92715, 0.9309666666666667, 0.9334, 0.93495, 0.9376833333333333, 0.9402666666666667, 0.94405, 0.9439166666666666, 0.9466833333333333, 0.9464833333333333], [0.3859497320652008, 0.3124091213941574, 0.28177140313386917, 0.2564259949326515, 0.24969424712657928, 0.23137387067079543, 0.22758139592409135, 0.22978509336709976, 0.2293499847650528, 0.22430640310049058, 0.21563700905442237, 0.21529569518566133, 0.22171301135420798, 0.2105387990772724, 0.21190602815151213, 0.21494245541095733, 0.21312989933788776, 0.20670134457945824, 0.2146600303351879, 0.21474341893941165], [0.86, 0.888, 0.89625, 0.907, 0.908, 0.915, 0.917875, 0.92, 0.921125, 0.917625, 0.924, 0.921875, 0.925875, 0.92575, 0.928125, 0.92775, 0.928625, 0.93075, 0.92975, 0.930375]], [0.25, 0.75, [1.1724896589194789, 0.8803599189911315, 0.692622532690766, 0.5974764075837156, 0.5319996399920124, 0.49373906012028773, 0.4741932853007876, 0.45601858158927483, 0.43706520244892216, 0.4238534729236733, 0.41077356216813454, 0.38932509837882606, 0.3771154705856019, 0.3687882057305719, 0.34927689276937485, 0.3379922736602933, 0.33547254843212393, 0.3263144160448107, 0.31800466419251233, 0.3133781185822446], [0.5631833333333334, 0.6579333333333334, 0.7342166666666666, 0.7765833333333333, 0.8036333333333333, 0.8197166666666666, 0.82755, 0.8320166666666666, 0.8397833333333333, 0.8432666666666667, 0.8519333333333333, 0.85835, 0.86285, 0.8641, 0.87105, 0.8756666666666667, 0.8775166666666666, 0.87965, 0.88255, 0.8832333333333333], [0.5745115535259246, 0.4740168128013611, 0.4092038922309876, 0.345498643040657, 0.32894178831577303, 0.2999964846372604, 0.28456189918518066, 0.28186965006589887, 0.26958267349004744, 0.26703972268104553, 0.2667745503783226, 0.2553461962342262, 0.25764305877685545, 0.2528705199956894, 0.24987997275590895, 0.24210182267427444, 0.2366510547697544, 0.24053962442278862, 0.22825994032621383, 0.2270425768494606], [0.776875, 0.822625, 0.848875, 0.87825, 0.88925, 0.899875, 0.9015, 0.904375, 0.9035, 0.906, 0.906875, 0.91125, 0.907, 0.908625, 0.91175, 0.917125, 0.91675, 0.916125, 0.919875, 0.917625]], [0.5, 0, [0.43062501005145276, 0.29807482149078646, 0.2541527441585623, 0.21918726423338278, 0.1950343672964555, 0.17517360023010387, 0.16213757058244144, 0.14869415854364, 0.13477844860392815, 0.12352272007129848, 0.11392300839184412, 0.10589898744228679, 0.09751250602896692, 0.089864786467088, 0.08516462990539526, 0.07973235945548934, 0.07441158362824137, 0.07053931183896578, 0.06258528833356954, 0.06177985634201014], [0.8429, 0.88905, 0.9052166666666667, 0.9182166666666667, 0.92755, 0.9337666666666666, 0.93835, 0.944, 0.9489333333333333, 0.95365, 0.9565333333333333, 0.9599166666666666, 0.9637833333333333, 0.9659666666666666, 0.9685666666666667, 0.9705, 0.9713666666666667, 0.9738, 0.9770166666666666, 0.9769833333333333], [0.32814766228199005, 0.29447353577613833, 0.25052148789167406, 0.22761481428146363, 0.23280890756845474, 0.23155913531780242, 0.21984874603152274, 0.2166314404308796, 0.2202563073039055, 0.22508277136087418, 0.2237191815972328, 0.2246915928721428, 0.22815296687185765, 0.2254556802213192, 0.2337513281852007, 0.2381753808259964, 0.24798179551959038, 0.24766947883367538, 0.24877363580465317, 0.2518915164768696], [0.879625, 0.89025, 0.907875, 0.916625, 0.91625, 0.91825, 0.920875, 0.923625, 0.922625, 0.923, 0.92575, 0.927125, 0.928625, 0.92625, 0.925375, 0.925625, 0.926375, 0.92475, 0.9255, 0.92675]], [0.5, 0.25, [0.5022556754285847, 0.3545388207554436, 0.2965180559564374, 0.2689443711818917, 0.24340009927622544, 0.22504497168144819, 0.21177587015574167, 0.19926073912507308, 0.18498492261557692, 0.1792394390810273, 0.16716771742809555, 0.16088557891500022, 0.15540826101420022, 0.1471743908549931, 0.14383414784458273, 0.1351151093741311, 0.1312572255915305, 0.12904865093140014, 0.12332957751079918, 0.11934908895072208], [0.8186333333333333, 0.8711666666666666, 0.8905666666666666, 0.9020666666666667, 0.9106333333333333, 0.9169333333333334, 0.9227, 0.9258166666666666, 0.9317, 0.9329666666666667, 0.9384833333333333, 0.9394333333333333, 0.94185, 0.9447666666666666, 0.9449833333333333, 0.9489, 0.9506, 0.9520333333333333, 0.95295, 0.9556833333333333], [0.37072600054740906, 0.2894986196160316, 0.2896255247592926, 0.2553737629055977, 0.2347450014948845, 0.23144772934913635, 0.22532679361104965, 0.2152210614681244, 0.21610748746991157, 0.22872606116533278, 0.22058768355846406, 0.20230921444296837, 0.2118315652012825, 0.20028054055571556, 0.20844366964697839, 0.20884322375059128, 0.21231223946809769, 0.19875787001848222, 0.2072589308321476, 0.22480831852555275], [0.862, 0.894, 0.892375, 0.906375, 0.912625, 0.91375, 0.916875, 0.918875, 0.92125, 0.9185, 0.920375, 0.92825, 0.9255, 0.92925, 0.926875, 0.9285, 0.926375, 0.93075, 0.931125, 0.922875]], [0.5, 0.5, [0.6208003907124879, 0.4341448332582201, 0.3655890760454796, 0.3245583019102179, 0.3000562671722888, 0.2840681741280215, 0.2686156402947679, 0.25843519997844566, 0.24892204790227196, 0.23988707410469493, 0.22968693327770304, 0.22323107979953416, 0.21376596502403714, 0.21353628940340172, 0.208721635311143, 0.20283085862393063, 0.19862186088204892, 0.1939613972542319, 0.18833921627917968, 0.18451892669552933], [0.7769666666666667, 0.8453333333333334, 0.86965, 0.88425, 0.8911, 0.8957666666666667, 0.90125, 0.9056666666666666, 0.9083833333333333, 0.9122666666666667, 0.91455, 0.9176833333333333, 0.92035, 0.9217, 0.9232333333333334, 0.9238333333333333, 0.9270333333333334, 0.9283, 0.93035, 0.9312333333333334], [0.390482270359993, 0.3140819278359413, 0.286346542596817, 0.26530489122867584, 0.25648517191410064, 0.25534764647483826, 0.24066219604015351, 0.22813884472846985, 0.22091108289361, 0.22591463786363603, 0.22548504903912545, 0.21807716876268388, 0.23463654381036758, 0.21917386519908905, 0.2077158398628235, 0.2112607652246952, 0.205703763961792, 0.21748955991864205, 0.20092388433218003, 0.20742826372385026], [0.859125, 0.884375, 0.89225, 0.9035, 0.9045, 0.904875, 0.907875, 0.915375, 0.914875, 0.915375, 0.916375, 0.92075, 0.91575, 0.91825, 0.92375, 0.924, 0.924875, 0.917125, 0.926875, 0.920875]], [0.5, 0.75, [1.1608194957918196, 0.8736483463918222, 0.7270457689632485, 0.6118623841482439, 0.5539627463769302, 0.5169604117872872, 0.4843029365547176, 0.4664089765979537, 0.449539397952399, 0.4308713404481599, 0.4170197155842903, 0.4104185118508746, 0.3983522486299086, 0.3890672579232945, 0.38423672571047535, 0.38125834129512437, 0.36963055836461756, 0.36898326972273116, 0.3608236700328174, 0.35822524538617145], [0.56785, 0.6591833333333333, 0.71765, 0.7660333333333333, 0.7931666666666667, 0.8079666666666667, 0.8198833333333333, 0.8275166666666667, 0.8349833333333333, 0.8422, 0.8473666666666667, 0.8486833333333333, 0.85425, 0.85675, 0.8578666666666667, 0.8603333333333333, 0.8643333333333333, 0.8637833333333333, 0.8684333333333333, 0.8680166666666667], [0.5984484012126923, 0.5152713191509247, 0.42289899206161496, 0.3746640253067017, 0.3369040569067001, 0.32359291434288023, 0.2978636801838875, 0.2998174095153809, 0.2883352539539337, 0.2839300352931023, 0.2775397801399231, 0.2616970262527466, 0.259125192284584, 0.25470315623283385, 0.2535187450051308, 0.2600560383200645, 0.25031394577026367, 0.2547155976295471, 0.23950587111711502, 0.24401323813199996], [0.750875, 0.78025, 0.86225, 0.869875, 0.884875, 0.891625, 0.898875, 0.89275, 0.901875, 0.9005, 0.899875, 0.908375, 0.91125, 0.910375, 0.910375, 0.907, 0.9135, 0.910375, 0.914125, 0.911625]], [0.75, 0, [0.5018121279410716, 0.3649225841834347, 0.31199926770985253, 0.2825479824850554, 0.25993211727057186, 0.2431308363737074, 0.22870161555913973, 0.22126636312587428, 0.2113911879540824, 0.20279224649834227, 0.19300907663603836, 0.18686007729360163, 0.1815741605866057, 0.1759802805684777, 0.17041425832084564, 0.16513840764014323, 0.15892388751861383, 0.1548161118118557, 0.1498002242614656, 0.14744469122107284], [0.8158, 0.8648, 0.8846833333333334, 0.8954666666666666, 0.9035333333333333, 0.9097666666666666, 0.9142666666666667, 0.91615, 0.9219166666666667, 0.9239333333333334, 0.9268166666666666, 0.9287666666666666, 0.9304833333333333, 0.9327333333333333, 0.9365, 0.9368666666666666, 0.9395333333333333, 0.9418833333333333, 0.9445, 0.9450166666666666], [0.35916801404953, 0.30038927191495896, 0.2824265750646591, 0.28094157111644746, 0.2402345055937767, 0.24779821130633353, 0.2263277245759964, 0.22270147562026976, 0.22010754531621932, 0.20850908517837524, 0.21723379525542258, 0.20454896742105483, 0.2065480750799179, 0.20593296563625335, 0.21030707907676696, 0.2015896993279457, 0.19770563289523124, 0.19552358242869378, 0.197759574085474, 0.19900305101275445], [0.867125, 0.890875, 0.896875, 0.896, 0.912125, 0.90875, 0.9185, 0.916875, 0.920375, 0.925125, 0.919375, 0.92675, 0.927125, 0.924625, 0.924125, 0.9275, 0.928, 0.928875, 0.93325, 0.930125]], [0.75, 0.25, [0.564780301424359, 0.41836969141385705, 0.3581543931924204, 0.3251280398018706, 0.30215959723538427, 0.28700008430778345, 0.27507679125488693, 0.26540731782439164, 0.25373875692105496, 0.24964979071734048, 0.24098571216357922, 0.23604591902512223, 0.2270722362135392, 0.2229606584985373, 0.22031292727570545, 0.21439386613126885, 0.21020108821200156, 0.2042837777872012, 0.20376247368149283, 0.20021205727082453], [0.7927, 0.8474166666666667, 0.8672166666666666, 0.8811833333333333, 0.8883, 0.8952833333333333, 0.89795, 0.9011333333333333, 0.9055833333333333, 0.9071166666666667, 0.9100333333333334, 0.911, 0.91515, 0.9162166666666667, 0.91775, 0.9197833333333333, 0.9218666666666666, 0.9239, 0.9236833333333333, 0.92455], [0.39558523416519165, 0.3187315353155136, 0.30105597496032716, 0.2717038299441338, 0.25286867189407347, 0.24664685553312302, 0.24286985045671464, 0.23643679201602935, 0.23006864881515504, 0.2277349520921707, 0.22591854375600814, 0.2165311907827854, 0.21385486593842506, 0.21402871897816658, 0.2096972267627716, 0.21242560443282127, 0.2098898750245571, 0.2062524998188019, 0.19932547932863234, 0.20170186588168143], [0.850625, 0.88125, 0.8845, 0.897125, 0.9065, 0.9085, 0.907625, 0.91275, 0.917125, 0.9135, 0.91825, 0.922625, 0.91925, 0.921125, 0.923625, 0.92225, 0.923375, 0.922875, 0.925625, 0.92775]], [0.75, 0.5, [0.6916971901205303, 0.4947840944567977, 0.41710148827988963, 0.38678343986460906, 0.36429949198513906, 0.34339441834831796, 0.33055868282564665, 0.3199633415272114, 0.31550557391920575, 0.3022628513289921, 0.2959158662110885, 0.2941135993993867, 0.28555906579089063, 0.27903660322462065, 0.2769482293601102, 0.27154609372716215, 0.26548120195963487, 0.26188135733291795, 0.2588035051009929, 0.2574938320115939], [0.7497333333333334, 0.8236833333333333, 0.8482333333333333, 0.8618666666666667, 0.8703666666666666, 0.8772166666666666, 0.8803333333333333, 0.8829166666666667, 0.88525, 0.88945, 0.89275, 0.8937166666666667, 0.8969, 0.8977666666666667, 0.9, 0.90175, 0.9041666666666667, 0.9035, 0.9049, 0.9046166666666666], [0.41916924858093263, 0.3380992366075516, 0.31549062132835387, 0.2921286026239395, 0.2786481494307518, 0.28516836106777194, 0.25556409001350405, 0.2538892236948013, 0.24726227968931197, 0.24262803781032563, 0.24080126863718032, 0.24242325466871262, 0.23416680485010147, 0.22847312396764755, 0.22423979061841964, 0.2311997367441654, 0.22794704174995423, 0.21943940049409866, 0.21820387506484987, 0.21150743806362152], [0.8435, 0.87725, 0.88425, 0.890375, 0.898125, 0.89275, 0.905625, 0.906125, 0.911, 0.910625, 0.911, 0.909875, 0.914875, 0.915375, 0.917875, 0.915, 0.91475, 0.919625, 0.923875, 0.92425]], [0.75, 0.75, [1.162218615571573, 0.8284856370453642, 0.7309887468624217, 0.6590983641744931, 0.6089096262510906, 0.5663433943285363, 0.5383681068733048, 0.5242803116787725, 0.49926126579930785, 0.48940120944018556, 0.4789252862779062, 0.46633604049746163, 0.4596060775458686, 0.4464966354847971, 0.4418302221593064, 0.43759817490254893, 0.42892070028827645, 0.4226101264516428, 0.418694807601763, 0.4110745745840103], [0.58005, 0.6824666666666667, 0.7223333333333334, 0.7464333333333333, 0.7711333333333333, 0.7891833333333333, 0.8012333333333334, 0.80635, 0.8172666666666667, 0.82225, 0.8271833333333334, 0.831, 0.8335833333333333, 0.8371833333333333, 0.8412166666666666, 0.84265, 0.8458833333333333, 0.8471166666666666, 0.8497666666666667, 0.8522833333333333], [0.5945872340202332, 0.518519122838974, 0.4681703653335571, 0.42978407418727876, 0.40349935555458066, 0.37377681517601014, 0.35234942865371705, 0.3359788683652878, 0.3217720929384232, 0.3279728285074234, 0.3114012089371681, 0.3060767319202423, 0.2949701727628708, 0.2981588536500931, 0.2855641575455666, 0.28112928783893587, 0.28212732630968096, 0.27846804082393645, 0.27372796374559405, 0.27415593349933626], [0.78525, 0.8215, 0.820125, 0.844375, 0.86375, 0.875125, 0.876625, 0.882, 0.887875, 0.884625, 0.890375, 0.892125, 0.897125, 0.894125, 0.902625, 0.89975, 0.89975, 0.90125, 0.902, 0.90075]]]\n",
        "\n",
        "\n",
        "Dropout1 = 0.25 # param {type:\"slider\", min:0, max:0.75, step:0.25}\n",
        "Dropout2 = 0.75 # param {type:\"slider\", min:0, max:0.75, step:0.25}\n",
        "\n",
        "def plot(Dropout1, Dropout2):\n",
        "  d1, d2, train_loss, train_acc, validation_loss, validation_acc = data[int(Dropout1 * 4) * 4 + int(Dropout2 * 4)]\n",
        "  print(d1, d2)\n",
        "  plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)\n",
        "  plt.gcf().axes[0].set_ylim(0, 1.2)\n",
        "  plt.gcf().axes[1].set_ylim(0.5, 1)\n",
        "\n",
        "  my_stringIObytes = io.BytesIO()\n",
        "  plt.savefig(my_stringIObytes, format='png', dpi=90)\n",
        "  my_stringIObytes.seek(0)\n",
        "  my_base64_jpgData = base64.b64encode(my_stringIObytes.read())\n",
        "  plt.close()\n",
        "  p.value = \"\"\"<img src=\"data:image/png;base64,\"\"\" + str(my_base64_jpgData)[2:-1] + \"\"\"\" alt=\"Graph\">\"\"\"\n",
        "\n",
        "d1 = widgets.FloatSlider(min=0, max=0.75, value=0.25, step=0.25, description=\"Dropout 1\", style={'description_width': 'initial', 'width': '800px'}, )\n",
        "d2 = widgets.FloatSlider(min=0, max=0.75, value=0.25, step=0.25, description=\"Dropout 2\", style={'description_width': 'initial', 'width': '800px'}, )\n",
        "p = widgets.HTML(value=\"aasdsd\")\n",
        "\n",
        "w = interactive_output(plot, {\"Dropout1\":d1, \"Dropout2\": d2})\n",
        "display(widgets.VBox([d1, d2, p, w]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "4l01p7z05Q90"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Dropout_exploration_Bonus_Interactive_Demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "FqDJ4gV_5Q90"
      },
      "source": [
        "### Coding Exercise Bonus 2.2: How much does augmentation help?\n",
        "\n",
        "Last week you also learned how data augmentation can  regularize a network. Let's add data augmentation to our model via transforms and see if that helps our model to better generalize! In the following cell, add the transforms you want in the list `augmentation_transforms`. We will then run the same network you created in the above exercise (with regularization) and then plot the loss and accuracies.\n",
        "\n",
        "[Here](https://pytorch.org/vision/stable/transforms.html) is the link to the list of transforms available in PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "QDWXKzol5Q90"
      },
      "outputs": [],
      "source": [
        "# @title Download Fashion-MNIST, if it has not been downloaded.\n",
        "fname = 'FashionMNIST.tar.gz'\n",
        "folder = 'FashionMNIST'\n",
        "url = \"https://osf.io/dfhu5/download\"\n",
        "download_data(fname, folder, url, tar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "kDH1OcGo5Q90"
      },
      "outputs": [],
      "source": [
        "def transforms_custom(binary=False, download=False, seed=0):\n",
        "  \"\"\"\n",
        "  Helper function defining transformations\n",
        "\n",
        "  Args:\n",
        "    binary: boolean\n",
        "      If True, number of classes = 2\n",
        "    download: boolean\n",
        "      If True, download dataset\n",
        "    seed: int\n",
        "      Set seed for reproducibility\n",
        "\n",
        "  Returns:\n",
        "    train_loader: torch.loader\n",
        "      Training Set\n",
        "    test_loader: torch.loader\n",
        "      Test Set\n",
        "    validation_loader: torch.loader\n",
        "      Validation Set\n",
        "  \"\"\"\n",
        "  # Basic preprocessing\n",
        "  preprocessing_transforms = [transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.1307,), (0.3081,))]\n",
        "  # Add the augmentation transforms to the preprocessing\n",
        "  train_transform = transforms.Compose(get_augmentation_transforms() +\n",
        "                                       preprocessing_transforms)\n",
        "  # Load the Fashion MNIST dataset with the transforms\n",
        "  train_data = datasets.FashionMNIST(root='.',\n",
        "                                     download=download,\n",
        "                                     train=True,\n",
        "                                     transform=train_transform)\n",
        "  if binary:\n",
        "    # Reduce to our two classes to speed up training\n",
        "    train_data = reduce_classes(train_data)\n",
        "\n",
        "  # Get the data loader instances for the dataset\n",
        "  train_loader, validation_loader, test_loader = get_data_loaders(train_data,\n",
        "                                                                  validation_data,\n",
        "                                                                  test_data,\n",
        "                                                                  seed)\n",
        "\n",
        "  return train_loader, validation_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "DJ-vtiot5Q90"
      },
      "outputs": [],
      "source": [
        "def get_augmentation_transforms():\n",
        "  \"\"\"\n",
        "  Returns Augmentation Transforms\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    augmentation_transforms: list\n",
        "      List of augmentation transforms\n",
        "  \"\"\"\n",
        "  ####################################################################\n",
        "  # Fill in missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Add Transforms\")\n",
        "  ####################################################################\n",
        "  augmentation_transforms = [..., ...]\n",
        "\n",
        "  return augmentation_transforms\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "net3 = FMNIST_Net2(num_classes=2).to(DEVICE)  # Get the network\n",
        "\n",
        "## Uncomment below to test your function\n",
        "# train_loader, validation_loader, test_loader = transforms_custom(binary=True, seed=SEED)\n",
        "# train_loss, train_acc, validation_loss, validation_acc = train(net3, DEVICE, train_loader, validation_loader, 20)\n",
        "# print(f'Test accuracy is: {test(net3, DEVICE, test_loader)}')\n",
        "# plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mCWYsQnR5Q90"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_240aa557.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=1525.0 height=525.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_240aa557_3.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "RWlxM49C5Q90"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_How_much_augmentation_help_Bonus_Exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "T2pZWxn15Q91"
      },
      "source": [
        "### Think! Bonus 2.2: Data Augmentation\n",
        "\n",
        "Did the training accuracy reduce further compared to with dropout alone? Is the model still overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8R8u_iTZ5Q91"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main/tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_ae125a93.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "OfW2sPrN5Q91"
      },
      "source": [
        "Great! In this section you trained what may have been your very first CNN. You added regularization and data augmentation in order to get a model that generalizes well. All the pieces are beginning to fit together!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "2u155K-I5Q91"
      },
      "outputs": [],
      "source": [
        "# @title Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_Data_Augmentation_Bonus_Discussion\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "W2D2_Tutorial1",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b87eb034ba5442d0bf3e034a568de188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TabModel",
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TabView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f25571432bba452ba1f3ce03f18e03e8",
              "IPY_MODEL_998a3290d6f14cf0aafdfd0d249e0a30"
            ],
            "layout": "IPY_MODEL_f5a46f5d4127447fbb4af27c8ae4f230",
            "selected_index": 0
          }
        },
        "f25571432bba452ba1f3ce03f18e03e8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_786c5cb41f6241f7bded86594855baeb",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://youtube.com/watch?v=5598K-hS89A\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7a283b6e7ed0>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/5598K-hS89A?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ",
                  "image/jpeg": "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\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "998a3290d6f14cf0aafdfd0d249e0a30": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_03b9701815d949bd883444253016294b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://www.bilibili.com/video/BV1cL411p7rz\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<__main__.PlayVideo at 0x7a283b5692d0>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1cL411p7rz&page=1?fs=1&autoplay=False\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
                },
                "metadata": {}
              }
            ]
          }
        },
        "f5a46f5d4127447fbb4af27c8ae4f230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786c5cb41f6241f7bded86594855baeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b9701815d949bd883444253016294b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710b8404c9214c5e89d8f9e2b6724776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TabModel",
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TabView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37004122064e4b0ab6da16504e53690f",
              "IPY_MODEL_322aa03c08044c59aed23f845b5a4e56"
            ],
            "layout": "IPY_MODEL_7d56cdb94b2f4a379c93b3244069aecf",
            "selected_index": 0
          }
        },
        "37004122064e4b0ab6da16504e53690f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_70b674d385904a38964ac9d5cce6fc55",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://youtube.com/watch?v=AXO-iflKa58\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7a283b83b310>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/AXO-iflKa58?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ",
                  "image/jpeg": "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\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "322aa03c08044c59aed23f845b5a4e56": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3304fae8eb5345d9aee08c1abe019634",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://www.bilibili.com/video/BV1c64y1x7mJ\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<__main__.PlayVideo at 0x7a283b7e4950>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1c64y1x7mJ&page=1?fs=1&autoplay=False\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
                },
                "metadata": {}
              }
            ]
          }
        },
        "7d56cdb94b2f4a379c93b3244069aecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b674d385904a38964ac9d5cce6fc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3304fae8eb5345d9aee08c1abe019634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8611a6b7ccd4c55b932d8eefd241c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TabModel",
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TabView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24e5a887acec411d8ff57a9b759e5fab",
              "IPY_MODEL_8e032ad7e3d74986aa420fece8b33afa"
            ],
            "layout": "IPY_MODEL_88286767786440e3b6e15852af349671",
            "selected_index": 0
          }
        },
        "24e5a887acec411d8ff57a9b759e5fab": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c3a4dfcb530c44448ce054311f32fcab",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://youtube.com/watch?v=pmc40WCnF-w\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7a2919c75210>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/pmc40WCnF-w?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ",
                  "image/jpeg": "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\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "8e032ad7e3d74986aa420fece8b33afa": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_1816700c745846cdbc1e0a3ac94da452",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://www.bilibili.com/video/BV1Q64y1z77p\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<__main__.PlayVideo at 0x7a283b5bc950>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1Q64y1z77p&page=1?fs=1&autoplay=False\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
                },
                "metadata": {}
              }
            ]
          }
        },
        "88286767786440e3b6e15852af349671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a4dfcb530c44448ce054311f32fcab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1816700c745846cdbc1e0a3ac94da452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}